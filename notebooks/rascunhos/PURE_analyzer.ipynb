{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def check_files(directory1, directory2):\n",
    "    \"\"\"\n",
    "    Compares filesnames between two directories and return information about intersections and differences\n",
    "    \n",
    "    Args:\n",
    "        directory1 (str): Path to the first directory.\n",
    "        directory2 (str): Path to the second directory.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing unique intersections and files from each directory.\n",
    "    \"\"\"\n",
    "    files1 = os.listdir(directory1)\n",
    "    files2 = os.listdir(directory2)\n",
    "    \n",
    "    names1 = set([x[:x.find(\".\")] for x in files1])\n",
    "    names2 = set([x[:x.find(\".\")] for x in files2])\n",
    "    \n",
    "    intersection = names1.intersection(names2)\n",
    "    excluisive_directory1 = names1 - names2\n",
    "    excluisive_directory2 = names2 - names1\n",
    "    \n",
    "    excluisive_directory1 = sorted(list(excluisive_directory1))\n",
    "    excluisive_directory2 = sorted(list(excluisive_directory2))\n",
    "    \n",
    "    result =  {\n",
    "        \"intersection\": intersection,\n",
    "        \"excluisive_directory1\": excluisive_directory1,\n",
    "        \"excluisive_directory2\": excluisive_directory2\n",
    "    }\n",
    "\n",
    "    print(f\"Directories compared: {directory1} and {directory2}\")\n",
    "    print(f\"Intersection: {result['intersection']}\")\n",
    "    print(f\"Exclusive files in directory 1: {result['excluisive_directory1']}\")\n",
    "    print(f\"Exclusive files in directory 2: {result['excluisive_directory2']}\")\n",
    "    print(\"=\" * 250)\n",
    "\n",
    "    return result\n",
    "\n",
    "def check_keys(csv_path):\n",
    "    \"\"\"\n",
    "    Checks if all keys in a CSV file start with \"G.D\".\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "              - \"valid_keys\": List of valid keys (that start with \"G.D\").\n",
    "              - \"invalid_keys\": List of invalid keys (that do not start with \"G.D\").\n",
    "              - \"total_keys\": Total number of key checked.\n",
    "              - \"valid_count\": Number of valid keys.\n",
    "              - \"invalid_count\": Number of invalid keys.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error readinf CSV file: {e}\"}\n",
    "\n",
    "    if \"keys\" not in df.columns:\n",
    "        return {\"error\": \"The 'keys' column was not found in the CSV file.\"}\n",
    "\n",
    "    keys = df[\"keys\"]\n",
    "\n",
    "    valid_keys = [key for key in keys if str(key).startswith(\"G.D\")]\n",
    "    invalid_keys = [key for key in keys if not str(key).startswith(\"G.D\")]\n",
    "\n",
    "    return {\n",
    "        \"valid_keys\": valid_keys,\n",
    "        \"invalid_keys\": invalid_keys,\n",
    "        \"total_keys\": len(keys),\n",
    "        \"valid_count\": len(valid_keys),\n",
    "        \"invalid_count\": len(invalid_keys)\n",
    "    } \n",
    "    \n",
    "def generate_filename_map(directory):\n",
    "    \"\"\"\n",
    "    Generates a mapping of filenames in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are filenames without extensions and \n",
    "              the values are their respective positions in the directory listing.\n",
    "    \"\"\"\n",
    "    files = os.listdir(directory)\n",
    "    filenames = [x[:x.find(\".\")] for x in files]\n",
    "    filenames_map = {v: k for k, v in enumerate(filenames)}\n",
    "    \n",
    "    return filenames_map    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 0, valor: G.D\n",
      "num: 1, valor: G.D1\n",
      "num: 2, valor: G.D2\n",
      "num: 3, valor: G.D3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for num, valor in enumerate([\"G.D\", \"G.D1\", \"G.D2\", \"G.D3\"]):\n",
    "    print(f\"num: {num}, valor: {valor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_doc_path = os.path.join(\"..\", \"data\", \"ReqList_ReqNet_ReqSim\", \"0 Requirement Specification Documents\")\n",
    "\n",
    "req_doc_raw_path = os.path.join(\"..\", \"data\", \"ReqList_ReqNet_ReqSim\", \"0.1 Raw Text\")\n",
    "\n",
    "req_list_path = os.path.join(\"..\", \"data\", \"ReqList_ReqNet_ReqSim\", \"1 ReqLists\")\n",
    "\n",
    "doc_structure_path = os.path.join(\"..\", \"data\", \"ReqList_ReqNet_ReqSim\", \"2 DocumentStructure - Metadata\")\n",
    "\n",
    "mock_req_doc_raw_path = os.path.join(\"..\", \"tests\", \"mocks\", \"mock_0_req_doc_raw_text\")\n",
    "\n",
    "mock_req_list_path = os.path.join(\"..\", \"tests\", \"mocks\", \"mock_1_req_lists\")\n",
    "\n",
    "mock_doc_structure_path = os.path.join(\"..\", \"tests\", \"mocks\", \"mock_2_doc_struct_metadata\")\n",
    "\n",
    "directories = [\n",
    "    #req_doc_path,\n",
    "    #req_doc_raw_path,\n",
    "    #req_list_path,\n",
    "    #doc_structure_path,\n",
    "    #mock_req_doc_raw_path,\n",
    "    #mock_req_list_path,\n",
    "    mock_doc_structure_path\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733.25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8799/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories compared: ../data/ReqList_ReqNet_ReqSim/1 ReqLists and ../data/ReqList_ReqNet_ReqSim/0.1 Raw Text\n",
      "Intersection: {'2008 - virtual ed', '2016 - FDP Clearinghouse', '2008 - caiso', '2005 - clarus low', 'light-control-system', '2017 - NISTMfgData', '1999 - tcs', '2003 - tachonet', '2010 - mashboot', '2012 - EMR CCHIT LT', '2001 - ctc network', '2010 - split merge', '2007 - puget sound', '2012 - EMR HHS', '2007 - Wildlife', '2009 - gaia', '2004 - rlcs', '2002 - evla back', '1999 - multi-mahjong', '2004 - SGVTraffic', '2009 - warc III', '2005 - nenios', '2022 - MobileSurveillance', '2009 - video search', '2021 - ConnectedVehiclePilotNYC', '2004 - sprat', '1995 - gemini', '2002 - evla corr', '2001 - elsfork', '2004 - colorcast', '2012 - EMR CCHCS ISO', '2003 - agentmom', '2000 - Barrel', '2010 - fishing', '2003 - qheadache', '1997 - Modis', '2012 - EMR Pharmacy', '2001 - hats', 'automated-insulin-pump', '2003 - pnnl', '0000 - inventory', '0000 - gamma j', '2006 - stewards', '2005 - phin', '2006 - eirene sys 15', '2019 - MOSAR', '2012 - NASAProcessReq', '2000 - nasa x38', 'EHR System FuncReq - LA DHS', '2007 - ertms', '2005 - grid 3D', '2013 - iTrust', '1995 - Landsat7', '2010 - blit draft', '2012 - EMR CCHCS EA', '1998 - themas', '2021 - ReqView', '2005 - pontis', '2011 - KMS', '2012 - EMR HL7 IN', '2022 - UAM IMS', '2007 - get real 0', '2007 - mdot', '2017 - ePhyto', '1999 - Defense', '2001 - npac', '2011 - CCHIT', '2010 - home 1', '2009 - library', '2004 - grid bgc', '0000 - cctns', '2007 - e-store', '2014 - Minutia', '2007 - eirene fun 7', '2001 - beyond', '2009 - library2', '2012 - EMR HL7 DC', '2005 - triangle', '2009 - peppol', '2005 - znix', '2007 - nde', '2005 - clarus high', 'EHR System TechReq LA DHS', '2001 - esa', 'RROWDyS', '2018 - DataWarehouse'}\n",
      "Exclusive files in directory 1: []\n",
      "Exclusive files in directory 2: []\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Directories compared: ../data/ReqList_ReqNet_ReqSim/1 ReqLists and ../data/ReqList_ReqNet_ReqSim/2 DocumentStructure - Metadata\n",
      "Intersection: {'2008 - virtual ed', '2016 - FDP Clearinghouse', '2008 - caiso', '2005 - clarus low', 'light-control-system', '2017 - NISTMfgData', '1999 - tcs', '2003 - tachonet', '2010 - mashboot', '2012 - EMR CCHIT LT', '2001 - ctc network', '2010 - split merge', '2007 - puget sound', '2012 - EMR HHS', '2007 - Wildlife', '2009 - gaia', '2004 - rlcs', '2002 - evla back', '1999 - multi-mahjong', '2004 - SGVTraffic', '2009 - warc III', '2005 - nenios', '2022 - MobileSurveillance', '2009 - video search', '2021 - ConnectedVehiclePilotNYC', '2004 - sprat', '1995 - gemini', '2002 - evla corr', '2001 - elsfork', '2004 - colorcast', '2012 - EMR CCHCS ISO', '2003 - agentmom', '2000 - Barrel', '2010 - fishing', '2003 - qheadache', '1997 - Modis', '2012 - EMR Pharmacy', '2001 - hats', 'automated-insulin-pump', '2003 - pnnl', '0000 - inventory', '0000 - gamma j', '2006 - stewards', '2005 - phin', '2006 - eirene sys 15', '2019 - MOSAR', '2012 - NASAProcessReq', '2000 - nasa x38', 'EHR System FuncReq - LA DHS', '2007 - ertms', '2005 - grid 3D', '2013 - iTrust', '1995 - Landsat7', '2010 - blit draft', '2012 - EMR CCHCS EA', '1998 - themas', '2021 - ReqView', '2005 - pontis', '2011 - KMS', '2012 - EMR HL7 IN', '2022 - UAM IMS', '2007 - get real 0', '2007 - mdot', '2017 - ePhyto', '1999 - Defense', '2001 - npac', '2011 - CCHIT', '2010 - home 1', '2009 - library', '2004 - grid bgc', '0000 - cctns', '2007 - e-store', '2014 - Minutia', '2007 - eirene fun 7', '2001 - beyond', '2009 - library2', '2012 - EMR HL7 DC', '2005 - triangle', '2009 - peppol', '2005 - znix', '2007 - nde', '2005 - clarus high', 'EHR System TechReq LA DHS', '2001 - esa', 'RROWDyS', '2018 - DataWarehouse'}\n",
      "Exclusive files in directory 1: []\n",
      "Exclusive files in directory 2: []\n",
      "==========================================================================================================================================================================================================================================================\n",
      "Directories compared: ../data/ReqList_ReqNet_ReqSim/0.1 Raw Text and ../data/ReqList_ReqNet_ReqSim/2 DocumentStructure - Metadata\n",
      "Intersection: {'2008 - virtual ed', '2016 - FDP Clearinghouse', '2008 - caiso', '2005 - clarus low', 'light-control-system', '2017 - NISTMfgData', '1999 - tcs', '2003 - tachonet', '2010 - mashboot', '2012 - EMR CCHIT LT', '2001 - ctc network', '2010 - split merge', '2007 - puget sound', '2012 - EMR HHS', '2007 - Wildlife', '2009 - gaia', '2004 - rlcs', '2002 - evla back', '1999 - multi-mahjong', '2004 - SGVTraffic', '2009 - warc III', '2005 - nenios', '2022 - MobileSurveillance', '2009 - video search', '2021 - ConnectedVehiclePilotNYC', '2004 - sprat', '1995 - gemini', '2002 - evla corr', '2001 - elsfork', '2004 - colorcast', '2012 - EMR CCHCS ISO', '2003 - agentmom', '2000 - Barrel', '2010 - fishing', '2003 - qheadache', '1997 - Modis', '2012 - EMR Pharmacy', '2001 - hats', 'automated-insulin-pump', '2003 - pnnl', '0000 - inventory', '0000 - gamma j', '2006 - stewards', '2005 - phin', '2006 - eirene sys 15', '2019 - MOSAR', '2012 - NASAProcessReq', '2000 - nasa x38', 'EHR System FuncReq - LA DHS', '2007 - ertms', '2005 - grid 3D', '2013 - iTrust', '1995 - Landsat7', '2010 - blit draft', '2012 - EMR CCHCS EA', '1998 - themas', '2021 - ReqView', '2005 - pontis', '2011 - KMS', '2012 - EMR HL7 IN', '2022 - UAM IMS', '2007 - get real 0', '2007 - mdot', '2017 - ePhyto', '1999 - Defense', '2001 - npac', '2011 - CCHIT', '2010 - home 1', '2009 - library', '2004 - grid bgc', '0000 - cctns', '2007 - e-store', '2014 - Minutia', '2007 - eirene fun 7', '2001 - beyond', '2009 - library2', '2012 - EMR HL7 DC', '2005 - triangle', '2009 - peppol', '2005 - znix', '2007 - nde', '2005 - clarus high', 'EHR System TechReq LA DHS', '2001 - esa', 'RROWDyS', '2018 - DataWarehouse'}\n",
      "Exclusive files in directory 1: []\n",
      "Exclusive files in directory 2: []\n",
      "==========================================================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#req_x_req_doc = check_files(req_list_path, req_doc_path)\n",
    "req_x_req_doc_raw = check_files(req_list_path, req_doc_raw_path)\n",
    "req_x_doc_structure = check_files(req_list_path, doc_structure_path)\n",
    "#req_doc_x_doc_structure = check_files(req_doc_path, doc_structure_path)\n",
    "#req_doc_x_req_doc_raw = check_files(req_doc_path, req_doc_raw_path)\n",
    "req_doc_raw_x_doc_structure = check_files(req_doc_raw_path, doc_structure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chaves verificadas: 12725\n",
      "Chaves válidas: 12725\n",
      "Chaves inválidas: 0\n",
      "\n",
      "Todas as chaves são válidas!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = os.path.join(\"..\", \"data\",\"pure_req_user_stories.csv\") \n",
    "result = check_keys(csv_path)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "else:\n",
    "    print(f\"Total de chaves verificadas: {result['total_keys']}\")\n",
    "    print(f\"Chaves válidas: {result['valid_count']}\")\n",
    "    print(f\"Chaves inválidas: {result['invalid_count']}\")\n",
    "\n",
    "    if result[\"invalid_keys\"]:\n",
    "        print(\"\\nChaves inválidas encontradas:\")\n",
    "        for key in result[\"invalid_keys\"]:\n",
    "            print(f\"- {key}\")\n",
    "    else:\n",
    "        print(\"\\nTodas as chaves são válidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_req = {\n",
    "        \"2012 - EMR CCHCS EA ISO HL7 IN 20120420_Attach8\" : [\"2012 - EMR CCHCS EA\", \"2012 - EMR CCHCS ISO\", \"2012 - EMR HL7 IN\"],\n",
    "        \"2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS_Attach9\" : [\"2012 - EMR CCHIT LT\", \"2012 - EMR HHS\", \"2012 - EMR HL7 DC\", \"2012 - EMR Pharmacy\"]\n",
    "        }\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista com 3 elementos.\n"
     ]
    }
   ],
   "source": [
    "if (n := len([1, 2, 3])) > 2:\n",
    "    print(f\"Lista com {n} elementos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "user_stories = [\n",
    "    {'id': '0-1-1-0.0', 'text': 'As a type of user 01-1.1, I want goal 01-1.1 so that reason 01-1.', 'type_of_user': 'a type of user 01-1.1', 'goal': 'goal 01-1.1', 'reason': 'reason 01-1', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-1-1.0', 'text': 'As a type of user 01-2.1, I want goal 01-2.1 so that reason 01-2.', 'type_of_user': 'a type of user 01-2.1', 'goal': 'goal 01-2.1', 'reason': 'reason 01-2', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-1-1.1', 'text': 'As a type of user 01-2.2, I want goal 01-2.2 so that reason 01-2.', 'type_of_user': 'a type of user 01-2.2', 'goal': 'goal 01-2.2', 'reason': 'reason 01-2', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-1-2.0', 'text': 'As a type of user 01-3.1, I want goal 01-3.1 so that reason 01-3.', 'type_of_user': 'a type of user 01-3.1', 'goal': 'goal 01-3.1', 'reason': 'reason 01-3', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-1-3.0', 'text': 'As a type of user 01-4.1, I want goal 01-4.1 so that reason 01-4.', 'type_of_user': 'a type of user 01-4.1', 'goal': 'goal 01-4.1', 'reason': 'reason 01-4', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-1-4.0', 'text': 'As a type of user 01-5.1, I want goal 01-5.1 so that reason 01-5.', 'type_of_user': 'a type of user 01-5.1', 'goal': 'goal 01-5.1', 'reason': 'reason 01-5', 'requirement_id': '0-1-1', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-2-0.0', 'text': 'As a type of user 02-1.1, I want goal 02-1.1 so that reason 02-1.', 'type_of_user': 'a type of user 02-1.1', 'goal': 'goal 02-1.1', 'reason': 'reason 02-1', 'requirement_id': '0-1-2', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-2-1.0', 'text': 'As a type of user 02-2.1, I want goal 02-2.1 so that reason 02-2.', 'type_of_user': 'a type of user 02-2.1', 'goal': 'goal 02-2.1', 'reason': 'reason 02-2', 'requirement_id': '0-1-2', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-2-2.0', 'text': 'As a type of user 02-3.1, I want goal 02-3.1 so that reason 02-3.', 'type_of_user': 'a type of user 02-3.1', 'goal': 'goal 02-3.1', 'reason': 'reason 02-3', 'requirement_id': '0-1-2', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-2-3.0', 'text': 'As a type of user 02-4.1, I want goal 02-4.1 so that reason 02-4.', 'type_of_user': 'a type of user 02-4.1', 'goal': 'goal 02-4.1', 'reason': 'reason 02-4', 'requirement_id': '0-1-2', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-1-2-4.0', 'text': 'As a type of user 02-5.1, I want goal 02-5.1 so that reason 02-5.', 'type_of_user': 'a type of user 02-5.1', 'goal': 'goal 02-5.1', 'reason': 'reason 02-5', 'requirement_id': '0-1-2', 'req_doc_id': '0', 'metadata_id': '0-1'},\n",
    "{'id': '0-2-1-0.0', 'text': 'As a type of user 03-1.1, I want goal 03-1.1 so that reason 03-1.', 'type_of_user': 'a type of user 03-1.1', 'goal': 'goal 03-1.1', 'reason': 'reason 03-1', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-2-1-1.0', 'text': 'As a type of user 03-2.1, I want goal 03-2.1 so that reason 03-2.', 'type_of_user': 'a type of user 03-2.1', 'goal': 'goal 03-2.1', 'reason': 'reason 03-2', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-2-1-1.1', 'text': 'As a type of user 03-2.2, I want goal 03-2.2 so that reason 03-2.', 'type_of_user': 'a type of user 03-2.2', 'goal': 'goal 03-2.2', 'reason': 'reason 03-2', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-2-1-2.0', 'text': 'As a type of user 03-3.1, I want goal 03-3.1 so that reason 03-3.', 'type_of_user': 'a type of user 03-3.1', 'goal': 'goal 03-3.1', 'reason': 'reason 03-3', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-2-1-3.0', 'text': 'As a type of user 03-4.1, I want goal 03-4.1 so that reason 03-4.', 'type_of_user': 'a type of user 03-4.1', 'goal': 'goal 03-4.1', 'reason': 'reason 03-4', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-2-1-4.0', 'text': 'As a type of user 03-5.1, I want goal 03-5.1 so that reason 03-5.', 'type_of_user': 'a type of user 03-5.1', 'goal': 'goal 03-5.1', 'reason': 'reason 03-5', 'requirement_id': '0-2-1', 'req_doc_id': '0', 'metadata_id': '0-2'},\n",
    "{'id': '0-3-1-0.0', 'text': 'As a type of user 04-1.1, I want goal 04-1.1 so that reason 04-1.', 'type_of_user': 'a type of user 04-1.1', 'goal': 'goal 04-1.1', 'reason': 'reason 04-1', 'requirement_id': '0-3-1', 'req_doc_id': '0', 'metadata_id': '0-3'},\n",
    "{'id': '0-3-1-1.0', 'text': 'As a type of user 04-2.1, I want goal 04-2.1 so that reason 04-2.', 'type_of_user': 'a type of user 04-2.1', 'goal': 'goal 04-2.1', 'reason': 'reason 04-2', 'requirement_id': '0-3-1', 'req_doc_id': '0', 'metadata_id': '0-3'},\n",
    "{'id': '0-3-1-2.0', 'text': 'As a type of user 04-3.1, I want goal 04-3.1 so that reason 04-3.', 'type_of_user': 'a type of user 04-3.1', 'goal': 'goal 04-3.1', 'reason': 'reason 04-3', 'requirement_id': '0-3-1', 'req_doc_id': '0', 'metadata_id': '0-3'},\n",
    "{'id': '0-3-1-3.0', 'text': 'As a type of user 04-4.1, I want goal 04-4.1 so that reason 04-4.', 'type_of_user': 'a type of user 04-4.1', 'goal': 'goal 04-4.1', 'reason': 'reason 04-4', 'requirement_id': '0-3-1', 'req_doc_id': '0', 'metadata_id': '0-3'},\n",
    "{'id': '0-3-1-4.0', 'text': 'As a type of user 04-5.1, I want goal 04-5.1 so that reason 04-5.', 'type_of_user': 'a type of user 04-5.1', 'goal': 'goal 04-5.1', 'reason': 'reason 04-5', 'requirement_id': '0-3-1', 'req_doc_id': '0', 'metadata_id': '0-3'},\n",
    "{'id': '1-1-1-0.0', 'text': 'As a type of user 11-1.1, I want goal 11-1.1 so that reason 11-1.', 'type_of_user': 'a type of user 11-1.1', 'goal': 'goal 11-1.1', 'reason': 'reason 11-1', 'requirement_id': '1-1-1', 'req_doc_id': '1', 'metadata_id': '1-1'},\n",
    "{'id': '1-1-1-1.0', 'text': 'As a type of user 11-2.1, I want goal 11-2.1 so that reason 11-2.', 'type_of_user': 'a type of user 11-2.1', 'goal': 'goal 11-2.1', 'reason': 'reason 11-2', 'requirement_id': '1-1-1', 'req_doc_id': '1', 'metadata_id': '1-1'},\n",
    "{'id': '1-1-1-2.0', 'text': 'As a type of user 11-3.1, I want goal 11-3.1 so that reason 11-3.', 'type_of_user': 'a type of user 11-3.1', 'goal': 'goal 11-3.1', 'reason': 'reason 11-3', 'requirement_id': '1-1-1', 'req_doc_id': '1', 'metadata_id': '1-1'},\n",
    "{'id': '1-1-1-3.0', 'text': 'As a type of user 11-4.1, I want goal 11-4.1 so that reason 11-4.', 'type_of_user': 'a type of user 11-4.1', 'goal': 'goal 11-4.1', 'reason': 'reason 11-4', 'requirement_id': '1-1-1', 'req_doc_id': '1', 'metadata_id': '1-1'},\n",
    "{'id': '1-1-1-4.0', 'text': 'As a type of user 11-5.1, I want goal 11-5.1 so that reason 11-5.', 'type_of_user': 'a type of user 11-5.1', 'goal': 'goal 11-5.1', 'reason': 'reason 11-5', 'requirement_id': '1-1-1', 'req_doc_id': '1', 'metadata_id': '1-1'},\n",
    "{'id': '1-2-1-0.0', 'text': 'As a type of user 12-1.1, I want goal 12-1.1 so that reason 12-1.', 'type_of_user': 'a type of user 12-1.1', 'goal': 'goal 12-1.1', 'reason': 'reason 12-1', 'requirement_id': '1-2-1', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-1-1.0', 'text': 'As a type of user 12-2.1, I want goal 12-2.1 so that reason 12-2.', 'type_of_user': 'a type of user 12-2.1', 'goal': 'goal 12-2.1', 'reason': 'reason 12-2', 'requirement_id': '1-2-1', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-1-2.0', 'text': 'As a type of user 12-3.1, I want goal 12-3.1 so that reason 12-3.', 'type_of_user': 'a type of user 12-3.1', 'goal': 'goal 12-3.1', 'reason': 'reason 12-3', 'requirement_id': '1-2-1', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-1-3.0', 'text': 'As a type of user 12-4.1, I want goal 12-4.1 so that reason 12-4.', 'type_of_user': 'a type of user 12-4.1', 'goal': 'goal 12-4.1', 'reason': 'reason 12-4', 'requirement_id': '1-2-1', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-1-4.0', 'text': 'As a type of user 12-5.1, I want goal 12-5.1 so that reason 12-5.', 'type_of_user': 'a type of user 12-5.1', 'goal': 'goal 12-5.1', 'reason': 'reason 12-5', 'requirement_id': '1-2-1', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-2-0.0', 'text': 'As a type of user 13-1.1, I want goal 13-1.1 so that reason 13-1.', 'type_of_user': 'a type of user 13-1.1', 'goal': 'goal 13-1.1', 'reason': 'reason 13-1', 'requirement_id': '1-2-2', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-2-1.0', 'text': 'As a type of user 13-2.1, I want goal 13-2.1 so that reason 13-2.', 'type_of_user': 'a type of user 13-2.1', 'goal': 'goal 13-2.1', 'reason': 'reason 13-2', 'requirement_id': '1-2-2', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-2-2.0', 'text': 'As a type of user 13-3.1, I want goal 13-3.1 so that reason 13-3.', 'type_of_user': 'a type of user 13-3.1', 'goal': 'goal 13-3.1', 'reason': 'reason 13-3', 'requirement_id': '1-2-2', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-2-3.0', 'text': 'As a type of user 13-4.1, I want goal 13-4.1 so that reason 13-4.', 'type_of_user': 'a type of user 13-4.1', 'goal': 'goal 13-4.1', 'reason': 'reason 13-4', 'requirement_id': '1-2-2', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2-2-4.0', 'text': 'As a type of user 13-5.1, I want goal 13-5.1 so that reason 13-5.', 'type_of_user': 'a type of user 13-5.1', 'goal': 'goal 13-5.1', 'reason': 'reason 13-5', 'requirement_id': '1-2-2', 'req_doc_id': '1', 'metadata_id': '1-2'},\n",
    "{'id': '1-2.2-1-0.0', 'text': 'As a type of user 14-1.1, I want goal 14-1.1 so that reason 14-1.', 'type_of_user': 'a type of user 14-1.1', 'goal': 'goal 14-1.1', 'reason': 'reason 14-1', 'requirement_id': '1-2.2-1', 'req_doc_id': '1', 'metadata_id': '1-2.2'},\n",
    "{'id': '1-2.2-1-1.0', 'text': 'As a type of user 14-2.1, I want goal 14-2.1 so that reason 14-2.', 'type_of_user': 'a type of user 14-2.1', 'goal': 'goal 14-2.1', 'reason': 'reason 14-2', 'requirement_id': '1-2.2-1', 'req_doc_id': '1', 'metadata_id': '1-2.2'},\n",
    "{'id': '1-2.2-1-2.0', 'text': 'As a type of user 14-3.1, I want goal 14-3.1 so that reason 14-3.', 'type_of_user': 'a type of user 14-3.1', 'goal': 'goal 14-3.1', 'reason': 'reason 14-3', 'requirement_id': '1-2.2-1', 'req_doc_id': '1', 'metadata_id': '1-2.2'},\n",
    "{'id': '1-2.2-1-3.0', 'text': 'As a type of user 14-4.1, I want goal 14-4.1 so that reason 14-4.', 'type_of_user': 'a type of user 14-4.1', 'goal': 'goal 14-4.1', 'reason': 'reason 14-4', 'requirement_id': '1-2.2-1', 'req_doc_id': '1', 'metadata_id': '1-2.2'},\n",
    "{'id': '1-2.2-1-4.0', 'text': 'As a type of user 14-5.1, I want goal 14-5.1 so that reason 14-5.', 'type_of_user': 'a type of user 14-5.1', 'goal': 'goal 14-5.1', 'reason': 'reason 14-5', 'requirement_id': '1-2.2-1', 'req_doc_id': '1', 'metadata_id': '1-2.2'},\n",
    "{'id': '1-3-1-0.0', 'text': 'As a type of user 15-1.1, I want goal 15-1.1 so that reason 15-1.', 'type_of_user': 'a type of user 15-1.1', 'goal': 'goal 15-1.1', 'reason': 'reason 15-1', 'requirement_id': '1-3-1', 'req_doc_id': '1', 'metadata_id': '1-3'},\n",
    "{'id': '1-3-1-1.0', 'text': 'As a type of user 15-2.1, I want goal 15-2.1 so that reason 15-2.', 'type_of_user': 'a type of user 15-2.1', 'goal': 'goal 15-2.1', 'reason': 'reason 15-2', 'requirement_id': '1-3-1', 'req_doc_id': '1', 'metadata_id': '1-3'},\n",
    "{'id': '1-3-1-2.0', 'text': 'As a type of user 15-3.1, I want goal 15-3.1 so that reason 15-3.', 'type_of_user': 'a type of user 15-3.1', 'goal': 'goal 15-3.1', 'reason': 'reason 15-3', 'requirement_id': '1-3-1', 'req_doc_id': '1', 'metadata_id': '1-3'},\n",
    "{'id': '1-3-1-3.0', 'text': 'As a type of user 15-4.1, I want goal 15-4.1 so that reason 15-4.', 'type_of_user': 'a type of user 15-4.1', 'goal': 'goal 15-4.1', 'reason': 'reason 15-4', 'requirement_id': '1-3-1', 'req_doc_id': '1', 'metadata_id': '1-3'},\n",
    "{'id': '1-3-1-4.0', 'text': 'As a type of user 15-5.1, I want goal 15-5.1 so that reason 15-5.', 'type_of_user': 'a type of user 15-5.1', 'goal': 'goal 15-5.1', 'reason': 'reason 15-5', 'requirement_id': '1-3-1', 'req_doc_id': '1', 'metadata_id': '1-3'}\n",
    "]\n",
    "print(len(user_stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expected_user_stories.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(\"expected_user_stories.json\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(user_stories, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "output_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         name   color\n",
      "0   1     blue sky    blue\n",
      "1   2    red heart     red\n",
      "2   3  green grass   green\n",
      "3   4   yellow sun  yellow\n",
      "4   5    black cat   black\n",
      "5   6   white snow   white\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class ink:\n",
    "    id: int\n",
    "    name: str\n",
    "    color: str\n",
    "\n",
    "ink_1 = ink(1, \"blue sky\", \"blue\")\n",
    "ink_2 = ink(2, \"red heart\", \"red\")\n",
    "ink_3 = ink(3, \"green grass\", \"green\")\n",
    "ink_4 = ink(4, \"yellow sun\", \"yellow\")\n",
    "ink_5 = ink(5, \"black cat\", \"black\")\n",
    "ink_6 = ink(6, \"white snow\", \"white\")\n",
    "\n",
    "inks = [ink_1, ink_2, ink_3, ink_4, ink_5, ink_6]\n",
    "inks_df = pd.DataFrame([asdict(ink) for ink in inks])\n",
    "\n",
    "print(inks_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
