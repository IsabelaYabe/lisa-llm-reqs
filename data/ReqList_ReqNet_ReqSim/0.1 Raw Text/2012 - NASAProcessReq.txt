
 
  
 
 
NASA NID to NPR 7123.1A 
Procedural Effective Date: March 13, 2012  
Requirements Expiration Date: March 12, 2013   
COMPLIANCE IS MANDATORY 
RESPONSIBLE OFFICE:  
Office of the Chief Engineer 
 
 
 
 
 
 
 
NASA Systems Engineering  
Processes and Requirements  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
DISTRIBUTION: 
NODIS 
 
 
This Document Is Uncontrolled When Printed.  
Check the NASA Online Directives Information System (NODIS) Library 
to verify that this is the correct version before use: http://nodis3.gsfc.nasa.gov  
 
  
1,'
135$
This Document Is Uncontrolled When Printed.  ii  
Table of Content s 
 
Preface  
P.1 Purpose  
P.2 Applicability and Scope  
P.3 Authority  
P.4 References  
P.5 Measurement/Verification  
P.6 Cancell ation  
Prologue  
Chapter 1. Introduction  
1.1 Background  
1.2 Framework for Systems Engineering Procedural Requirements  
1.3 Systems Engineering Management Plan  
1.4 Document Organization  
Chapter 2. Institutional and Programmatic Requirements  
2.1 Roles and Responsibilities  
2.2 Implementation Architecture  
2.3 Designated Governing Authority  
Chapter 3. Requirements for Common Technical Processes  
3.1 Introduction  
3.2 Process Requirements  
Chapter 4. NASA Oversight Activities on Contracted Projects  
4.1 Introduction  
4.2 Activities Prior to Contract Award  
4.3 During Contract Performance  
4.4 Contract Completion  
Chapter 5. Systems Engineering  Technical Reviews  
5.1 Life Cycle  
5.2 Technical Review Requirements  
5.3 Minimum Required Set of Technical  Reviews  
Chapte r 6. Systems Engineering Management Plan  
6.1 Systems Engineering Management Plan Function  
6.2 Roles and Responsibilities  
Appendix A. Definitions  
Appendix B. Acronyms  
Appendix C.  Practices for Common Technical Processes  
C.1 System Design Processes  
C.2 Product Realization Pr ocesses  
C.3 Technical Management Processes  
This Document Is Uncontrolled When Printed.  iii Appendix D. Systems Engineering Management Plan  
D.1 Purpose and Use  
D.2 Terms  Used  
D.3 SEMP Preparation  
D.4 SEMP Annotated Outline  
Appendix E. Hierarchy of Related NASA Documents  
Appendix F. Tailor ing 
Appendix G. Technical Review Entrance and Success Criteria  
G.1 Program/System Requirements Review  
G.2 Program /System Definition  Review  
G.3 Mission Concept Review  
G.4 System Requirements Review  
G.5 Mission Definition Review  
G.6 System Definition Review  
G.7 Preliminary Design Review  
G.8 Critical Design Review  
G.9 Production Readiness Review  
G.10  System Integration Review  
G.11  Test Readiness Review  
G.12  System Acceptance Review  
G.13  Operational Readiness Review  
G.14  Flight Readiness Review  
G.15  Post-Launch Assessment Review  
G.16  Critical Event Readiness Review  
G.17  Post-Flight Assessment Review  
G.18  Decommissioning Review  
G.19  Periodic Technical Review  
G.20  Technical Peer Reviews  
Appendix H. Templates  
H-1 Sample SE NPR Implementation Plan Temp late 
H-2 SE NPR Center Survey  
Appendix I. Reverences  
Appendix J. Index  
 
Table of Figures  
 
Figure 1 -1 – SE Framework  
Figure 2 -1 – Implementation Architecture  
Figure 3 -1 – SE Engine  
Figure 3 -2 – Application of SE Engine  Processes within System Structure  
Figure 5 -1 – The NASA Program Life Cycle  
Figure 5 -2 – The NASA Project Life Cycle  
Figure 5 -3 – Product Line Technical R eview Schedule  
This Document Is Uncontrolled When Printed.  iv Figure A -1 – Product -Based WBS Model Example  
Figure C -1 – Stakeholder Expectation Definition Process  
Figure C -2 – Technical Requirements De finition Process  
Figure C -3 – Logical Decomposition Process  
Figure C -4 – Design Solution Definition Process  
Figure C -5 –Sequencing of Product Realization Processes  
Figure C -6 – Product Implementation Process  
Figure C -7 – Product Integration Process  
Figure C -8 – Product Verification Process  
Figure C -9 – Product Validation Process  
Figure C -10 – Product Transition Process  
Figure C -11 – Technical Planning Process  
Figure C -12 – Requirements Management Process  
Figure C -13 – Interface Management Process  
Figure C -14 – Technical Risk Management Process  
Figure C -15 – Configuration Mana gement Process  
Figure C -16 – Technical Data Management Process  
Figure C -17 – Technical Assessment Process  
Figure C -18 – Decision Analysis Process  
Table of Tables  
 
Table G -1 – P/SRR Entrance and Success Criteria  
Table G -2 – P/SDR Entrance and Success Criteria  
Table  G-3 – MCR Entrance and Success Criteria  
Table G -4 – SRR Entrance and Success Criteria  
Table G -5 – MDR Entrance and Success Criteria  
Table G -6 – SDR Entra nce and Success Criteria  
Table G -7 – PDR Entrance and Success Criteria  
Table G -8 – CDR Entrance and Success Criteria  
Table G -9 – PRR Entrance and Success Criteria  
Table G -10 – SIR Entrance and Success Criteria  
Table G -11 – TRR Entrance and Success Criteria  
Table G -12 – SAR Entrance and Success Criteria  
Table G -13 – ORR Entrance and Success Criteria  
Table G -14 – FRR Entrance and Success Criteria  
Table G -15 – PLAR Entrance and Success Criteria  
Table G -16 – CERR Entrance and Success Criteria  
Table G -17 – PFAR Entrance and Success Criteria  
Table G -18 – DR Entrance and Success Criteria  
Table G -19 – Technology Readiness Levels  
 
 
 
 
This Document Is Uncontrolled When Printed.  1 
 Preface  
P.1 Purpose  
The purpose  of this document  is to clearly articulate and establish  the requiremen ts on the 
implementing org anization  for performing, supporting , and evaluating systems  engineering . 
Systems engineering  is a logical systems approach  performed by mu ltidisciplin ary teams  to 
engineer and integrate  NASA’s systems  to ensure NASA products  meet customers’ needs . 
Implementation  of this systems approach will enhance NASA’s core engineering, management, 
and scientific capabilities  and processes  to ensure safety  and mission  success, increase 
performance, and reduce  cost. This systems approach is applied to all elements  of a system  and 
all hierarchical levels of a system o ver the complete project  life cycle .  
P.2 Applicability  
a. In this directive, all document citations are assumed to be the latest version, unless otherwise 
noted. This NASA Procedural Requirement  (NPR ) applies  to NASA Headquarters  and 
NASA Centers , including component facilities  and technica l and service support centers. It 
also applies to the Jet Propulsion Laboratory  to the extent specified in its contracts with 
NASA.  This NPR applies to NASA employees and their service contractors  that use NASA 
processes  to augment and support NASA technical work . NASA NPRs and this Systems  
Engineering  NPR ( SE NPR ) do not apply to NASA contracts except as the NASA technical 
team  flows down the systems engineering  responsibilities  to all members of the system team , 
including  contractors and subcontractors.  (See Chapter  4.) 
b. The scope  of this document  encompasses the common technical processes  for large and small 
projects  and activities  in flight systems  and ground support  (FS&GS ) projects, advanced 
technology development  (ATD ) projects with deliverables  to FS&GS projects, information 
systems  and technology projects, and institutional project s (IP). Application of this NPR  to 
Construction of Facilities  (CoF) and Environmental Compliance and Restoration  (ECR ) 
projects (or portions thereof) should be scaled in accordance with the level of systems  
engineering  for the function of the structure  and documented in the systems engineering 
management plan  (SEMP ) (as required).  In this sen se, the design  of facilities  (or parts of 
facilities ) for processing FS&GS activities would require appropriate application  of systems 
engineering  effort, ensuring that interfaces with and functional requirements of the FS&GS 
systems engineering are addressed. The design of administrative facilities or soil remediation 
projects may not require the application  of specific systems engineering efforts. Engineering 
requirements for CoF and ECR projects are specified in NPR 8820.2 and NPR 8590.1, 
respectively.  Applying the common technical processes and reviews  may also benefit basic 
and applied res earch  (BAR ) and other ATD projects. They are recommended but not required 
for BAR and ATD projects.  
c. In this document , the word ―project ‖ generally refers to a unit of work  performed in 
programs , projects, and activities . Management of a work unit is referred to as ―project 
management ,‖ which includes managing programs, projects , and activities.  A project is: (1) 
A specific investment having defined  goals , objectives, requirements , life-cycle  cost, a 
beginning, and an end. A project yields new  or revised products  or services that directly 
address NASA’s strategic needs. Projects may be performed wholly in -house; by 
Government, industry, academia partnerships ; or through contracts with private industry.   
This Document Is Uncontrolled When Printed.  2 (2) A unit of work performed in programs, projects, and activities.  Requirements for 
technical work on projects, therefore, also apply  to technical work performed on programs.  
d. The requirements  enumerated in this document  are applicable to all new programs  and 
projects , as well as to all programs and projects currently in Formulation  phase as of the 
effective date of this document. (See NPR  7120.5  for definitions of program phases.) This 
NPR also applies  to programs and p rojects in their Implementation  phase as of the effe ctive 
date of this document . However, the  technical team may request permission from the 
designated governing authority  to be allowed to continue without complying  with all or 
sections of this NPR.  
e. Many other discipline areas  such as safety , medical, reliability, maintainability, quality 
assurance, information technology , security, logistics , environmental, etc., perfo rm functions 
during project  life-cycle  phases  that influence or are influenced by the engineering  functions  
performed  and need to be fully integrated  with the engineering functions . The description of 
these disciplines and their relationship to the overall management life  cycle are defined  in 
other NASA directives ; for example , the safety, medical, reliability, maintainability, and 
quality assurance requirement s are defined in the 8700  series of directives.  
P.3 Authority  
a. National Aeronautics and Space Act, as amended, 51 U.S.C. § 20113(a).  
b. NPD  1000 .0, NASA Governance and Strategic Handbook . 
c. NPD  1000.3, The NASA Organization . 
d. NPD 1001.0, NASA Strategic Plan . 
e. NPD  7120.4, NASA Engineering and Program/Project Management Policy . 
P.4      Applicable Documents and Forms  
a. NPD  1440.6, NASA Records Manag ement.  
b. NPD  2820.1, NASA Software  Policy . 
c. NPD  8700 .1, NASA Policy  for Safety and Mission Success . 
d. NPR  1080.1 , Requirements for the Conduct of NASA Research and Technology (R&T) . 
e. NPR  1441.1, NASA Records Retention Schedules . 
f. NPR  1800.1, NASA Occupational Health Program  Procedures.  
g. NPR  7120.5, NASA Space Flight Program and Project Management Requirements.  
h. NPR  7150.2, NASA Software  Engineerin g Requirements . 
i. NPR  8000.4, Agency Risk Management Procedural Requirements . 
j. NPR 8590.1, Environmental Compliance and Restoration Program .  
k. NPR  8820.2 , Facility Project  Requirements . 
l. SP-6105, NASA Systems  Engineering  Handbook . 
This Document Is Uncontrolled When Printed.  3 P.5 Measurement/Verification  
Compliance  with this NPR  will be documented by Center  Directors  in the SE NPR  
Implementation  Plan, which reports  how the particular Center will assess  compliance to the SE 
NPR. In addition, the Office of the Chief Engineer ( OCE ) conducts periodic assessments at the 
Centers to obtain feedback on the effectiveness of the SE NPR to facilitate updating the NPR.  
P.6 Cancellation  
NPR  7123.1, NASA Systems  Engineering  Processes  and Requirements, dated March 13, 2006, is 
cancelled on the effective date of NPR 7 123.1A . 
 
 
 
 
Michael Ryschkewitsch  
Chief Engineer  
 
 
DISTRIBUTION:  
NODIS  
This Document Is Uncontrolled When Printed.  4 Prologue  
a. NASA missions  are becoming increasingly complex, and the challenge of engineering  
systems  to meet the cost , schedule , and performance requirement s within acceptable levels of 
risk requires revitalizing  systems engineering . Functional and physical interfaces  are 
expanding in number and complexity . Software  and embedded hardware must be integrated  
with platforms of varying complexity. Pre -planned project  development  and the extension of 
system applications drive higher levels of integration.  A driver of increasing system 
complexity is the significant reduction of operations  staff to reduce life-cycle  cost and 
incorporation of their workload into the system.  In addition, systems are moving toward 
increased autonomy  with stored knowledge, data gathering, intra - and inter -system 
communications, and decision -making ca pabilities . 
b. The e ngineering  of NASA  systems  requires the application  of a systematic, disciplined 
engineering approach  that is  quantifiable, recursive, iterative, and repeatable  for the 
development , operation, maintenance , and disposal  of systems integrated  into a whole 
throughout the life cycle  of a project  or program . The emphasis of systems engineering  is on 
safely  achieving stakeholder  functional, physical, and operational performance requirement s 
in the intended use environments  over the system’s planned life within cost  and schedule  
constraints . 
c. While rising to the greater challenge, NASA must also address concerns over past failures. 
The need for this SE NPR  was driven both by past experience and evolving NASA program  
requirements . Drawing on the  result of reports and findings, the OCE  initiated a revitalization 
of engineering  to provide for future missions . This NPR  satisfies the component of the 
revitalization that calls for Agency -level requirements  to establish  standard technical 
practices  for systems  engineering . 
d. The vision for systems  engineering  is to ―develop and implement  a framework  and promote 
the environment  for excellence and the revolutionary advancement of systems engineering  
capability  to anticipate and meet the needs of NASA programs  and proj ects.‖1 A robust 
approach  is required to meet the Agency ’s objectives.  Achieving the goal  requires systems -
level thinking on the part of all project participants to accomplish the engineering o f NASA 
systems.  
e. This transformation is necessary to provide consistency across the Agency  and advance the 
practice in NASA. This SE NPR  will then be applicable to no t just the discipline of systems  
engineering , but the technical teams  that perform the activities  to engineer the missions  for 
the Agen cy.  
f. This document  establishes the common technical processes  for implementing NASA 
products  and systems , as directed by NPD  7120.4, Program/Project Management . 
Additionally, t his NPR  establishes the common NASA systems engineering  technical model  
and presents tailoring  and waiver  guidelines . This document complements the administration, 
                                                 
1J.A. Moody, W.L. Chapman, F.D. Van Voorhees, A.T. Bahill , Metrics  and Case Studies for Evaluating 
Engineering  Designs,  (Upper Saddle River, NJ: Prentice Hall, 1997).  
This Document Is Uncontrolled When Printed.  5 management, and review  of all programs and projects , as specified in NPR 7120.5, NASA 
Space Flight Program and Project Management Requir ement s. 
This Document Is Uncontrolled When Printed.  6 Chapter 1.  Introduction  
1.1 Background  
1.1.1 Systems  engineering  at NASA  requires the application  of a systematic, disciplined 
engineering approach  that is quantifiable, recu rsive, iterative, and repeatable  for the 
development , operation, maintenance , and disposal  of systems integrated  into a whole 
throughout the life cycle  of a project  or program . The emphasis of systems engineering  is on 
safely  achieving stakeholder  functional, physical, a nd operational performance requirement s in 
the intended use environments  over the system’s planned life within cost  and schedule  
constraints . 
1.1.2 This NPR  establishes a core set of common Agency -level technical processes  and 
requirements needed to define , develop, realize , and integrate  the quality of the system  products  
created and acquired by or for NASA. The processes described in this document  build upon and 
apply best practices  and lessons learned from NASA, other governmental agencies, and industry 
to clearly delineate a successful model  to complet e comprehensive technical work , reduc e 
program  and tec hnical risk, and  improv e mission  success. The  set of common processes in this 
NPR may be supplemented and tailored  to achieve specific project  requirements. (See Appendix 
F. Tailoring.)  
1.1.3 Under the lean gove rnance of the updated NPD  1000.0 , the relationship of the 
program/project management  and the technical team  was clarified to reflect new technical 
authority . The program/project manager (PM ) has overall responsibility for their 
program/project. The technical team works with and for the PM to accomplish the goals  of the 
project. Due to this updated governance, there is a need to clearly define  the role of the sy stems  
engineering  management plan  (SEMP) and how it will be developed. The technical team, 
working under the overall program management plan  (PMP), develops and updates the SEMP as 
necessary. The technical team works with the PM to review  the content and obtain concurrence. 
This allows for thorough discussion and coordination of how the proposed technical activities  
would impact the programmatic, cost , and schedule  aspects of the project. However, in cases of 
pure technical issues and for approval  of requested waiv ers to technical requirements , the 
technical team also has an independent route through the technical designated governing 
authority  (DGA ) (as described in Section 2.3)  to resolve  issues with program/project 
management. Once all issues are resolved, the PM signs the SEMP. It then goes to the DGA for 
final signature. The DGA signature assures that an independent review has evaluated the 
technical aspect s of the technical plans and allows for approval of technical waivers or tailoring  
of the requirements of this NPR  and other relevant technical standards  that pertain to this NPR . 
1.1.4 Precedence  
The order of precedence in case of conflict  between requirements  is 42 U.S.C. 2473(c)(1), 
Section 203(c)(1), National Aeronautics and Space Act of 1958, as amended ; NPD  1000.0 , 
Strategic Management & Governance Handbook ; NPD 1000.3, The NASA Organization ; NPD 
7120.4, Program/Project Management ; and NPR  7123 .1, NASA Systems  Engineering  Processes  
and Requirements.  
 
This Document Is Uncontrolled When Printed.  7 1.1.5 Requirement  Verbs  
In this NPR , a requirement is identified by ―shall ,‖ a good practice by ―should, ‖ permission by 
―may‖ or ―can,‖ expected outcome or action by ―will,‖ and descriptive material by ―is‖ or ―are‖ 
(or another verb form of ―to be ‖). 
1.1.6 Figures  
Figures  within this NPR  are not intended to be prescriptive but notional . 
1.2 Framework  for Systems  Engineering  Procedural Requirements  
There are three major groupings of requirements  within the Office of the Chief Engineer  (OCE ), 
i.e., program management requirements , systems  engineering  requirements , and independent 
review . This NPR  focuses on the systems engineering  requirements . (See Appendix E for the 
hierarchy of related documents .) 
1.2.1 Systems  Engineering  Framework  
1.2.1.1  The common systems  engineering  framework  consists of three elements that make up 
NASA systems engineering  capability . The relationship of the three elements is illustrated in 
Figure  1-1. The integrated  implementation  of the three elements of the SE Framework is 
intended to improve the overall capability required for the efficient and effective engineering of 
NASA systems. The SE processes  are one element of the larger context to produce quality 
products  and achieve miss ion success. This NPR  addresses the SE processes. The larger SE 
framework also includes the workforce  and tools  and methods . OCE  initiatives to address these 
other elements include revision of the NASA handbook  on systems engineering and development  
of tools and an assessment  model . Together, these elements comprise  the capability of an 
organization  to perform successful SE. Each element is described below .  
 
Figure  1-1 – SE Framework  
1.2.1.2  Element 1: Common Technical Processes . The common technical processes  of this 
NPR  provide what has to be done to engineer system  products  within a project  and why. These 
processes are applied to the hardware, software , and human parts of a system as one integrated  
whole. Within this NPR, the contribution of this element to improvement of SE  capability  is 
made not only by the common set of technical processes but also by inclusion of:  
a. Concepts and terminology that are basic to consistent application  and communication of the 
comm on technical processes  Agency -wide.  
b. A structure  for when the common technical processes  are applied.  
1.2.1.3  Element 2:  Tools  and Methods . Tools and m ethods enable the efficient and effective 
completion of the activities  and tasks  of the common technical processes . An essential 
contribu tion of  this element to SE  capability  is the improvement of the engineering  infrastructure 
through the three  Agency -wide initiatives listed below.  
This Document Is Uncontrolled When Printed.  8 a. Infusion of advanc ed methods  and tools  in the SE processes  to achieve greater efficiency, 
collaboration , and communication among distributed teams . 
b. Preparation of a NASA handbook  on SE methodologies intended to provide a source for 
various methods  and procedures that Centers can draw upon to plan implementation  of the 
required processes  in their projects . This will be an update of the current NASA Systems  
Engineering  Handbook (SP -6105)  that will be aligned with NPR  7120.5 and the SE NPR . 
c. Creation or adoption of an assessment  model  to measure the SE capability  of projects  within 
NASA and to assess the improvements  of capability resulting from implementation  of the SE 
NPR , use of adopted methods  and tools , and workforce  engineering  training.  
1.2.1.4  Element 3:  Workforce . A well -trained , knowledgeable , and experienced  technical 
workforce  is essential for improving SE  capability . The workforce must be able to app ly NASA 
and Center  standardized methods  and tools  for the completion of the required SE processes  
within the context of the program  or proj ect to which they are assigned. In addition, they must be 
able to effectively communicate requirements  and solutions to customers, other engineers , and 
management to work  efficiently and effectively on a t eam. Issues of recruitment, retention , and 
training are aspects included in this element. The OCE  will facilitate the training of the NASA 
workforce on the application  of this a nd associated NPRs.  
1.2.1.5  SE Capability . Together, the three elements of Figure  1-1 comprise an Agency -wide 
capability to perform successful SE in the engineering  of NASA system  products .  
1.3 Systems  Engineering  Management Plan  
A Systems  Engineering  Management Plan  (SEMP) is used to establish  the technical content of 
the engineering  work  early i n the Formulation  phase for each project  and updated throughout the 
project life cycle . The SEMP provides the specifics of the technical effort and describes what 
technical processes  will be used,  how the processes will be applied using appropriate activities , 
how the project will be organized to accomplish the activities, and the cost  and schedule  
associated with accomplishing the activities. The process activities are driven by the critical or 
key events during any phase of a life cycle (including operations ) that set the objectives and 
work product  outputs of the processes and how the processes are integrated . (See Chapter  6 for a 
description of the SEMP and Appendix D for an annotated outline for the SEMP. ) The SEMP 
provides the communication bridge between the project management  team  and the technical 
implementation  teams  and within technical team s. The SEMP  provides the framework  to realize 
the appropriate work products that meet the entry and exit criteria  of the applicable project life-
cycle  phases  and provide s management with necessary information for making decision s.  
1.4 Document  Organization  
This SE NPR  is organized into the following chapters .  
a. The Preface  describes items such as the applicability, scope , authority , and references of this 
SE NPR . 
b. The Prologue describes the purpose  and vision for this SE NPR . 
c. Chapter  1 describes  the SE framework  and introduces the SEMP . 
This Document Is Uncontrolled When Printed.  9 d. Chapter  2 describe s the institu tional and programmatic requirements , includ ing roles  and 
responsibilities .  
e. Chapter  3 describ es the core set of common Agency -level technical processes  and 
requirements  for engineering  NASA system  products  throughout the product life cycle . 
Appendix C contains supplemental amp lifying material.  
f. Chapter  4 describ es the activities  and requirements  to be accomplished by assigned NASA 
technical teams  or individuals (NASA employees and their service support contra ctors ) when 
performing technical oversight  of a prime or external contractor .  
g. Chapter  5 describes the technical review  requirement s throughout the  program and project 
life cycles. 
h. Chapter  6 describes  the SEMP , including the SEMP role, functio ns, and content. Appendix D 
provides details of a generic SEMP annotated outline .
This Document Is Uncontrolled When Printed.  10  
Chapter 2.  Institutional and Programmatic Requirements  
2.1 Roles  and Responsibilities  
2.1.1 General  
2.1.1.1  The roles  and respon sibilities  of senior management are defined  in part in NPD  1000.0 , 
Strat egic Management & Governance Handbook . NPR  7120.5, NASA Space Flight Program and 
Project Management Requirement s; NPD 7120.4, Program/Project Management ; and other 
NASA directives define the responsibilities of program and project managers. This NPR  
establishes systems  engineering  processes a nd responsibilities .  
2.1.1.2  The OCE , under the authority  of this SE NPR , shall  ensure co mpliance  with this SE 
NPR .   
2.1.1.3  For programs  and projects  involving more than one Center , the lead organization  shall  
develop documentation to describe the hierarchy and reconciliation of Center plans 
implementing this NPR . The governing mission  directorate determines whether a Center 
executes a project in a lead role or in a peer role . For Centers in peer roles , compliance  should be 
jointly negotiated.  
2.1.1.4  For s ystems  that contain software , the technical team  shall  ensure that software 
developed within NASA or acquired complies with NPR  7150.2, NASA Software Engineering 
Requirements. Note that NPR 7150.2 elaborates on the requirements in this document  and 
determines the applicability of requirements based on the Agen cy's software classification. Also 
note that NPR 7150.2 contains additional Agency requirements for the acquisition, development , 
maintenance , and management of software.  
2.1.1.5  The OCE  shall  be the clearinghouse  for systems  engineering  policies to ensure 
compatibility  across NASA. In the event of  differences be tween program  or project  offices and 
the OCE staff, the conflict  will ultimately reach the NASA Chief Engineer  or mission  director 
level. If agreement  is not achieved at t his level, the conflict will be brought to the NASA 
Administrator for resolution . 
2.1.1.6  In this document , the phrase ―the Center  Directors  shall …‖ means  the roles  and 
responsibilities  of the Center Directors  may be further delegated within the organization  as 
appropriate to the scope  and scale of the system . 
2.1.2 Center  Directors  
2.1.2.1  Center  Directors  oversee and manage the infrastructure for the s uccessf ul execution of 
technical autho rity, support, and assurance of all programs  and projects .  
This Document Is Uncontrolled When Printed.  11 2.1.2.2  Center  Directors  shall  perform the following activities  or delegate them to the 
appropriate Center organization :  
a. Develop the SE NPR  Implementation  Plan per the template  in Appendix H-1 describing how 
the requirements  of this SE NPR  will be applied to the programs  and projects  under their 
cognizance or authority . 
b. Establish policies, procedures, and processes  to execut e the requirements  of this SE NPR . 
c. Assess and take corrective actions to improve the execution of the requirements  of this SE 
NPR . 
d. Perform the SE NPR  Center  Survey  in accordance with Appendix H -2 for the purpose  of 
providing feedback on the SE NPR . The initial Center Survey will be submitted  five months 
from the effectiv e date of this SE NPR . Subsequent updates will be upon the request of the 
OCE , no earlier than nine months after the initial submission. The Center Survey will use the 
common survey tool  in Appendix H -2 and will be submitted through the Center System 
Engineering Working Group  (SEWG ) representative.  
e. Select appropriate standards applicable to projects  under their control . 
2.1.3 Technical Team s 
Each technical team shall  execute the Center  processes  intended to implement  this SE NPR  
under the oversight  of the Center Director s in accordance with the SEMP . The makeup and 
organiza tion of each technical  team is the responsibility of each Center or program  and include s 
the personnel required to implement the project .  
2.2 Implementation  Architecture  
2.2.1 Implementation  Plan  
2.2.1.1  Figure  2-1 illustrate s the engineering  implementation  flow and key documents . NPD  
7120.4 establishes the policy for engineering and prog ram and project  management  for the 
Agency . From that directi ve, the OCE  develop ed and publish ed this  SE NPR , which  is consistent 
and comple mentary to NPR  7120.5 and other pertinent Agency directi ves. The requirements 
established in th is SE NPR will flow  down to the implementing organizations a nd Center s.  
2.2.1.2  The Center  Directors  shall submit their SE NPR  Implementation  Plan to the OCE  
within three months after the effective date of this NPR . The plan will be updated as required. 
The SE NPR Implementation Plan will be provided to mission  directorates for review  and 
comment. Each SE NPR Implementation Plan  will be  approved  by the OCE and include the 
applicable documents employed by the individual Centers. These Center documents may include 
Center procedural requirement s, work  instructions, standards, and rules, as well as other Center -
unique documentation. The SE NPR is a requi rements document that specifies what needs to  be 
accomplished at an Agency  level. There will also be a body of knowledge developed to assist in 
the implementation of the NPR. This body of knowledge will include an updated NASA Systems  
Engineering  Handbook  (SP-6105 ) as well as best practices , standards , and templates.  
This Document Is Uncontrolled When Printed.  12 2.2.1.3  The Center  Director s shall develop and document  in the SE NPR  Implementation  Plan 
how the particular Center will assess  compliance  to the SE NPR  and provide regular updates to 
the OCE . In addition, the OCE will conduct periodic updates at the Centers to obtain feedback on 
the effectiveness of the SE NPR to facilitate updat ing the NPR.  
 
Figure  2-1 – Implementation  Architecture  
2.3 Designated Governing Authority  
The designated governing authority  (DGA ) for the technical effort in this SE NPR  is the Center  
Director  or the person or organization  that has been design ated by them t o ensu re the appropriat e 
level of technical management oversight . The DGA is assigned primary responsibility for  
evaluating the technical content of a particular program  or project  to ensure that it is meeting the 
commitments specified in the key managemen t documents . Typically , the DGA is the final 
approval  signature on the System s Engineering  Management Plan s, waiver  authorizations , and 
other key technical documents.  While overall management of the project SEMPs, technical 
review s, and similar project -specific SE products  and reviews  is the responsibility of the 
program/project manager , who  is expected to sign the documents, the DGA has the final 
approval signature to ensure independent assessment  of technical content and waiver 
authorizations that pertain to this NPR . 

This Document Is Uncontrolled When Printed.  13 2.3.1 Tailoring  and Waivers  
2.3.1.1  The appropriate DGA  shall  have responsibility to approve or disapprove any SE NPR  
requirement  that is either tailored  or waived . Approved tailoring  or waivering will be 
documented in the SEMP , as per the directions provided in appendic es D and F .  
2.3.1.2  The amount of detail, formality , and rigor require d for the implement ation  of this SE 
NPR ’s requirements  is tailorable base d on the size and complexity  of each project  and acceptable 
risk, subject to approval  by the project manager  and the  DGA . Critical project  considerations  
(e.g., public safety , security, litigation exposures) may preclude tailoring out required process 
activities , regardless of cost , manpower available , or other considerations .  
2.3.1.3  A waiver  is a documented agreement  intentionally releasing a program  or project  from 
meeting a requirement . Waivers are required to release a program or project from meeting a 
requirement in the execution of the processes  described in this SE NPR . 
This Document Is Uncontrolled When Printed.  14 Chapter 3.  Requirements  for Common Technical Processes   
3.1 Introduction  
3.1.1 This chapter  establishes the core set of common technical processes  and requirements  to 
be used by NASA projects  in engineering  system  products  during applicable product -line life-
cycle  phases  (see Figure  5-3) to meet phase  exit criteria  and project objectives. The 17 common 
technical processes are enumerated according to their description in this chapter and their 
interactions shown in Figure 3 -1. This SE  common technical processes model  illustrates the use 
of: (1) the system design  processes for ―top down‖ design of each product in the system 
structure , (2) the product realization processes for ―bottom up‖ realization of each product in the 
system structure, and (3) the technical management processes for planning, assessing, and 
controlling the implementation  of the syste m design and product realization processes and to 
guide technical decision  making  (decision analysis ). The SE common technical processes model 
is referred to as an ―SE engine ‖ in this SE NPR  to stress that these common technical processes 
are used to drive the development  of the system products and associated work  products required 
by ma nagement to satisfy the applicable product -line life-cycle  phase exit criteria  while meeting 
stakeholder  expectations  within cost , schedule , and risk constraints .   
 
Figure  3-1 – SE Engine  
This Document Is Uncontrolled When Printed.  15 3.1.2 The context in which the common technical processes  are used is provided be low. 
3.1.2.1  The common technical processes  are applied to a product -based Work  Breakdown 
Structure  (WBS ) model  to concurrently develop the products that will satisfy the operational or 
mission  functions of the system  (end product s) and that will satisfy the life-cycle  support 
functions of the system (enabling product s). The enabling products facilitate the activities  of 
system design , product realization, operations  and mission support, sustainment , and end -of-
product -life disposal  or recycling by having the products and services available when needed.  
3.1.2.2  The common technical processes  are applied to design  a system  solution definition  for 
each WBS  model  down and across each level of the system structure  and to realize the WBS 
model end product s up and across the system structure. Figure  3-2 illustrates how the three major 
sets of processes of the SE  Engine  (system design processes, product realization processes , and 
technical management processes) are applied to a WBS model within a system structure (a 
hierarchy of product -based WBS models).  
 
Figure  3-2 – Application of SE  Engine  Processes  within System  Structure  

This Document Is Uncontrolled When Printed.  16 3.1.2.3  The common technical processes  are used to define  the WBS  models of the system  
structure  in each applicable phase  of the relevant product -line life cycle  (see Figure  5-3) to 
generate work  products and system products needed to satisfy the exit criteria  of the applicable 
phase. System engineering  continues well into the operations  and maintenance  phase of a 
project , i.e., after the system products are delivered. For example, in the course of operating, 
maintaining, and dispo sing of an existing system, all upgrades, enhancements, supporting or 
enabling developments, and reconfigurations must apply the common SE  technical processes.   
3.1.2.4  The common technical processes  are applied by assigned technical teams  and 
individuals of the NASA workforce  trained in the requirements  of this SE NPR .  
3.1.2.5  The assigned technical teams  and individuals should use the appropriate and available 
sets of tools  and methods  to accomplish required common technical process a ctivities . This 
would include the use of modeling  and simulation  as applicable to the product -line phase , 
location of the WBS  model  in the system  structure , and the applicable phase exit criteria .  
3.1.3  The assigned technical teams  shall  define in the project  SEMP  how the required  17 
common technical  processes , as implemented by Center  documentation, will be applied to the 
various levels of  project  WBS  model  system  structure  during each appl icable life-cycle  phase  
and have their approach  approved  by the DGA . 
3.2 Process Requirements  
For the statements  below ―establish ‖ means developing policy, work  instructions, or procedures 
to implement  process activities . ―Maintain‖ includes planning the p rocess, providing resources, 
assigning responsibilities , training  people, managing  configurations, identifying  and involving 
stakeholders, and monitoring and controlling th e process.  
3.2.1 Stakeholder  Expectations  Definition  Process  
3.2.1.1  The Center  Directors  or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation , for the definition of stakeholder  
expectations  for the applicable WBS  model .  
3.2.1.2  The stakeholder  expectations  definition  process  is used to elicit and define use cases, 
scenarios, operational concepts, and stakeholder expectations for the applicable product -line life-
cycle  phases  and WBS  model . This includes requirements  for: (a) operational end product s and 
life-cycle -enabling product s of the WBS model ; (b) expected skills  and capabilities of operators 
or users; (c) expected number of simultaneous users, (d) system  and human performance criteria , 
(e) technical authority , standards, regulations , and laws; ( f) factors such as safety , quality, 
security, context of use by humans, reliability , availability, maintainability, electromagnetic 
compatibility , interoperability , testability, transportability, supportability , usability,  and 
disposability; and ( g) local management constraints  on how work  will be done (e.g., operating 
procedures). The baselined  stakeholder expectations are used for validation  of the WBS model 
end product during product realization.  
3.2.1.3  Typical practices  of this process are defined  in Appendix C.1.1.  
This Document Is Uncontrolled When Printed.  17 3.2.2 Technical Requirements  Definition  Process  
3.2.2.1  The Center  Director s or designees  shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for definition of the technical 
requirements from the set of agreed upon  stakeholder  expectations  for the applicable WBS  
model .  
3.2.2.2  The technical requirements  definition  process  is used to transform the ba selined  
stakeholder  expectations  into unique, quantitative, and measurable technical requirements 
expressed as ―shall‖  statements that can be used for defining a design  solution  for the WBS  
model  end product  and related enabling product s.  
3.2.2.3  Typical practices  of this process are defined  in Appendix C.1.2.  
3.2.3 Logical Decomposition  Process  
3.2.3.1  The Center  Director s or designees  shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and docum entation, for logical decomposition  of the 
validated technical requirements of the applicable WBS  model .  
3.2.3.2  The logical decomposition  process is used to improve understanding of the defined  
technical requirements  and the relationships among the requirements (e.g., functional, 
behavioral, and temporal) and to transform the defined set  of technical requirements into a set of 
logical decomposition models and their associated set of derived technical requirements for input  
to the design  solution  definition process . 
3.2.3.3  Typical practices  of this process are defined  in Appendix C.1.3.  
3.2.4 Design  Solution  Definition  Process  
3.2.4.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for designing product  solution 
definitions within the applicable WBS  model that satisfy the derived technical requirements.  
3.2.4.2  The design  solution  definition  process  is used to translate the outputs  of the logical 
decomposition  process into a design solution definiti on that is in a form consistent with the 
product -line life-cycle  phase  and WBS  model  location in the system  structure  and that will 
satisfy phase exit criteria . This includes transforming the defined logical decomposition models 
and their associated sets of derived technical requirements  into alternative solutions , then 
analyzing each alternative to be able to select a preferred alternative , and fully defin ing that 
alternative into a final design solution definition that will satisfy the technical requirements. 
These design solution definitions will be used for generating end product s either by using the 
product implementation  process or product integration process  as a function of the position of the 
WBS model in the system structure and whether there are additional subsystems of the end 
product that need to be defined. The output definitions from the design solution (end product 
specifications ) will be used for conducting product verification .  
3.2.4.3  Typical practices  of this process are defined  in Appendix C.1.4.  
This Document Is Uncontrolled When Printed.  18 3.2.5 Product Implementation  Process  
3.2.5.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for implementation  of a design  solution  
definition by making, buying , or reusing an end product  of the applicable WBS  model .  
3.2.5.2  The product  implementation  process is used to generate a specified product of a WBS  
model  through buying, making , or reusing in a form consistent with the product -line life-cycle  
phase  exit criteria  and that s atisfies the design  solution  definition  specified requirements  (e.g., 
drawings, specifications ). 
3.2.5.3  Typical practices  of this process are defined  in Appendix C.2.1  
3.2.6 Product Integration  Process  
3.2.6.1  The Center  Director s or designees shall  establish  and maintain a process to include 
activities , requirements , guidelines , and documentation for the integration  of lower  level 
products  into an end product  of the applicable WBS  model  in accordance with its design  solution  
definition.  
3.2.6.2  The product  integration process  is used to transform the design  solution  definition  into 
the desired end product  of the WBS  model  through as sembly and integration of lower level , 
validated end products  in a form consistent with the produc t-line life-cycle  phase  exit criteria  and 
that satisfies the design solution definition requirements  (e.g., drawings, specifications ).  
3.2.6.3  Typical practices  of this process are defined  in Appendix C.2.2.  
3.2.7 Product Verification Process  
3.2.7.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for verification  of end product s 
generated by the product implementation  process or product integration process  against their 
design  solution  definitions.  
3.2.7.2  The product  verification  process is used to demonstrate that an end product  generated 
from product implementation  or product integratio n conforms to its design  solution  definition  
requirements  as a function of the product -line life-cycle  phase  and the locat ion of the WBS  
model  end product in the system  structure . Special attention is given to demonstrating 
satisfaction  of the measures of performance (MOPs) defined for each measure of effectiveness  
(MOE s) during conduct of the technical requirements definition process .  
3.2.7.3  Typical practi ces of this process are defined  in Appendix C.2.3.  
3.2.8 Product Validation  Process  
3.2.8.1  The Center  Director s or designees  shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for validation  of end product s generated 
This Document Is Uncontrolled When Printed.  19 by the product implementation  process or product integration process  against their stakeholder  
expectations .  
3.2.8.2  The product  validation  process is used to confirm that a verified end product  generated 
by product implementation  or pro duct integration  fulfills (satisfies) its intended use when placed 
in its intended environment  and to ensure that any anomalies discovered during validation are 
appropriately resolved prior to delivery of the product  (if validation is done by the supplier of the 
product) or prior to integration with other products into a higher -level assembled product (if 
validation is done by the receiver of the product). The validation is done against the set of 
baselined  stakeholder  expectations . Special attention should be given to demonstrating 
satisfaction  of the MOEs identified during conduct of the stakeholder expectati ons definition  
process . The type of product validation is a function of the form of the product  and product -line 
life-cycle  phase  and in accordance with an applicable customer  agreement . 
3.2.8.3  Typical practices  of this process are defined  in Appendix C.2.4.  
3.2.9 Product Transition  Process   
3.2.9.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for transitioning end product s to the next 
higher level WBS -model  customer  or user.  
3.2.9.2  The product  transition  process  is used to transition  a verified and validated end product  
that has been generated by product implementation  or product integration  to the customer  at the 
next level in the system  structure  for integration into an end product or, for the top level end 
product, transitioned to the intended end user. The form of the product transitioned will be a 
function of the product -line life-cycle  phase  exit criteria  and the location within the system 
structure of the WBS  model  in which the end product exits.  
3.2.9.3  Typical practices  of this process are defined  in Appendix C.2.5.  
3.2.10  Technical Planning Process  
3.2.10.1  The Center  Directors  or designees shall  establish  and maintain  a process  to include 
activities , requirements , guidelines , and documentation, for planning the technical effort.  
3.2.10.2  The technical planning process is used to plan  for the application  and management of 
each common technical process and to identify, define , and plan the technical effort applicable to 
the product -line life-cycle  phase  for WBS  model  location within the system  structure  and to meet 
project  objectives and product -line life-cycle  phase exit criteria . A key document  generated by 
this process is the SEMP . (See Chapter  6.)  
3.2.10.3  Typical practices  of this process are defi ned in Appendix C.3.1.  
This Document Is Uncontrolled When Printed.  20 3.2.11  Requirements  Management Process  
3.2.11.1  The Center  Directors  or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for management of requirements defined 
and baselined  during the application  of the system  design  processes .  
3.2.11.2  The requirements  management  process is used to: (a) manage  the product  requirements 
identified, baselined , and used in the definition  of the WBS  model  products duri ng system  
design ; (b) provide bidirectional traceability back to the top WBS model requirements ; and (c) 
manage the changes to established requirement baselines over the life cycle  of the system 
products.  
3.2.11.3  Typical practices  of this process are defined  in Appendix C.3.2.  
3.2.12  Interface Management Process  
3.2.12.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for management of the interfaces 
defined and generate d during the application  of the system  design  processes .  
3.2.12.2  The interface management process is used to : (a) establish  and use formal interface  
management to assist in controlling system  product  development  efforts when the efforts are 
divided between Government  programs , contractors , and/or geographically diverse technical 
teams  within the same program or project  and (b) maintain interface definition  and compliance  
among the end product s and enabling product s that compose the system , as well as with other 
systems with which the end products and enabling products must interoperate .  
3.2.12.3  Typical practi ces of this process are defined  in Appendix C.3.3.  
3.2.13  Technical Risk Management  Process  
3.2.13.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation , for management of the technical risk 
identified during the te chnical effort. (NPR  8000.4 , Agency Risk Management Procedural 
Requirements , is to be used as a source document  for defining this process , and NPR 8705.5,  
Probabilistic Risk Assessment (PRA) Procedures for NASA Programs  and Projects , provides one 
means of identifying  and assessing technical risk. ) 
3.2.13.2  The technical risk management process is used to examine  on a continuing basis the 
risks  of technical deviations from the project  plan and identify potential technical problems 
before they occur so that risk -handling activities  can be planned a nd invoked as needed across 
the life of the product  or project to mitigate impacts on achieving product -line life-cycle  phase  
exit criteria  and meeting technical objectives.  
3.2.13.3  Typical  practices  of this process are defined  in Appendix C.3.4.  
This Document Is Uncontrolled When Printed.  21 3.2.14  Configuration Management  Process  
3.2.14.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for configuration  management.  
3.2.14.2  The configuration  management  process for end product s, enabling product s, and other 
work  products placed under co nfiguration control  is used to: (a) identify the configuration of the 
product or work product at various points in time ; (b) systematically control changes to the 
configuration of the product or work product ; (c) maintain  the integrity and traceability of the 
configuration of the product or work product throughout its life ; and (d) preserve the records of 
the product or end product configuration throughout its life cycle , dispositioning them in 
accordance with NPR  1441.1 , NASA Records Retention Schedules . 
3.2.14.3  Typical practices  of this process are defined  in Appendix C.3.5.  
3.2.15  Technical Data Management Process   
3.2.15.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for management of the technical data 
generated and used in the technical effort.  
3.2.15.2  The t echnical data management process  is used to: (a) provide the basis for identifying  
and controlling data requirements ; (b) responsively and economic ally acquire, access, and 
distribute data needed to develop, manage, operate , and support system  products  over their 
product -line life; (c) manage and disposition data as records;  (d) analyze data use; (e) if any of 
the tech nical effort is performed by an external contractor , obtain technical data feedback for 
managing  the contracted technical effort ; and ( f) assess  the collection of appropriate technical 
data and informa tion.  
3.2.15.3  Typical practices  of this process are defined  in Appendix C.3.6.  
3.2.16  Technical Assessment Process   
3.2.16.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for maki ng assessments of the progress 
of planned technical effort and progress toward requirements satisfaction .  
3.2.16.2  The technical assessment process  is used to help monitor  progress of the technical 
effort and provide status information for support of the system  design , product  realization, and 
technical management processes .  
3.2.16.3  Typical practices  of this process are defined  in Appendix C.3.7.  
3.2.17  Decision Analysis Process   
3.2.17.1  The Center  Director s or designees shall  establish  and maintain a process  to include 
activities , requirements , guidelines , and documentation, for making technical deci sions . 
This Document Is Uncontrolled When Printed.  22 3.2.17.2  The decision analysis process , including data collection (e.g., engineering  performance, 
quality, and reliability data) , is used to help evaluate  technical decision issues, technical 
alternatives, and their uncertainties to support decision  making . This process is used throughout 
technical management, system  design , and  product  realization processes  to evaluate the impact 
of decisions on performance, cost , schedule , and technical risk.   
3.2.17.3  Typical practices  of this process are defined  in Appendix C.3.8.  
 
This Document Is Uncontrolled When Printed.  23 Chapter 4.  NASA Overs ight Activities  on Contracted  Projects  
4.1 Introduction  
4.1.1 Oversight /insight  of projects  where prime or external contractors  do the majority of the 
development  effort has always been an important part of NASA programs  and projects. With the 
new focus on Exploration and Space missions , not only will such projects increase , but also it 
will become more critical that NASA provide increased systems  engineering  on these projects 
before, during, and after contract  performance .  
4.1.2 This chapter  defines a minimum set of technical activities  and requirements  for a NASA 
project  technical team  to perform  before contract  award , during contract performance , and upon 
completion of the contract  on projects where prime or external contractors  do the majority of the 
development  effort . These activities and requirements are intended to supplement the common 
technical process activities and requirements of Chapter 3 and thus enhance the outcome of the 
contracte d effort.  
4.2 Activities  Prior to Contract Award  
4.2.1 The assigned NASA technical team  shall  prepare  a SEMP  that covers the periods before 
contract  award , during contract performance , and upon contract completion in accordance with 
content contained in the annotated outline in Appendix D.  
4.2.2 The assigned technical team  shall use common technical processes , as implemented by 
the Center 's documentation, to establish  the technica l inputs  to the Request for Proposal  (RFP ) 
appropriate for the product to be developed , includ ing product  requirements  and Statement of 
Work  tasks .. 
4.2.3 The technical team  shall  determine the technical work  products  to be delivered by the 
offeror or contractor , to include a contractor SEMP  that specifies their systems  engineering  
approach  for requirements  development ; technical solution definit ion; design  realization ; product 
evaluation ; product transition ; and technical planning, control , assessment , and decision analysis . 
4.2.4 The tech nical team  shall  provide to the contracting  officer, for inclusion in the RFP , the 
requirements  for technical oversight  activ ities planned in the NASA SEMP . (Care should be 
taken that no requirements or solicitation information is divulged prior to the release of the 
solicitation by the cognizant contracting officer. ) 
4.2.5  The technical team  shall  participate in the evaluation  of offeror proposals following 
applicable NASA and Center  source selection procedures.  
4.3 During Contract Performance  
4.3.1 The assigned technical team , under the authority  of the cognizant contracting  officer , 
shall  perform the technical oversight  activities  established in the NASA SEMP .  
This Document Is Uncontrolled When Printed.  24 4.4 Contract Completion  
4.4.1 The assigned technical team  shall  participate in scheduled milestone  reviews  to finalize 
Government acceptance of the deliverables . 
4.4.2 The assigned technical team  shall  participate in product  transition  to the customer  and/or 
disposal  as defined in the NASA SEMP .  
This Document Is Uncontrolled When Printed.  25 Chapter 5.  Systems  Engineering  Technical Reviews   
5.1 Life Cycle  
5.1.1  NASA has four interrelated product line s: Basic and Applied Research  (BAR ); 
Advanced Technology Development  (ATD ); Flight System  and Ground Support  (FS&GS ) 
projects ; and Institutional Project s (IPs). Each product line has its own unique product -line life 
cycle . Figure  5-1 shows the life cycle for NASA programs . Figure 5 -2 shows the life cycle for 
NASA projects. Figure 5 -3 shows the product  line technical review  schedule  and technical 
reviews  mapped into the management life cycle .  
5.1.2 The IP  management life cyc le proceeds through a capital assets life cycle in five well -
defined  phases . An IP project  starts with a ―Pre-Formulation  and Proposal‖ phase, progresses 
into a ―Pre liminary Design ‖ and then a ―Build/Construct/Fabricate‖ phase, and eventually ends 
after ―Operations  and Maintenance ‖ with a n ―Asset Disposal ‖ phase. For noncapital asset 
projects, the last three phases are replaced by an ―Execute Project Plan ‖ phase. Typically, these 
projects enable all of the other NASA investment areas  and product line s.  
5.1.3 The two major common phases  for all product line s are Formulation  and Implementation . 
Each product  line has specific phases. FS&GS  projects  have three  variations —human , robotic , 
and Announcement of Opportunity  (AO) projects . 
5.1.4 The life -cycle phases  and the technical review s of this chapter  are closely linked to the 
management life -cycle phases  of NPR  7120.5  as represented in figures  5-1 and 5 -2. The 
application  of the common technical processes  within each life -cycle phase produce s technical 
results  that provide inputs  to technical reviews  and support informed management decisions for 
progressing to the next life -cycle phase.   
5.1.5 The progress between life -cycle phases  is marked by key decisi on point s (KDP s). At each 
KDP , management examines  the maturity of the technical aspects of the project . For example, 
management examines whether the resources (staffing  and fundin g) are sufficient for the planned 
technical effort, whether the technical maturity has evolved, what the technical and nontechnical 
internal issues and risks  are, or whether the stakeholder  expectations  have changed. If the 
technical and management aspects of the project are satisfactory , including the implementation  
of corrective actions , then the project can be approved  to proceed to the next phase .
This Document Is Uncontrolled When Printed.  26 Figure 5 -1 – The NASA Program Life Cycle  
NASA Life 
Cycle PhasesApproval for 
Implementation FORMULATION IMPLEMENTATION
KDP IIProgram Life 
Cycle Gates & 
Major EventsOperations Pre-Program Acquisition Program Acquisition
KDP n KDP IV 
process will be restarted when directed by the AA, i.e., the program ’s upgrade will go through the 
same formulation and implementation steps as originally done.
7.These reviews are conducted by the program for the independent S RB (with the exception of the 
FRR and SMSR). See Section 2.5 and Table 2 -5.
ACRONYMS
ASP—Acquisition Strategy Planning meeting
ASM —Acquisition Strategy Meeting
CDR —Critical Design Review
CERR —Critical Events Readiness Review
FAD—Formulation Authorization Document
FRR—Flight Readiness Review
KDP—Key Decision Point
LRR—Launch Readiness Review
ORR —Operational Readiness Review
PAR—Program Approval ReviewPCA—Program Commitment Agreement
PDR —Preliminary Design Review
PIR—Program Implementation Review
PLAR —Post-Launch Assessment Review
PPAR —Preliminary Program Approval Review
P/SDR —Program/System Definition Review
P/SRR —Program/System Requirements Review
PSR—Program Status Review
SIR—System Integration Review
SRB—Standing Review Board
SMSR —Safety and Mission Success ReviewP/SRR
(PPAR5)Major Program 
Reviews7FADKDP 06
PCA1
Program Plan1
P/SDR
(PAR)Start Project2
1, 2, 3, …Project m, m+1
FRR
LRR
SMSRCDR PDR SIR CERR PLAR ORRProject 
Starts
Program
UpdatesUpdated 
Program PlanUpdated PCA Start process 
again6KDP I KDP III
Single -Project3& Tightly Coupled Programs4Uncoupled & Loosely Coupled Programs
orPSR
(PIR)
PSR
(PIR)orPSRs ,PIRs , &KDPs are conducted ~ every two years
FOOTNOTES
1.PCA and Program Plans are baselined at KDP I and reviewed and updated, as required, 
to ensure program content, cost, and budget remain consistent. 
2.Projects, in some instances, may be approved for formulation pri or to KDP II .  Initial 
project pre -formulation generally occurs during program formulation.
3.Single -project program reviews from PDR until operations are the same r eviews as the 
project reviews (not duplicates). Single -project programs are approved at KDP II.
4.Tightly coupled program reviews generally differ from other prog ram types because they 
are conducted to ensure the overall integration of all program e lements (i.e., projects). 
Once in operations, PSRs/PIRs are conducted ~ every two years.
5.KDP 0 and the PPAR may be required by the Decision Authority to ensure major issues 
are understood and resolved prior to formal program approval at KDP I.
6.When programs require upgrades (e.g., new program capabilities), the life -cycleASM ASPAgency R eviewsNASA Life 
Cycle PhasesApproval for 
Implementation FORMULATION IMPLEMENTATION
KDP IIProgram Life 
Cycle Gates & 
Major EventsOperations Pre-Program Acquisition Program Acquisition
KDP n KDP IV 
process will be restarted when directed by the AA, i.e., the program ’s upgrade will go through the 
same formulation and implementation steps as originally done.
7.These reviews are conducted by the program for the independent S RB (with the exception of the 
FRR and SMSR). See Section 2.5 and Table 2 -5.
ACRONYMS
ASP—Acquisition Strategy Planning meeting
ASM —Acquisition Strategy Meeting
CDR —Critical Design Review
CERR —Critical Events Readiness Review
FAD—Formulation Authorization Document
FRR—Flight Readiness Review
KDP—Key Decision Point
LRR—Launch Readiness Review
ORR —Operational Readiness Review
PAR—Program Approval ReviewPCA—Program Commitment Agreement
PDR —Preliminary Design Review
PIR—Program Implementation Review
PLAR —Post-Launch Assessment Review
PPAR —Preliminary Program Approval Review
P/SDR —Program/System Definition Review
P/SRR —Program/System Requirements Review
PSR—Program Status Review
SIR—System Integration Review
SRB—Standing Review Board
SMSR —Safety and Mission Success ReviewP/SRR
(PPAR5)Major Program 
Reviews7FADKDP 06 KDP 06
PCA1
Program Plan1
P/SDR
(PAR)Start Project2
1, 2, 3, …Project m, m+1Start Project2
1, 2, 3, …Project m, m+1Project m, m+1
FRR
LRR
SMSRCDR PDR SIR CERR PLAR ORRProject 
Starts
Program
UpdatesUpdated 
Program PlanUpdated 
Program PlanUpdated PCA Start process 
again6KDP I KDP III
Single -Project3& Tightly Coupled Programs4Uncoupled & Loosely Coupled Programs
orPSR
(PIR)
PSR
(PIR)orPSRs ,PIRs , &KDPs are conducted ~ every two years
FOOTNOTES
1.PCA and Program Plans are baselined at KDP I and reviewed and updated, as required, 
to ensure program content, cost, and budget remain consistent. 
2.Projects, in some instances, may be approved for formulation pri or to KDP II .  Initial 
project pre -formulation generally occurs during program formulation.
3.Single -project program reviews from PDR until operations are the same r eviews as the 
project reviews (not duplicates). Single -project programs are approved at KDP II.
4.Tightly coupled program reviews generally differ from other prog ram types because they 
are conducted to ensure the overall integration of all program e lements (i.e., projects). 
Once in operations, PSRs/PIRs are conducted ~ every two years.
5.KDP 0 and the PPAR may be required by the Decision Authority to ensure major issues 
are understood and resolved prior to formal program approval at KDP I.
6.When programs require upgrades (e.g., new program capabilities), the life -cycleASM ASPAgency R eviews
This Document Is Uncontrolled When Printed.  27 Figure 5 -2 – The NASA Project  Life Cycle  
 
NASA Life 
Cycle Phases
Project
Life Cycle 
PhasesPre-Phase A:
Concept
StudiesPhase A:
Concept & Technology 
DevelopmentPhase B:
Preliminary Design &
Technology CompletionPhase C:
Final Design & 
FabricationApproval for 
Implementation FORMULATION IMPLEMENTATION
KDP C Project 
Life Cycle 
Gates & 
Major EventsOperations Pre-Systems   Acquisition Systems Acquisition
Phase E:
Operations 
& Sustainment
KDP A
LaunchKDP DPhase D:
System Assembly, 
Int& Test, Launch
KDP BPhase F:
CloseoutDecommissioning
End of Mission
FOOTNOTES
1. Flexibility is allowed in the timing, number, and content of rev iews as long as the 
equivalent information is provided at each KDP and the approach is fully 
documented in the Project Plan. These reviews are conducted by t he project for 
the independent SRB. See Section 2.5 and Table 2 -6.
2. PRR needed for multiple ( ≥4) system copies.  Timing is notional.
3. CERRs are established at the discretion of Program Offices.
4. For robotic missions, the SRR and the MDR may be combined.
5. The ASP and ASM are Agency reviews, not life -cycle reviews.
6. Includes recertification, as required. 
7. Project Plans are baselined at KDP C and are reviewed and updated as 
required, to ensure project content, cost, and budget remain con sistent.Final Archival 
of  DataKDP F  
SMSR, LRR 
(LV), FRR (LV)KDP E  
Peer Reviews, Subsystem PDRs, Subsystem CDRs, and System ReviewsDR PLARMDR4Robotic 
Mission Project 
Reviews1
MCRSRR PDR CERR3 SIR FRR
ACRONYMS
ASP—Acquisition Strategy Planning Meeting
ASM —Acquisition Strategy Meeting
CDR —Critical Design Review
CERR —Critical Events Readiness Review
DR—Decommissioning Review
FAD—Formulation Authorization Document
FRR—Flight Readiness Review
KDP—Key Decision Point
LRR—Launch Readiness Review
MCR —Mission Concept Review
MDR —Mission Definition Review
NAR —Non-Advocate ReviewORR —Operational Readiness Review
PDR —Preliminary Design Review
PFAR —Post-Flight Assessment Review
PLAR —Post-Launch Assessment Review
PNAR —Preliminary Non -Advocate Review
PRR —Production Readiness Review
SAR—System Acceptance Review
SDR —System Definition Review
SIR—System Integration Review
SMSR —Safety and Mission Success Review 
SRR —System Requirements ReviewFAD
Draft Project
Requirements
Launch 
Readiness 
ReviewsSDR CDR / 
PRR2PDR MCR FRR SRR SIR CERR3PLAR SARHuman Space 
Flight Project
Reviews1
Re-flightsDR
(NAR ) (PNAR )
Supporting 
ReviewsORR
Inspections and 
Refurbishment
Re-enters appropriate life cycle phase if  
modifications are needed between flights6End of 
Flight
PFARPreliminary 
Project PlanBaseline  
Project Plan7
ASP5
ORRASM5
(NAR ) (PNAR )CDR / 
PRR2Agency
ReviewsNASA Life 
Cycle Phases
Project
Life Cycle 
PhasesPre-Phase A:
Concept
StudiesPhase A:
Concept & Technology 
DevelopmentPhase B:
Preliminary Design &
Technology CompletionPhase C:
Final Design & 
FabricationApproval for 
Implementation FORMULATION IMPLEMENTATION
KDP CKDP C Project 
Life Cycle 
Gates & 
Major EventsOperations Pre-Systems   Acquisition Systems Acquisition
Phase E:
Operations 
& Sustainment
KDP AKDP A
LaunchLaunchKDP DPhase D:
System Assembly, 
Int& Test, Launch
KDP BPhase F:
CloseoutDecommissioning
End of MissionEnd of Mission
FOOTNOTES
1. Flexibility is allowed in the timing, number, and content of rev iews as long as the 
equivalent information is provided at each KDP and the approach is fully 
documented in the Project Plan. These reviews are conducted by t he project for 
the independent SRB. See Section 2.5 and Table 2 -6.
2. PRR needed for multiple ( ≥4) system copies.  Timing is notional.
3. CERRs are established at the discretion of Program Offices.
4. For robotic missions, the SRR and the MDR may be combined.
5. The ASP and ASM are Agency reviews, not life -cycle reviews.
6. Includes recertification, as required. 
7. Project Plans are baselined at KDP C and are reviewed and updated as 
required, to ensure project content, cost, and budget remain con sistent.Final Archival 
of  DataFinal Archival 
of  DataKDP F  KDP F  
SMSR, LRR 
(LV), FRR (LV)KDP E  KDP E  
Peer Reviews, Subsystem PDRs, Subsystem CDRs, and System ReviewsDRDR PLARPLARMDR4Robotic 
Mission Project 
Reviews1
MCRSRR PDR CERR3 SIR FRR
ACRONYMS
ASP—Acquisition Strategy Planning Meeting
ASM —Acquisition Strategy Meeting
CDR —Critical Design Review
CERR —Critical Events Readiness Review
DR—Decommissioning Review
FAD—Formulation Authorization Document
FRR—Flight Readiness Review
KDP—Key Decision Point
LRR—Launch Readiness Review
MCR —Mission Concept Review
MDR —Mission Definition Review
NAR —Non-Advocate ReviewORR —Operational Readiness Review
PDR —Preliminary Design Review
PFAR —Post-Flight Assessment Review
PLAR —Post-Launch Assessment Review
PNAR —Preliminary Non -Advocate Review
PRR —Production Readiness Review
SAR—System Acceptance Review
SDR —System Definition Review
SIR—System Integration Review
SMSR —Safety and Mission Success Review 
SRR —System Requirements ReviewFADFAD
Draft Project
Requirements
Launch 
Readiness 
ReviewsSDR CDR / 
PRR2PDR MCR FRR SRR SIR CERR3PLAR SARHuman Space 
Flight Project
Reviews1
Re-flightsDRDR
(NAR ) (PNAR )
Supporting 
ReviewsORR
Inspections and 
Refurbishment
Re-enters appropriate life cycle phase if  
modifications are needed between flights6End of 
Flight
PFARPFARPFARPreliminary 
Project PlanPreliminary 
Project PlanBaseline  
Project Plan7Baseline  
Project Plan7
ASP5ASP5
ORRASM5
(NAR ) (PNAR )CDR / 
PRR2Agency
Reviews
This Document Is Uncontrolled When Printed.  28  
Figure  5-3 – Product Line Technical Rev iew Schedule  

This Document Is Uncontrolled When Printed.  29 5.1.6 Three points  are important:  (1) Management  reviews  and the technical  review s support 
one another. (2) Technical  reviews are completed before a KDP . (3) Technical reviews are event 
based  and occur when the entrance criteria  for the applicable review  as specified in Appendix G  
are satisfied. They occur based on  the maturity of the relevant  technic al baseline  as opposed to 
calendar milestones  (e.g., the quarterly progress review , the yearly summary).   
5.2 Technical Review Requirements  
5.2.1 Review  Process  and Practices  
5.2.1.1  For each product line  (BAR , ATD , IP, and FS&GS ), technical efforts are monitored 
throughout  the life cycle  to ensure that the technical goals  of the project  are being achieved  and 
that the technical direction of the project is appropriate.  
5.2.1.2  Technical teams  shall  monitor  technical effort through periodic technical reviews .  
5.2.1.3  A technical review  is an evaluat ion of the project , or element thereof, by a 
knowledgeable group  for the purposes of:  
a. Assessing  the status of and progress toward accomplishing the planned activities . 
b. Validating the technical tradeoffs explored and design  solution s proposed . 
c. Identifying technical weaknesses  or marginal design  and potential problems  (risks) and 
recommending improvements  and corrective actions .  
d. Making judgments on the activities ’ readiness  for the follow -on events , including additional 
future evaluation  milestones  to improve the likelihood of a successful outcome . 
e. Making assessments and recommendations to the project  team , Center , and Agency  
management.  
f. Providing a his torical record  that can be referenced of decisions that were made during these 
formal reviews . 
g. Assess ing the technical risk status  and current risk profile.  
5.2.1.4  See NPR  7120.5  for major program  and project  reviews  and independent reviews .  
5.2.1.5  Technical reviews  are used to evaluate  the status of the technical progress and are 
supported by other equivalent technical discipline activities , including  safety  reviews .  
5.2.1.6  The technical team  shall  ensure that system  aspects represented or implemented in 
software  are included in all technical review s to demonstrate that project  technical goals  and 
progress are being achieved and that all NPR  7150.2 software revi ew requirements are 
implemented.  
This Document Is Uncontrolled When Printed.  30 5.2.2 Planning and Conduct  
The technical team shall  develop and document  plans for technical review s for us e in the project  
planning process . The technical review  schedule , as documented in the SEMP , will be reflected 
in the overall project plan  described in NPR  7120.5.  The results  of each technical review will be 
used to update the technical review plan as part of the SEMP update process . The review plans, 
data, and results should be m aintained and dispositioned as Federal r ecords . 
5.3  Minimum Required Set of Technical  Reviews  
5.3.1 Definition  of Minimum Required Reviews  
5.3.1.1  The minimum set of required technical review s applies  to all current and future NASA 
FS&GS  and IP  programs  and projects  as defined  in sec tion P .2 of this document  (including 
spacecraft, launch vehicles, instruments d eveloped for space flight programs and projects, 
designated research and technology development s to be incorporated by space flight programs 
and projects, critical technical facilities  specifically  developed or significantly modified for space 
flight systems , information systems  and technology that support space flight programs and 
projects, and ground systems that are in direct  support of space flight operations ). Between each 
life-cycle  phase , a program or project goes through KDPs  preceded by one or more reviews  that 
enable a disciplined approach  to assessing programs ’ and projects ’ readiness  to progress to the 
next phase . Allowances are made within a phase for the differences between human and robotic 
FS&GS  projects. Additional description of  technical reviews is provided in  the NASA Systems 
Engineering  Handbook  (SP-6105).  (For more information on program and project life cycles and 
management reviews , see the appropriate NPR , e.g. , NPR 7120.5.)  
5.3.1.2  The technical team  shall  address the entrance and success crit eria listed in Appendix G 
for applicability to the respective reviews . 
5.3.1.3  The technical team  shall  execute the required Program /System  Requir ements Review  
(P/SRR) and Program Approval  Review  (PAR) in accordance with the review  entry and success 
criteria  defined in tables G -1 and G -2 of Appendix G.  
5.3.1.4  The technical team  shall  execute the required program  technical review s in accordance 
with the following timeline: P/SRR  before KDP  0 and PAR  before KDP 1.  
5.3.1.5  For human FS&GS  projects , the technical team  shall  execute the following required 
minimum set of technical review s in accordance with the review  entry and success criteria  
defined in tables G -3, G-4, G-6, G-7, G-8, and G-10 through G-18 of Appendix G : Mission 
Concept Review  (MCR ), System  Requirements Review  (SRR) , System Definition Review 
(SDR), Preliminary Design  Review (PDR), Critical Design Review  (CDR ), System Integration 
Review  (SIR ), Test Readiness Review  (TRR ), System Acceptance Review  (SAR ), Operational 
Readiness Review  (ORR ), Flight Readiness Review  (FRR ), Post-Laun ch Assessment Review  
(PLAR ), Critical Event Readiness Review (CERR ), Post-Flight Assessment Review  (PFAR ), 
and Decommissioning Review  (DR). (For more information on program  and project life cycles  
and management reviews , see the app ropriate NPR , e.g., NPR 7120.5.)  
This Document Is Uncontrolled When Printed.  31 5.3.1.6  For robotic  FS&GS  projects , the technical  team  shall  execute  and document  the 
following minimum required technical review s: the MCR , SRR , Mission Def inition Review 
(MDR ), PDR, CDR , SIR , TRR , ORR , FRR , PLAR , CERR , and DR  in accordance with the 
review  entry and success criteria  given in tables G -3, G-4, G-5, G-7, G-8, G-10, G -11, G -13 
through G -16, and  G-18 of Appendix G . Robo tic projects can combine the SRR and MDR based 
on size and level of risk. If the two reviews are conducted separately, Table G -4 will be  used for 
the SRR  and Table G -5 will be used for the MDR. If the two reviews are combined, the entrance 
and success crit eria for both SRR and MDR will be combined for this single review.   
5.3.1.7  The technical team  shall  also execute a Production Readiness Review  (PRR ) as an 
additiona l technical review  for both human and robotic FS&GS  projects  developing or acquiring 
multiple or similar systems  greater than three (or as  determined by the project) in accordance 
with the review  entry and success criteria  defined in Table G -9 of Appendix G. Any project 
producing end product s with three or less units will still perform the required CDR . The CDR 
will include production considerations when a PRR is not performed.  
5.3.1.8  The technical team  shall  execute the required FS&GS  project  technical review s in 
accordance with the following timelines:  
a. MCR  prior to KDP  A. 
b. Human FS&GS  project  SRR prior to SDR and robotic missions  SRR and MDR  prior to KDP  
B. 
c. Human FS&GS  project  SDR prior to KDP  B. 
d. PDR  prior to KDP  C. 
e. CDR  prior to starting fabrication of system  end product s and SIR . 
f. PRR  prior to starting fabrication of system  end product s for projects  requiri ng multiple units.  
g. SIR prior to KDP  D. 
h. TRR  prior to starting product  verif ication  and product validation  testing . 
i. Human FS&GS  project  SAR  after completion of KDP  D. 
j. ORR  after SAR  or KDP  D and before FRR . 
k. FRR  prior to KDP  E. 
l. PLAR  after system  end product  launch.  
m. CERR  after PLAR  and before KDP  F. 
n. Human FS&GS  project  PFAR  at end of flight  and before KDP  F. 
o. DR after KDP  F. 
5.3.1.9  The assigned technical team  shall  accomplish the monitoring function for flight -related  
ATD  projects  using appropriately defined and conducted  periodic  technical  review s (PTR s) and 
continuation reviews  (CRs) . (See Figure  5-3.) 
This Document Is Uncontrolled When Printed.  32 5.3.1.10  The assigned technical team  shall  accomplish the monitoring function for IPs using 
PTR and SAR . (See Figure  5-3.) 
5.3.1.11  Reviews  are considered complete when the following are accomplished:  
a. Agreement  exists for the dispos ition of all Review Item Discrepancies  (RID s) and Request 
for Actions  (RFA ).  
b. The review  board report and minutes are complete and distributed.  
c. Agreement  exists on a plan  to address the issues and concerns in the review  board’s report.  
d. Agreement  exists on a plan  for addressing the actions identified out of the review . 
e. Liens  against the review  results  are closed, or an adequate and timely plan  exists for their 
closure.  
f. Differences of opinion between the project  under review  and the review board(s) have been 
resolved, or a timely plan  exists to resolve  the issues.  
g. A report is given by the review  board chairperson to the appropriate management and 
governing program  management committee s (PMCs ) charged with oversight  of the project . 
h. Appropriate procedures and controls  are instituted to ensure that all actions from reviews  are 
followed and verified thr ough implementation  to closure.  
This Document Is Uncontrolled When Printed.  33 Chapter 6.  Systems  Engineering  Management Plan  
6.1 Systems  Engineering  Management Plan  Function  
6.1.1 The primary function of the SEMP  is to provide the basis for implementing the technical 
effort and communicating what will be done, by whom, when, where, cost  drivers , and why it is 
being done. In addition , the SEMP identifies the roles  and responsibility interfaces of the 
technical effort and how those interfaces will be man aged.  
6.1.2 The SEMP  is the vehicle that documents  and communicates the technical approach  
including the application  of the common technical  processes ; resources to be used ; and key 
technical tasks, activities , and events along with their metrics  and success criteria . The SEMP 
communicates the technical effort that will be performed by the assigned technical team  to the 
team itself, managers, customers , and other stakeholders. Whereas the primary focus is on the 
applicable phase  in which the technical effort will be done, the planning extends to a summary of 
the technical efforts that are planned for future applicable phases.   
6.1.3 The SEMP  is a ―living ‖ and tailorable document  that captures a project ’s current and 
evolving systems  engineering  strategy and its relatio nship with the overall pr oject management  
effort throughout the life cycle  of the system. The SEMP ’s purpose  is to guide all technical 
aspects of the project.   
6.1.4 The SEMP  is consi stent with higher level SEMPs and the project  plan in accordance with 
NPR  7120.5.  
6.1.5 The content of a SEMP  for an in -house technical effort may differ from an external 
technical effort. For an external technical effort, the SEMP should include details on developing 
requirements  for source selection, monitoring per formance, and transferring and integrating 
externally produced products  to NASA. (See Appendix D for fu rther details.)  
6.1.6 The SEMP  provides the basis for generating the contractor  engineering  plan.  
6.2 Roles  and Responsibilities  
6.2.1 Working with the program /project  manager , the technical team  shall  determine the 
appropriate level within the system  structure  at which SEMPs are developed, taking into account 
factors such as number and complexity  of interfaces, operating environments , and risk factors.   
6.2.2 The technical team  shall  baseline  the SEMP  per the Center ’s Implementation  Plan 
incorporating  the content of Appendix D, Systems  Engineering  Management Plan, prior to 
completion of Phase  A in the program  life cycle  or the equivalent milestone . At the discretion of 
the PM  and the DGA , for a small project  the material in the SEMP can be placed in the project 
plan’s technical summary and the annotated ou tline in Appendix D used as a topic guide. As 
changes occur, the SEMP will be updated by the technical team, reviewed and concurr ed with by 
the PM, and presented at subsequent milestone reviews  or their equivalent.  
6.2.3 The DGA  shall  review  and approve or disapprove the SEMP  at each major milestone  
review or its equivalent.  
This Document Is Uncontrolled When Printed.  34 6.2.4 The assi gned technical team  shall  establish  the initial SEMP  early in the Formulation  
phase and update it as necessary to re flect changes in scope  or improved technical development . 
6.2.5 The technical team  shall  ensure that any technical plans and discipline plans describe 
how the technical activities  covered in the plans are consistent with the SEMP  and are 
accomplished as fully integrated  parts of the technical effort.  
6.2.6 The technical team  shall  ensure  that the project ’s software  development /management 
plan describes how the software activities  are consistent with the S EMP and are accomplished as 
fully integrated  parts of the technical effort.  The required content of the project’s software 
development/management plan  is provided in NPR  7150.2 , dependent upon the classification of 
software items  
6.2.7 The technical team shall establish Technical Performance Measures (TPMs) for the 
project that track/describe the current state vers us plan.  
 
6.2.7.1  The Technical Team shall report the TPMs to the program/project manager on an 
agreed -to reporting interval.  
 
6.2.7.2  The set of TPMs shall include the following leading indicators:  
 
a.  Mass Margins for projects involving hardware . 
 
b.  Power Margins for projects tha t are powered . 
 
c.  Closure of review action documentation (Request s for Action, Review Item Discrepancies , 
and/or Action Items as established by the project) for all hardware and software projects . 
This Document Is Uncontrolled When Printed.  35 Appe ndix A. Definitions  
Activity: (1) Any of the project  components or research functions that are executed to deliver a 
product  or service or provide support or insight to mature technologies. (2) A set of tasks that 
describe the technical effort to accompl ish a process and help generate expected outcomes.  
Advanced Technology Development : ATD  is one of four interrelated NASA product line s. 
ATD programs  and projects  are investments that produce entirely new capabilities  or that help 
overcome technical limitations of existing systems . ATD is seen as a bridge between BAR  and 
actual  application  in NASA, such as FS&GS  projects or elsewhere. ATD projects typically fall 
within a Technology Readiness Level  (TRL ) range of 4 to 6.  
Baseline : An agreed -to set of requirements , designs, or documents  that will have changes 
controlled through a formal approval  and monitoring process.  
Basic and Applied Research : Research whose results  expand the knowledge base, provide 
scientific and technological breakthroughs that are immediately applicable, or evolve into an 
advanced te chnology development  (ATD ). Basic research addresses the need for knowledge, 
while applied research  directs this new knowledge toward a practical application . 
 
Component Facilities:  Complexes that are geographically separated from the NASA Center  or 
institution to which they are assigned.  
Contractor:  For the purposes of this NPR , a ―contractor ‖ is an individual, partnership, company, 
corporation, associ ation , or other service  having a contract with the Agency  for the design , 
development , manufacture, maintenance , modification, operation, or supply of items or services  
under the terms of a contract to a program  or project  within the scope  of this NPR.   Research 
grantees, research contractors , and research subcontractors  are excluded from this definition . 
Critical Event  (also referred to as a Key Event in this NPR ): An event that requires 
monitoring  in the projected life cycle  of a product  that will generate critical requirements that 
would affect system  design , development , manufacture, test , and opera tions  (such as with an 
MOE , MOP, Technical Performance Measure ( TPM ), or KPP ). 
Customer : The organization  or individual that has requested a product  and will receive the 
product to be delivered. The customer may be an end user of the product, the acquiring agent for 
the end user,  or the request or of the work  products from a technical effort. Each product within 
the system  hierarchy has a customer.  
Decision Authority : The Agency ’s responsible individual who authorizes the transition  at a 
KDP  to the next  life-cycle  phase  for a program /project . 
Designated Governing Authority : The manageme nt entity above the program , project , or 
activity  level with technical oversight  responsibility.  
Enabling Products : The life -cycle  support pr oducts  and services (e.g., production, test , 
deployment, training , maintenance , and disposal ) that facilitate the progression and use of the 
operational end product  through its life cycle. Since the end product and its enabling product s are 
This Document Is Uncontrolled When Printed.  36 interdependent, they are viewed as a system . Project  responsibility thus extends to res ponsibility 
for acquiring services from the relevant enabling products i n each life -cycle  phase . When a 
suitable enabling product does not already exist, the  project that is responsible for the  end 
product can also be responsible for creatin g and using the enabling  product.  
Entry Criteria : Minimum accomplishments each project  needs to fulfill to enter  into the next 
life-cycle  phase  or level of technical maturity . 
Establish (with respect to each process in Chapter  3): The act of developing policy, work  
instructions or procedures to implement  process activities . 
Exit Criteria : Specifi c accomplishments that should be  satisfactorily demonstrated before a 
project  can progress to the next product -line life-cycle  phase . 
Expectation : Statements of needs, desires, capabilitie s and wants that are not expressed as a 
requirement  (not expressed as a ―shall ‖ statement) is to be referred to as an ―expectation .‖ Once 
the set of expectations from applicab le stakeholders is collected, analyzed , and converted into a 
―shall‖ statement , the ―expectation‖ becomes a ―requirement.‖ Expectations can be stated in 
either qualitative ( nonmeasu rable) or quantitative ( measurable ) terms. Requirements are always 
stated i n quantitative terms. Expectations can be stated in terms of functions, behaviors, or 
constraints  with respect to the product  being engineered or the process used to engineer the 
product . 
Flight Systems  and Ground Support : FS&GS  is one of four interrelated NASA product line s. 
FS&GS projects  result in the most complex and visible of NASA investments. To manage these 
systems , the Formulation  and Implementation  phases  for FS&GS projects follow the NASA 
project life -cycle  model  consisting of phases A (Concept Development) through  F (Closeout ). 
Primary drivers for FS&GS projects are safety  and mission  success.  
Formulation  Phase : The first part of the NASA management life cycle  defined  in NPR  7120.5 
where system  requirements are baselined , feasible concepts are determined, a sys tem definition 
is baselined for the selected concept(s), and preparation  is made for progressing to the 
Implementation  phase.  
Implementation  Phase : The part of the NASA management life cycle  defined  in NPR  7120.5 
where the detailed design  of system  products  is completed and the products to be deployed are 
fabricated, assembled, integrated  and tested; and the products are deployed to their customers or 
users for their assigned use or mission . 
Institutional Project s: Projects that build or maintain  the institutional infrastructure to support 
other NASA product line s.  
Information Systems  and Technology Projects:  All NASA projects  for or including the 
development , modernization, enhancement, or steady -state operations  of informat ion systems  
and technologies.  This includes projects for or containing computer and/or communications 
systems, ancillary equipment, hardware, software  applications, firmware, or networks for the 
generation, processing, stor age, access, manipulation, exchange or safeguarding of information.  
This Document Is Uncontrolled When Printed.  37 Iterative : Application of a process to the same product  or set of products to correct a discovered 
discrepa ncy or other variation from requirements . (See ―recursive‖ and ―repeatable .‖) 
Key Decision Point :  The event at which the Decision Authority  determines the readiness  of a 
program /project  to progress to the next phase  of the life cycle  (or to the next KDP ). 
 
Key Event:  See Critical Event.  
Key Performance Parameters : Those  capabilities  or characteristics (typically engineering -
based or related to safety  or operational performance) considered most essential for successful 
mission  accomplishment. Failure to  meet a KPP  threshold can be cause for the project , system , 
or advanced technology development  to be reevaluated or terminated or f or the system  concept 
or the contributions of the individual systems to be reassessed. A project’s KPPs are identified 
and quantified in the project baseline . (See Technical Perfo rmance Parameter .) 
Logical Decomposition : The decomposition of the defined  technical requirements  by functions, 
time, and behaviors to determine the appropriate set of logical models and related derived 
technical requirements. Models may include  functional flow block diagrams, timelines, data 
control  flow, states and modes, behavior diagrams, operator tasks, and functional failure modes.  
Maintain (with respect to establishment of processes  in Chapter  3): The act of planning the 
process, providing resources, assigning responsibilities , training  people, managing  
configurations, identifying  and involving stakeholders, and monitoring process effectiveness.  
Measure of Effectiveness : A measure by which a stakeholder ’s expectations  will be judged in 
assessing satisfaction  with products  or systems  produced and delivered in accordance with the 
associated technical effort. The MOE  is deemed to be critical to not only the acceptability of the 
product by the stakeholder but also c ritical to operational/mission  usage. An MOE is typically 
qualitative in nature or not able to be used directly as a ―design -to‖ requirement . 
Measure of Performance: A quantitative measure that, when met by the design  solution , will 
help ensure that an MOE  for a product  or system  will be satisfied. These MOPs are given special 
attention durin g design to ensure that the MOEs to which they are associated are met. There are 
generally two or more measures of performance for each MOE.  
Other Interested Parties : A subset of ―stakeholders,‖ other interested parties are g roups or 
individuals that are n ot customers of a planned technical effort but may be affected by the 
resulting product , the manner in which the product is realized or used, or have a responsibility 
for providing life -cycle  support services. A subset o f ―stakeholders .‖ (See Stakeholder .) 
Peer Review:  Independent evaluation  by internal or external subject matter experts who do not 
have a vested interest in the work  product  under review . Peer reviews can be planned, focused 
reviews conducted on selected work products by the producer’s peers to identify defects and 
issues prior to that work product moving into a milestone  review or approval  cycle.  
Process:  A set of activities  used to convert inputs  into desired outputs  to generate expected 
outcomes and satisfy a purpose . 
This Document Is Uncontrolled When Printed.  38 Product:  A par t of a system  consisting of end product s that perform operational functions and 
enabling product s that perform life -cycle  services related to the end product or a result of the 
technical efforts in the form of a work  product (e.g. , plan, baseline , or test result).  
Product -Based WBS  Model : See WBS model . 
Product R ealization : The act of making, buying , or reusing a product , or the assembly and 
integration  of lower level realized products into a new p roduct, as well as the verification  and 
validation  that the product satisfies its appropriate set of requirements  and the transition  of the 
product to its customer . 
Program : A strategic investment by a mission  directorate (or mission support office) that has 
defined  goals , objectives, architecture , funding level, and  a management structure  that supports 
one or more projects . 
Program  Commitment Agreement : The contract  between the Administrator and the cognizant 
Mission Directorate A ssociate Administrator (MDAA)  or Mission Support Office Director 
(MSOD)  for implementation  of a program.  
Project : (1) A specific investment having defined  goals , objectives, requirem ents, life-cycle  
cost, a beginning, and an end. A project yields new or revised products  or services that directly 
address NASA’s strategic needs. They may be performed wholly in -house;  by Government, 
industry, academia partnerships ; or through contracts with private industry. (2) A unit of work  
performed in programs , projects, and activities . 
Realized Product: The desi red output  from the application  of the four Product Realization 
Processes . The form of this product  is dependent on the phase  of the pro duct-line life  cycle  and 
the phase exit criteria . 
Recursive:  Value is added to the system  by the repeated application  of processes  to design  next 
lower layer system products  or to realize next upper layer end product s within the system 
structure . This also applies  to repeating application of the same processes to the system structure 
in the next life -cycle  phase  to mature the system definition  and satisfy phase exit criteria . 
Relevant  Stakeholder : See Stakeholder.  
Repeatable : A characteristic of a process that can be applied to products  at any level of the 
system  structure  or within any life -cycle  phase . 
Requirement : The agreed upon need , desire, want, capability , capacity,  or demand for 
personnel, equipment, facilities , or o ther resources or services by specified quantities for specific 
periods of time or at a specified time  expressed as a ―shall ‖ statement . Acceptable form  for a 
requirement statement  is indivi dually clear , correct, feasible to obtain, una mbiguous in meaning, 
and can be validated at the level of the system  structure  at which stated. In pairs of requirement 
statements or as a set, collectively , they are not redundant, are adequ ately related with respect to 
terms used, and are not in conflict  with one another.  
This Document Is Uncontrolled When Printed.  39 Risk : The combination of the probability that a program  or project  will experience an undesired 
event (some examples incl ude a cost  overrun, schedule  slippage, safety  mishap, health problem, 
malicious activities , environmental impact, failure to achieve a needed scientific or technological 
breakthrough or missi on success criteria ) and the consequences, impact, or severity of the 
undesired event, were it to occur. Both the probability and consequences may have associated 
uncertainties. (Reference 7120.5 .) 
Software : As defined  in NPD  2820.1,  NASA Software Policy . 
Specification : A document  that prescribes, in a complete, precise, verifiable manner, the 
requirements , design , behavior, or characteristics of a system  or system component.  
Stakeholder : A group  or individual who is affected by or is in some way accountable for the 
outcome of an undertaking. The term ―relevant stakeholder‖ is a subset of the term ― stakeholder‖ 
and describes people or roles  that are designated in a plan  for stakeholder involvement. Since 
―stakeholder‖ may describe a very large number of people, a lot of time and effort would be 
consumed by attempting to dea l with all of them. For this reason, ―relevant stakeholder‖  is used 
in most practice statements  to describe the people identified to contribute to a specific task. 
There are two main classes of stakeholders . See  ―customers‖ and ―other i nterested parties.‖  
Success Criteria : Specific accomplishments  that must be satisfactorily demonstrated to meet the 
objectives of a technical review  so that a technical effort can progress further in the life cycle . 
Success criteria  are documented in the corresponding technical review  plan. 
Surveillance -Type  Projects:  A project  where prime or external contractors  do the majority of 
the development  effort that requires NASA oversight .  
System : (a) The combination of elements that function together to produce the capability  to meet 
a need. The elements include all hardware, software , equipment, facilities , personnel, processes , 
and procedures needed for this purpose . (Refer to  NPR  7120.5 .) (b) The end product  (which 
performs operational functions) and enabl ing product s (which provide life-cycle  support services 
to the operational end products)  that make up a system . (See WBS  definition .) 
Systems  Approach : The application  of a systematic, disciplined engineering  approach  that is 
quantifiable , recursive, iterative, and repeatable  for the development , operation, and maintenance  
of systems integrated  into a whole throughout the life cycle  of a proje ct or program .  
Systems  Engineering  Engine : The SE  model  shown in Figure  3-1 provide s the 17 technical 
processes  and their relationship with each other. The model is called an ―SE engine ‖ in that the 
appropriate set of processes is  applied to the products  being engineered to drive the technical 
effort.  
System s Engineering  Management Plan : The SEMP identifies the roles  and responsibility 
interfaces of the technical effort and how those interfaces will be managed. The SEMP is the 
vehicle that documents  and communicates the technical approach , including the application  of 
the common technical processes ; resources to be used; and key technical tasks, activities , and 
events along with their metrics  and success crite ria. 
This Document Is Uncontrolled When Printed.  40 System  Safety  Engineering : The application  of engineering and management principles, 
criteria , and techniques to achieve acceptable mishap risk,  within the constraints  of operational 
effectiveness and suitability,  time, and cost , throughout all phases  of the system life cycle . 
System  Structure : A system structure  is made up of a layered structure  of product -based WBS  
models . (See WBS definition .)  
Tailoring : The documentation and approval  of the adaptation of the process and approach  to 
complying  with requirements  underlying the specific program  or projects . Tailoring 
considerations include system  size and complexity , level of system definition  detail, scenarios 
and missions , constraints  and requirements, technology base, major risk factors, and 
organizational best practices  and strengths.  Critical project  considerations  (e.g.,  public safety , 
security, litigation exposures) may preclude tailoring out required process activities , regardless 
of cost , manpower available , or other considerations . (From Systems Engineering  Fundamentals, 
Defense Acquisition University, January 2001 .) 
Technical Performance Measures : The set of critical or key performance parameters  that are 
monitored by comparing the current actual achievement of the parameters  with that anticipated at 
the current time and on future da tes. Used to confirm progress and identify deficiencies that 
might jeopardize meeting a system  requirement .  Assessed parameter values that fall outside an 
expected range around the anticipated values indicate a need for  evaluation  and corrective action. 
Technical performance measures are typically selected from the defined  set of Measures of 
Performance (MOPs).  
Technical Team : A group  of multidisciplinary individuals with appropriate domain knowledge, 
experience,  competencies , and skills  assigned to a specific technical task.  
Technology Readiness Level : Provides a scale against which to m easure the maturity of a 
technology. TRLs range from 1, Basic Technology Research, to 9, Systems  Test, Launch and 
Operations . Typically, a TRL  of 6 (i.e., technology demonstrated in a relevant envi ronment ) is 
required for a technology to be integrated  into an SE process.  
Technical Risk : Risk associated with the achievement of a technical goal , criterion, or obj ective.  
It applies  to undesired consequences related to technical performance, human safety , mission  
assets, or environment . 
Transition : The act of  delivery or moving of a product  from the location where the product has 
been implemented or integrated , as well as verified and validated, to a customer . This act can 
include packaging, handling, stori ng, moving, transporting, installing , and sustainment  activities . 
Transition  Process : In the context of this SE NPR , the Transition Process transfers a product  to 
a customer  higher in the system  structure  for assembly and integration  into a higher level product 
or to the intended end use customer.  
Validation  (of a product ): Proof that the product accomplishes the intended purpose . Validation 
may be d etermined by a combination of test , analysis , and demonstration.  
This Document Is Uncontrolled When Printed.  41 Validated Requirements : A set of requirements that are well -formed (clear and un -ambiguous), 
complete (agrees with customer  and stakeholder  needs and expectations ), consistent (conflict  
free), and individually verifiable and traceable to a higher -level requirement or goal . 
Verification  (of a product ): Proof of compliance  with specifications . Verification may be 
determined by  test, analysis , demonstration, and inspection.  
Waiver : A documented agreement  intentionally releasing a program  or project  from meeting a 
requirement . (Some Centers use deviations prior to Implementation  and waivers  during 
Implementation).  
WBS  Model: Model that d escribes a system  that consists of end product s and their subsystems 
(perform the operational f unctions of the system), the supporting or enabling product s (for 
development ; fabrication, assembl y, integration , and test ; operations ; sustainment ; and end -of-
life pro duct disposal  or recycling ), and any other work  products (plans, baselines ) required for 
the development of the system. See the example p roduct -based WB S for an aircraft system and 
one of its subsystems (navigation subsystem) below:  
 
Figure  A-1 – Product -Based WBS  Model Example  

This Document Is Uncontrolled When Printed.  42 Appendix B. Acron yms 
AO  Announcement of Opportunity  
ATD  Advanced Technology Development  
BAR   Basic and Applied Research  
CDR  Critical Design  Review  
CERR  Critical Event Readiness Review  
CM  Configuration Management  
CMM  Capability  Maturity Model®  
CMMI  Capability  Maturity Model® IntegrationSM 
CoF Construction of Facilities  
ConR  Continuation Reviews  
DGA  Designated Governing Authority  
DR Decommissioning Review  
ECP Engineering Change Proposal  
ECR  Environmental Compliance  and Restoration  
EEE Electrical, Electronic, and Electromechanical  
EMC  Electromagnetic Compatibility  
EMI Electromagnetic Interference  
EPR Engineering Peer Reviews  
FAD  Formulation  Approval  Document  
FRR  Flight Readiness Review  
FS&GS  Flight Systems  and Ground Support  
ICD Interface Control  Document  
ICWG  Interface Control  Working Group  
INCOSE  International Council on Systems  Engineering  
IP  Institutional Projects  
IPD Integrated Product Development  
IPPD  Integrated Product and Process Development  
KDP  Key Decision Point  
KPP  Key Performance Parameter  
LLIL  Limited Life Items List 
MCR  Mission Concept Review  
MD Mission Directorates  
MDAA  Mission Directorate Associate Administrator  
MDR  Mission De finition  Review  
MOE   Measure s of Effe ctiveness  
MOP  Measures of Performance  
MSO  Mission Support Office  
MSOD  Mission Support Office Director  
NODIS  NASA On -Line Directives Information System   
NPD  NASA Policy Directive  
NPR  NASA Procedural Requirement s 
OCE   Office of the Chief Engineer  
ORR   Operational Readiness Review  
OSMA  Office of Safety and Mission Assurance  
This Document Is Uncontrolled When Printed.  43 PA Portfolio  Approval  
PAR  Program  Approval Review  
PCA                Program Commitment Agreement  
PDR  Preliminary Design  Review  
PFAR  Post Flight Assessment Review  or Post Flight Anomaly Records  
PLAR  Post Launch Assessment Rev iew 
PM Program  or Project  Manager  
PMP  Program  Management P lan 
PNAR  Pre-Non-Advocate Review  
PP Project  Plan 
PR Procedural Requirements  
PRA  Probabilistic Risk Assessment  
PRR  Production Readiness  Review  
P/SRR  Program /System  Requirements  Review  
PTR Periodic Technical Reviews  
RFA  Requests for Action  
RFP Request for Proposal  
RID Review Item Discrepancy  
SAR   System  Acceptance Review  
SDP Software  Development Plan  
SDR  System  Definition  Review  
SE Systems  Engineering  
SEMP   System s Engineering  Management Plan  
SE NPR  Systems  Engineering  NASA Procedural Requirement s 
SEWG   System s Engineering  Working Group  
SIR System  Integration Review  
S&MA  Safety and Mission Assurance  
SP Special Publication  
SRR  System  Requirements Review  
TPM   Technical Performance Measure  
TRL   Technology Readiness  Level  
TRR   Test Readiness Review  
V&V  Verification and Validation  
WBS  Work  Breakdown Structure  
 
 
 
 
This Document Is Uncontrolled When Printed.  44 Appendix C.  Practices  for Common Technical Processes   
a. This appendix contains best typical practices  as extracte d from industry  and national and 
international standards and as found within the Agency . The practices may be used by Centers in 
preparing directives , policies, rules, work  instructions, and other documen ts implementing SE  
processes . The practices of this appendix may also be used in the future assessments of those 
plans and processes to provide feedback to the OCE  and Centers on the strengths and 
weaknesses in the Center s’ implementation  of this SE NPR . These practices can be expanded 
and updated as necessary . 
b. Each process is described in terms of purpose , inputs , outputs , and activities . Notes are 
provided to further explain a process and to  help u nderstand the best practices  included. A 
descriptive figure  is also provided for each process to illustrate notional relationships between 
activities within a process and the sources of inputs and destinations of outputs. Figures in this 
appendix are not intended to include all possible inputs, outputs, or intermediate work  products .1  
C.1 System  Design  Processes  
a. There are four system  design  processes  applied to each product -based WBS  model  from the 
top to the bottom of the system structure : (1) Stakeholder  Expectation Definition , (2) Technical 
Requirements  Definition, (3) Logical Decomposition , and (4) Design Solution  Definition. (See 
Figure  3-2.)  
b. During the application  of these four processes  to a WBS  model  it is expec ted that there will 
be a need to apply activities  from other processes yet to be completed in this set of processes and 
to repeat process activities already performed in order to arrive at an acceptable set of 
requirements  and solutions. There will also be a need to interact with the technical management 
processes to aid in identifying  and resolving  issues and making decisions  between altern atives.  
c. For software  products , the technical team  should refer to NPR  7150.2 software design  
requirements. The technical team should also ensure that the process implementation s comply 
with NPR 7150.2 software product realization requirements for software aspects of the system . 
C.1.1 Stakeholder  Expectations  Definition  Process  
C.1.1.1  Purpose  
The stakeholder  expectations  definition  process  is used to elicit an d define use cases, scenarios, 
operational concepts, and stakeholder expectations for the applicable product -line life-cycle  
phases  and WBS  model . This includes requirements  for:  
a. operational end product s and life -cycle -enabling product s of the WBS  model ;  
b. expected skills  and capabilities of operators or users;  
                                                 
1The SEMP  is an input  to the common t echnical processes , but it is not shown in each process diagram in this 
appendix.  
This Document Is Uncontrolled When Printed.  45 c. expected number of simultaneous users ;  
d. system  and human perfor mance criteria ;  
e. technical authority , standards, regulations , and laws;  
f. factors such as safety , quality, security, context of use by humans, reliability, availability, 
maintainability, electromagnetic compatibility , interoperability, testability, transportability, 
supportability, usability, and disposability; and  
g. local management constraints  on how work  will be done (e.g., operating  procedures). The 
baselined  stakeholder  expectations  are used for validation  of the WBS  model  end product  
during product realization.   
C.1.1.2  Inputs  and Sources : 
a. Customer  expectations  (from users and program  and/or project ). 
b. Other stakeholder  expectations  (from project  and/or other interested parties of the WBS  
model  products —recursive loop) . 
c. Customer  flow-down requirements  from previous level WBS  model  products  (from Design  
Solution  Definition  Process —recursive loop —and Requirements Management and Interface 
Management Processes ). 
Note:  This would include requirements  for initiating enabling product  development  to provide appropriate life -cycle  
support products  and services to the mission , operational , or research end product  of the WBS  model . 
C.1.1.3  Outputs  and Destinations : 
a. Set of validated stakeholder  expectations , including interface requirements  (to Technical 
Requirements Definition , Requirements Management , and Interface Management Processes ). 
b. Baseline  operational concepts (to Technical Requirements  Definition  Process and 
Configuration Management Processes ). 
c. Baseline  set of enabling product  support strategies (to Technical Requirements  Definition  
Process and Configuration Management Processes ). 
d. Measures of Effectiveness  (MOEs) (to Technical R equirements  Definition  Process and 
Technical Data Management Process ). 
C.1.1.4  Activities  
For the WBS  model  in the system  structure , the following activit ies are typically performed:  
a. Establish a list that identifies customers and other stakeholders that have an interest in the  
system  and its products . 
b. Elicit customer  and other stakeholder  expectations  (needs, wants, desires, capabilities , 
external interfaces , and constra ints) from the identified stakeholders.  
c. Establish operational concepts and support strategies based on stakeholder  expected use of 
the system  products  over the system’s life.  
This Document Is Uncontrolled When Printed.  46 Note:  Defined scenarios and operational concepts include functionality and performance of intended uses and 
relevant boundaries, constraints , and environments  in which the product (s) will operate. Support str ategies include 
provisions for fabrication, test , deployment, operations , sustainment , and disposal  as appropriate.  
d. Define stakeholder  expectations  in acceptable statements  that are complete sentences and 
have the following characteristics: (1) individually clear, correct, and feasible to satisfy; not 
stated as to how it is to be satisfied; implementable; only one interpretation of meaning; one 
actor -verb-object expectation; and can be validated at the level of the system  structure  at 
which it is stated; and (2) in pairs or as a set there is an absence of redundancy,  consistency 
with respect to terms used, not in conflict  with one another, and do not contain stakeholder 
expectations of questionable utility or that have an unacceptable risk of satisfaction . 
e. Analyze sta keholder  expectation  statements  to establish  a set of measures ( MOE s) by which 
overall system  or product  effectiveness will be judged and customer  satisfaction  will be 
determined.  
Note:  A set of MOE s is selected from the set of defined  stakeholder  expectat ion statements. It represents a n 
expectation that is critical to the success of the system , and failure to satisfy th ese measure s will cause the 
stakeholder to deem the system unacceptable. Examples of typical MOEs are w eight, availability, mobility, 
user/operator comfort , CPU capacity, and parameters  associated with critical events during operations . Whereas 
weight is generally stated in quantitative terms and can be easily allocated  to lower level system products , other 
MOEs may be qualitative or not easily allocated and thus will need measures of performance (MOPs) derived that 
can be used as design -to requirements . MOPs are deriv ed during technical requirements definition process  activities . 
f. Validate that the resulting set of stakeholder  expectation  statements  are upward and 
downward traceable to reflect the elicited set of stakeholder expectations and that any 
anomalies  identified are resolved.  
g. Obtain commitments from customer  and other stakeholders such that the resultant set of 
stakeholde r expectation  statements  is acceptable.  
Note:  This can be done through the equivalent of a systems  requirement  review  with appropriate formalit y as a 
function of the location of the product  in the system structure , the agreement  affecting the development  effort, and 
the type of NASA product —ranging from applied research  to FS&GS . 
h. Baseline  the agreed to set of stakeholder  expectation  statements . 
Note 1:  Products  generated by the product implementation  process or product integration process  will be validated 
against this set of baselined  stakeholder  expectations . 
Note 2: The baselines  are generated and placed under change control  using the requirements  and interface 
management processes  and configuration  management process, as applicable to the formality required and the 
location of the WBS  model  in the system  structure . Initiate bidirectional traceability or expectations  and 
requirements at this point for tracking changes fro m initial stakeholder  inputs  through design  solution  definition  
outputs . 
Note 3: The baseline  information should include rational e for decisions made, assumptions with respect to the 
decisions made, and other information that will provide an understanding of the stakeholder  expectations  baseline.  
C.1.1.5  Process Flow Diagram  
a. A typical process  flow diagram  for the stakeholder  expectations  definition  process  is 
provided in Figure  C-1 with inputs  and their sources and the outputs  and their destinations. The 
activities  of the stakeholder expectations definition process are truncated to indicate the action 
and object of the action.  
This Document Is Uncontrolled When Printed.  47 b. The customer  flow-down requirements  from the design  solution  definition  process  are 
applicable at levels of the system  structure  below the top level. The other stakeholder  
expectations  are applicable at each level of the system structure to reflect the local management 
policies, applicable standards and regulations , and enabling product  support needs for the lower 
level WBS  model  products . 
 
Figure  C-1 – Stak eholder  Expectation Definition  Process  
C.1.2 Technical Requirements  Definition  Process  
C.1.2.1  Purpose  
The technical requirements  definition  process  is used to transform the baselined  stakeholder  
expectations  into unique, quantitative, and measurable technical requirements expressed as  
―shall‖ statements that can be used for defining a design  solution  definition for the WBS  model  
end product  and related enabling product s. 
C.1.2.2  Inputs  and Sources :  
a. Baselined  set of stakeholder  expectations , including interface requirements  (from 
Stakeholder Expectations Definition  and Configuration Management Processes ). 
b. Baselined  Concept of Operation (from Stakeholder  Expectations  Definition  and 
Configuration Management Processes ). 

This Document Is Uncontrolled When Printed.  48 c. Baselined  Enabling Product  Support Strategies (from Stakeholder  Expec tations  Definition  
and Configuration Management Processes ). 
d. Measures of Effectiveness  (from Stakeholder  Expectations  Definiti on and Technical Data 
Management Process es). 
C.1.2.3  Outputs  and Destinations :  
a. Set of validated technical requirements  that represents a reasonably complete descripti on of 
the problem to be solved, including interface requirements (to Logical Decomposition  and 
Requirements and Interface Management Processes ). 
b. Sets of MOPs that when met will satisfy the MOE s to which a set is related (to Logical 
Decomposition  and Technical Data Management Process es).  
c. A set of critical technical performance measures  (TPMs) that if not met will put the project  in 
cost, schedule , or performance risk (to Technical Assessment Process ). 
C.1.2.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed:  
a. Analyze the scope  of the technical problem to be solved to identify and resolve  the design  
boundar ies that identif y: (1) which system  functions are under design control  and which are 
not; (2) e xpected interaction among system functions (data flows, human responses , and 
behaviors); (3) external physical and functional interfaces (mechanical, electrical, thermal, 
data, procedural) with other systems; (4) required capacities of system products ; (5) timing of 
events, states, modes , and functions related to operational scenarios ; and (6) emerging or 
maturing technologies necessary to make requirements . 
b. Define constraints  affecting the design  of the system  or products  or how the system or 
products will be able to be used.  
Note:  Constraints  that affect the design  include physical product  constraints (e.g., color, texture, size, weight, 
buoyancy, use environment , rate of use, life -cycle  services) and human constraints (e.g., operator physical and 
performance capabilities , operator work  environment, and interfaces). Constraints are typically not able to be 
changed based on tradeoff analyses. Applicable industry standards should be referenced for possible constraints.  
c. Define functional and behavioral expectations  for the system  or product  in acceptable 
technical terms for the range of anticipated uses of system products as identified in the 
concept of operations . This permits separatin g defined  stakeholder  expectation functions and 
behaviors that belong to a lower level in the system structure  and allocat ing them to the 
appropriate level.  
d. Define the performance requirement s associated with each defined  functional and behavioral 
expectation . 
Note:  The performance requirement s are expressed as the quantitative part of a requirement to indicate how we ll 
each product  function is expected to be accomplished. Any qualitative performance expectations  should be analyzed 
and quantified , and the performance requirements that can be changed by tradeoff analysis  should be identified.  
e. Define technical requirements  in acceptable ―shall ‖ statements that are complete sentences 
with a single ―shall‖ per numbered statement and have the following characteristics: (1) 
This Document Is Uncontrolled When Printed.  49 indivi dually clear, correct, and feasible; not stated as to how it is to be satisfied; 
implementable; only one interpretation of meaning; one actor -verb-object requirement; and 
can be validated at the level of the system  structure  at which it is stated; and (2) in pairs or as 
a set, there is an absence of redundancy, consisten cy with terms used, no conflict  with one 
another, and form a set of ―design -to‖ requirements.  
f. Validate that the resulting technical requirement  statements : (1) have bidirectional  
traceability to the baselined  stakeholder  expectations ; (2) were formed using valid 
assumptions; and (3) are essential to and consistent with designing and realizing the 
appropriate product  solution form that will satisfy the applicable product -line life-cycle  phase  
exit criteria . 
g. Define MOPs for each identified measure of effectiveness  (MOE ) that cannot be directly 
used as a design -to technical requirement . 
Note:  Typically each qualitative MOE  will have two or more MOPs made up of functional and performance 
requirement  combinations. These quantitative MOPs, appropriately determined and define d, when designed in the 
design  solution  definition and met by a product  generated by the product implementation  process or product 
integration process , should help ensure that the qualitative MOEs (e.g., the seat shall be comfortable , the separation 
of the booster engines shall not cause damage to the mission  vehicle ) will be satisfied.  
h. Define a ppropriate TPMs  by which technical progress will be assessed.  
Note:  TPMs  are used for progress measurement  and must  meet certain criteria  to be a valid TPM : (1) be a 
significant qualifier of the system  (e.g., weight, range, capacity, response time, safety  parameter) that will be 
monitored at key events (e.g., inspections, planned tests ); (2) can be measured; and (3) projected progress profiles 
can be established (e.g., from historical data or based on test planning). TPMs provide an early warning method  to 
flag potential technical problems in that the project  will be put at technical performance, cost , or schedule  risk if the 
requirement  is not met. TPMs are typically selected from the MOPs.  
i. Establish the technical requirements  baseline . 
Note: The work  products  generated during the definition  of the technical requirements  should be captured along 
with key decision made, supporting decision rationale an d assumptions, and lessons learned in performing the 
technical requirements process activities  to provide an understanding of the technical requirements baseline . The 
baselines would be established and placed under chang e control  by invoking the activities of the requirements 
management , interface management , and configuration  management processes , as appropriate.  
C.1.2.5  Process Flow Diagram  
A typical process flow diagram  for the technical requirements  definition  process  is provided in 
Figure  C-2 with inputs  and their sources and the outputs  and their destinations. The activities  of 
the technical requirements definition process are truncated to indicate the action and object of the  
action.  
This Document Is Uncontrolled When Printed.  50  
Figure  C-2 – Technical Requirements  Definition  Process  
C.1.3 Logical Decomposition  Process  
C.1.3.1  Purpose   
The logical decomposition  process is used to improve understanding of the defined  technical 
requirements  and the relationships among the requirements (e.g., functional, behavioral, and 
temporal) and to transform the defined set of tec hnical requirements into a set of logical 
decomposition models and their associated set of derived technical requirements for input  to the 
design  solution  definition process . 
C.1.3.2  Inputs  and Sources : 
a. The baseline  set of validated technical requirements , including interface requirements (from 
Technical Requirements Definition  and Configuration Management  Processes ). 
b. The defined  MOPs (from Technical Requirements  Definition and Technical Data 
Management Process es). 
C.1.3.3  Outputs  and Destinations : 
a. Set o f validated derived technical requirements , including interface requirements (to Design  
Solution  Definition  and Requirements and Interface Management Processes ). 
b. The set of logical decomposition  models (to Design  Solution  Definition  and Configuration 
Management Processes ). 
c. Logical decomposition work  products  (to Technical Data Management Process es). 

This Document Is Uncontrolled When Printed.  51 C.1.3.4  Activities   
For the WBS  model  in the system  structure , the following activities are typically performed : 
a. Define one or more logical decomposition  models based on the defined  technical 
requirements  to gain a more detailed understanding and definition of the design  problem to 
be solved.  
Note 1:  The defined  technical requirements  can be decomposed and analyzed by functions, time, behavi ors, data 
flow, objects, states and modes, and failure modes and effects, as appropriate, to define sets of logical 
decomposition  models. The models may include functional flow block diagrams, timelines, data control  flow, states 
and modes, behavior diagrams, operator tasks, or functional failure modes and should be based on performance, 
cost, schedule , safety , and risk analyses.  
Note 2:  Use of existing products , which helps reduce development  time and cost , may be considered in establishing 
logical decomposition  models. New interfaces may appear with the introduction of existing produc ts. These 
interfaces need to be included in the technical requirements , thus requiring an iteration of the technical requirements 
definition  process . 
Note 3:  New technology insertion is co nsidered at this point. The use of new technologies can provide a competitive 
edge but needs to be balanced against the risks  of their insertion.  
b. Allocate the technical requirements  to the logical decomposition  models to form a set of 
derived technical requirement statements  that have the following characteristics:  
1. Describe functional and performance, service and attribute, time, and data flow 
requirements , etc. , as appropriate for the selected set of logical decomposition  models.  
2. Individually are complete sentences and are clear, correct, and feasible; not stated as to 
how to be satisfied; implementable; only have one int erpretation of meaning, one actor -
verb-object expectation ; and can be validated at the level of the system  structure  at which 
it is stated.  
3. In pairs o r as a set, have an absence of redundancy, are adequately related with respect to 
terms used, and are not in conflict  with one another.  
4. Form a set of detailed ―design -to‖ requirements . 
Note:  Traceability  for the allocated MOPs should be maintained throughout the logical decomposition  process. This 
is essential in that particular attention should be paid to demonstrating satisfaction  of the MO Ps during verification  
of a product  generated by the product implementation  process or product integration process . 
c. Resolve derived technical requ irement  conflicts.  
Note 1:  The logical decomposition  models and derived technical requirements  should be analyzed to identify 
possible conflicts. The established set of performance cri teria, cost , schedule , and risks  should be used in conducting 
tradeoff analyses for conflict  resolution . 
Note 2:  Conflicts among derived technical requirement s are always a problem. This logical decomposition  process 
activity  is designed to discover such conflicts early and resolve  them before the design  solution definition  is too far 
underway. Understanding the problem to be solved in more detail is helpful for obtaining a better and more cost -
effective design solution definition.  
d. Validate that the res ulting set of derived technical requirements  have: (1) bidirectional  
traceability with the set of validated technical requirements and (2) assumptions and decision 
rationale s consistent with the source set of technical requirements.  
Note 1:  There may be some technical requirements  that cannot be allocated to the logical decomposition  models. If 
so, then these should be allocated directly to the physical entities that will make up the al ternatives for design  
solution  definition . 
This Document Is Uncontrolled When Printed.  52 Note 2:  Bidirectional requirements  traceability is used for tracking changes to the technical requirements based on 
the logical decom position  models and their allocated derived technical requirements.  
e. Establish the derived technical requirements  baseline .  
Note 1:  The baselines  would be established and  placed under change control  by invoking the activities  of the 
requirements  management , interface management , and configuration  management proce sses, as appropriate.  
Note 2:  The work  products  generated during the definition  of the derived technical requirements  should be captured 
along with key decision made, su pporting decision rationale and assumptions, and lessons learned in performing the 
logical decomposition  process activities  to provide an understanding of the derived technical requirements baseline  
and the logical decomposition models and  to permit traceability to technical requirements, stakeholder  expectations , 
and logical decomposition models.  
C.1.3.5  Process Flow Diagram  
A typical process flow diagram  for logical decomposition  is provided in Figure  C-3 with inputs  
and their sources and the outputs  and their destinations. The activities  of the logical 
decomposition process are truncated to indicate the action and object of the action.  
 
Figure  C-3 – Logical Decomposition  Process  
C.1.4 Design Solution  Definition  Process  
C.1.4.1  Purpose   
The design  solution  definition  process  is used to translate the outputs  of the logical 
decomposition  process into a design solution definition that is in a form consistent with the 
product -line life-cycle  phase  and WBS  model  location in the system  structure  and that will 
satisfy phase exit criteria . This includes transforming the defined logical decomposition models 
and their associated sets of derived technical requirements  into alternative solutions , then 
analyzing each alternative to be able to select a preferred alternative  and fully define that 
alternative into a final design solution that will satisfy the technical requirements. These design 

This Document Is Uncontrolled When Printed.  53 solution definitions will be used for generating end product s either by using the product 
implementation  process or product integration process  as a function of the position of the WBS 
model in the system structure and whether there are additional subsystems of the end produc t 
that need to be defined. The output definitions from the design solution (end product 
specifications ) will be used for conducting product verification . 
C.1.4.2  Inputs  and Sources:  
a. A baselined  set of logical decomposition  models (from Logical Decomposition and 
Configuration Management Processes ). 
b. A baseline  set of derived technical requirements  including interface requirements (from 
Logical Decomposition  and Configuration Management Processes ). 
Note:  If there were unallocated technical requirements , these requirement s would also be input s to the design  
solution  definition  process .  
C.1.4.3  Outputs  and Destinations:  
The specified requirements  that describe the system  design  solution  definition  for the products  of 
the WBS  model  under development  include:  
a. A WBS  model  design  solution  definition  set of requirements  for the system  (see WBS 
definition in Appendix A), including specification  configuration  documentation and external 
interface specification (to Requirements and Interface Managem ent Process).  
b. A baseline  set of ―make -to,‖ ―buy -to,‖ ―reuse -to,‖ or set of ―assemble and integrate -to‖ 
specified requirements  (specifications  and configuration  documents ) for the desired end product  
of the WBS  model , including interface specifications (to  Requirements and Interface 
Management Process).  
Note:  The specifications  should include not only the product  characteristics and functional and performance 
requirement s, but also how each requir ement will be evaluated during verification  and/or acceptance tests . 
c. The initial specifications  for WBS  model  subsystems for flow down to the next applicable 
lower level WBS models, including interface specifications (to Stakeholder  Expectations  
Definition , and Requirements  and Interface Manage ment Processes ). 
Note:  If there is not a need for further development  of end product  subsystems, the product implementation  process 
is the applicable destination of the end product specified requirements . (See C.1.4. 2 above.)  
d. The requirements  for enabling product s that will be needed to provide life-cycle  support to 
the end product s, including interface requirements (to Stakeholder  Expectations  Definition  
Process fo r development  of enabling products or to Product Implementation  Process for 
acquisition of existing enabling products, and Requirements and Interface Management 
Processes ). 
e. A product  verification  plan that will be used to demonstrate that the product generated from 
the design  solution  definition  conforms to the design solution definition spe cified requirements  
(to Product Verification Process).  
Note:  The technical planning process should be used to develop this plan  based on the product  design  solution  
definition  process  activities  and the product verification  process activities.  
This Document Is Uncontrolled When Printed.  54 f. A product  validation  plan that will be use d to demonstrate that the product generated from 
the design  solution  definition  conforms to its set of stakeholder  expectations  (to Product 
Validation Proce ss). 
Note:  The technical planning process should be used to develop this plan  based on the product  design  solution  
definition  process  activi ties and the product validation  process activities.  
g. Baseline  operate -to and logistics  procedures (to Technical Data Management Process ). 
C.1.4.4  Activi ties 
For the WBS  model  in the system  structure , the following activities  are typically perform ed: 
a. Define alternative solutions  for the system  end product  being developed or improved that are 
consistent with derived technical requirements  and nonallocated technical requirements, if 
any. 
Note 1:  The derived technical requirements  should be partitioned based on their associated logical decomposition  
model  to potentia l physical elements that will make up the end product  (e.g., hardware, software , human/manual 
operations , data, processes , and/or composites of th ese).  
Note 2:  Alternative solutions can be formed by packaging the physical elements in such a way that the derived 
technical requirements  will be satisfied.  
Note 3:  Criteria  should be established by which alternative  solutions  can be evaluated.  
b. Analyze each alternative solution  against defined  criteria , such as satisfaction  of external 
interface requirements ; technology requirements; off -the-shelf availability of products ; 
physical failure modes, effects , and criticality; life-cycle  cost and support considerations; 
capac ity to evolve; make vs. buy; standardization of products; integration  concerns; and 
context of use issues of operators considering tasks, location, workplace equipment, and 
ambient conditions.  
c. Select the best solution alternative based on the analysis  results  of each alternative solution  
and technical decision analysis recommendations.  
Note:  The decision analysis process  is used to make an evaluated recommendation of the best or favored solution.  
d. Generate the full design  description of the selected alternative solution  in a form appropriate 
to the product -line life-cycle  phase , location of the WBS  model  in the system  structure , and 
phase exit criteria  to include: (1) system specification  and external interface specifications; 
(2) end product  specifications, configuration  description documents , and interface 
specifications; (3) end product subsystem initial specifications, if subsystems are required; 
(4) requirements  for associated supporting enabling product s; (5) end product verification  
plan; (6) end product validation  plan; and (7) applicable logistics  and operate -to procedures.  
Note 1:  The first application  of the system  design  processes  to develop a system structure  typically results  in a set of 
top-level requirements  and one or more concepts. The form of design solution  definition  output  could be, for 
example, a simulation  model  or paper study report.  
Note 2:  The output  of the design  solution  definition  process  is typically called a technical data package. This 
package evolves from phase  to phase  starting with conceptual sketches or models and ending before fabrication, 
assembly and integration  of the product  with complete drawings, parts list , and other details needed for product 
implementation  or product integration.  
Note 3:  Branches of the system  structure  tree end when there are no subsystems needed to make up an end product  
within a WBS  model . At that point the end product can be made, bought , or reused using the product 
implementation  process. Any end product that consists of lower l evel subsystem products will be realized by the 
This Document Is Uncontrolled When Printed.  55 product integration process . The form of the product will be dependent on the product -line life -cycle  phase , the 
location of the WBS model in the system structure, and the phase exit criteria . 
Note 4: The operational concept for the end product  should be updated to reflect the design  solution  definition  
selected.  
e. Verify that the design  solution  definition : (1) is realizable within constraints  imposed on the 
techni cal effort; (2) has specified requirements  that are stated in acceptable statements and 
have bidirectional  traceability with the derived technical requirements, technical 
requirements , and stakeholder  expectations ; and (3) has decisions and assumptions made in 
forming the solution consistent with its set of derived technical requirements, separately 
allocated technical requirements, and identified system  product  and service constraints.  
Note 1:  The use of peer reviews  is recommended to evaluate  the resulting design  solution  definition  documentation 
against a set of established criteria  consistent with the product -line life-cycle  phase  exit criteria  and the WBS  
model ’s location in the system  structure . 
Note 2:  Identified anomalies  should be resolved during the verification  of the design  solution  definition . 
f. Baseline  the design  solution  definition  specified requirements  including the specifications  
and configuration  descriptions.  
Note:  The baselines  would be established and placed under change and/or configuration  control  by invoking the 
activities  of the requirements  management , interface management , and configuration management processes , as 
appropriate.  
g. Initiate development  or acquisition of the life -cycle  supporting enabling product s needed, as 
applicable, for research, development, fabrication, integration , test , deployment, operations , 
sustainment , and disposal .  
Note 1:  Schedules  should be such that the enabling product s will be available when needed to support the product -
line life-cycle  phase  activities . 
Note 2:  Development of enabling product s and services rel ies on the same processes  used to develop their 
associated operational products  in the WBS  model . 
h. Initiate development  of the system  products  of the next lower level WBS  model , if any.  
Note 1:  Development of the next lower level of system  products  using the same design  processes  is an example of 
the recursive application  of the repeatable  system design processes.  
Note 2:  If this activity  is not applicable , then the end pro duct should be reviewed for making, buying , or reuse using 
the product implementation  process.  
C.1.4.5  Process Flow Diagram  
A typical process flow diagram  for design  solution  definition  is provided in Figure  C-4 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the design 
solution definition process  are truncated to indicate the action and object of the action.  
 
This Document Is Uncontrolled When Printed.  56  
Figure  C-4 – Design  Solu tion Definition  Process  
C.2 Product Realization Processes   
There are five product  realization processes . Four of the product realization processes are applied 
to each end product  of a WBS  model  from the bottom to the top of the system  structure : (1) 
either product implementation  or product integration , (2) product verification , (3) product 
validation , and (4) product transition . (See Figure  3-2.) The form of the end product realized will 
depend on the applicable product -line life-cycle  phase , location within the system structure of the 
WBS model containing the end product, and the exit criteria  of the phase. Typical early phase 
products are in the form of reports, models, simulations, mockups, prototypes, or demonstrators. 
Later phase product forms include the final mission  products , including payloads and expe riment 
equipment. For software  aspects of the system , the technical team  should ensure the product 
realization requirements  comply with  NPR  7150.2 , NASA Software Engineering Requirements . 
The product realization process descriptions that follow assume that each lowest level product 
goes through the sequencing shown in Figure C -5. Exceptions will need to be planned according  
to what has and has not been already performed.  

This Document Is Uncontrolled When Printed.  57  
Figure  C-5 –Sequencing of Product Realization Processes  
C.2.1 Product Implementation  Process  
C.2.1.1  Purpose   
The product  implementa tion process is used to generate a specified product of a WBS  model  
through buying, making, or reusing in a form consistent with the product -line life-cycle phase  
exit criteria  and that satisfies the design  solution  definition  specified requirements  (e.g., 
drawings, specifi cations ). 
C.2.1.2  Inputs  and Sources:  
a. Raw materials needed to make the end product  (from existing resources or external sources).  
b. End product  design  solution  definition  specified requirements  (specifications ) and 
configuration  documentation for the end product  of the applicable WBS  model , including 
interface specifications, in the form appropriate to satisfying the product -line life-cycle  phase  
exit criteria  (from Configuration Management Process).  
c. Product implementation  enabling product s (from existing resources or Product Tran sition  
Process  for enabling product  realization).  
C.2.1.3  Outputs  and Destinations:  
a. Made, bought , or reuse d end product  in the form appropriate to the product -line life-cycle  
phase  and to satisfy exit criteria  (to Product Verification Process).  
Note:  For early life -cycle phases , products  generated by the product implementation  process can be in the form o f 
reports, models, simulations, mockups, prototypes, and demonstrators. In later phases , the form may be mission -
ready products including payloads and experiment equipment.  

This Document Is Uncontrolled When Printed.  58 b. Documentation and manuals  in a form appropriate for satisfying the life-cycle  phase  exit 
criteria , including ―as-built‖ product  descriptions and ―operate -to‖ and maintenance  manuals 
(to Technical Data Management Process ). 
Note:  ―As-built‖ descriptions include materials for made, bought or reuse d products . For early life -cycle phases , 
documents  can be in draft form. In later phases , the documents/manuals  should be in mission - or experime nt-ready 
procedural form.  
c. Product implementation  work  products  needed to provide reports, records , and undeliverable  
outcomes of process activities  (to Technical Data Management Proces s). 
C.2.1.4  Activities  
For the WBS  model  in the system  structure , the following a ctivities  are typically performed : 
a. Prepare to conduct product  implementation  including:  (1) prepar e a product implementation 
strategy and detailed planning and procedures and (2) determin e whether the product 
configuration  documentation is adequately complete to conduct the type of product 
implementation as applicable for the product -line life-cycle  phase , location of the prod uct in 
the system  structure , and phase exit criteria . 
b. If the strategy is for buying an existing product , participate in the buy of the product 
includin g: (1) review  the technical information made available by vendors; (2) assist the 
preparation  of requests for acquiring the product from a vendor; (3) assist the inspection of 
the delivered product and the accompanying documentation; (4) determin e whether the 
vendor conducted product validation  or if it will need to be done by a project  technical team ; 
and (5) determin e  the availability of enabling produ cts to provide test , operations , and 
maintenance  support and disposal  services for the product.  
c. If the strategy is to reuse a product  that exists in the Government inventory, participate in 
acquiring the reuse d product including: (1) review  the technical information made available 
for the specified product to be reused; (2) determin e supporting documentati on and user 
manuals ’ availability; (3) determin e the availability of enabling product s to provide test , 
operations , and maintenance  support and disposal  services for the product; ( 4) assist the 
requests for acquiring the product  from Government sources; and ( 5) assist the inspection of 
the delivered product and the accompanying documentation.  
d. If the strategy is to make the product ,  
1. Evaluate  the readiness  of the product  implementation  enabling product s to make  the 
produ ct. 
2. Make the specified product  in accordance with the specified requirements , configuration  
documentation, and applicable standards.  
3. Prepare appropriate product  support documentat ion, such as integration  constraints  and/or 
special procedures for performing product verification  and product validation . 
e. Capture work  products  and related information generated while performing the product 
implementation  process activities .  
This Document Is Uncontrolled When Printed.  59 Note:  Work  products  include procedures used, rationale for decisions made, assumptions  made in product 
implementation , and decisions made, actions taken to correct identified anomalies , lessons learned in performing the 
product implementation activities , and update d product config uration  and support documentation.  
C.2.1.5  Process Flow Diagram  
C.2.1.5.1  A typical process flow diagram  for product  implementation  is provided in Figure  C-6 
with inputs  and their sources and outputs  and their destinations. The activities  of the product 
implementation process are truncated to indicate the ac tion and object of the action.  
C.2.1.5.2  The path that products  from the three sources in Figure  C-6 take with respect to 
product verification , product validation , and product transit ion vary based on:  
a. Whether the products  bought have been verified and/or validated by the vendor.  
b. Whether reuse products  that come from within the organization  have been ver ified and/or 
validated.  
c. Whether the customer  for the product  desires to do the product validation  or have the 
developer perform the product validation.   
 
Figure  C-6 – Product Implementat ion Process  
C.2.2 Product Integration  Process  
C.2.2.1  Purpose   
The product  integration process  is used to t ransform the design  solution  definition  into the 
desired end product  of the WBS  model  through as sembly and integration of lower level validated 
end products in a form consistent with the product -line life-cycle  phase  exit criteria  and that 
satisfies the design solution definit ion requirements  (e.g., drawings, specifications ). 

This Document Is Uncontrolled When Printed.  60 C.2.2.2  Inputs  and Sources:  
a. Lower level products  to be assembled and integrated  (from Product Transition  Process ). 
b. End product  design  definition  specified requirements  (specifications ) and configuration  
documentation for the applicable WBS  model , including interface specifications, in the form 
appropriate to satisfying the product -line life-cycle  phase  exit criteria  (from Configuration 
Management Process).  
c. Product integration  enabling product s (from existing resources or Product Trans ition Process  
for enabling product  realization).  
C.2.2.3  Outputs  and Destinations:  
a. Integrated product (s) in the form appropriate to the product -line life-cycle  phase  and to 
satisfy phase exit criteria  (to Product Verification Process) . 
Note:  For early life -cycle phases , products  generated by the product i ntegration process  can be in the form o f 
reports, models, simulations, mockups, prototypes, and demonstrators. In later phases , the form may be in mission -
ready products includ ing payloads and experiment equipment.  
b. Documentation and manuals  in a form appropriate for satisfying the life-cycle  phase  exit 
criteria , including ―as -integrated ‖ product  descriptions and ―operate -to‖ and maintenance  
manuals (to Technical Data Management Process ). 
Note:  ―As-integrated ‖ descriptions include descriptiv e materials for integrated products . For early life -cycle phases , 
documents  can be in draft form. In later phases , the documents  or manuals  should be in mission - or experiment -
ready procedural form.  
c. Product integration  work  products  needed to provide reports, records , and undeliverable  
outcomes of process activities  (to Technical  Data Management Process ). 
C.2.2.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare to conduct product  integration  to include : (1) preparing a product integration 
strategy, detailed planning for the integration, and in tegration sequences and procedures; and 
(2) determining whether the product configuration  documentation is adequately complete to 
conduct the type of product integration applicable for the product -line life-cycle  phase, 
location of the product in the system  structure , and management phase exit criteria . 
b. Obtain lower level products  required to assemb le and integrate  into the desired product.  
c. Confirm that the received products  that are to be assembled and integrated  have been 
validated to demonstrate that the individual products satisfy the agree d upon  set of 
stakeholder  expectations , including interfaces requirements . 
Note:  Documented evidence that the correct products  are provided for this activity  is necessary. This validation  can 
be completed by the providing organization  or by an assigned technical team  within the project . 
d. Prepare the integration  environment  in which assembly and integration will take place  to 
include evaluating the readiness  of the product -integration enabling product s and the 
assigned workforce .  
This Document Is Uncontrolled When Printed.  61 Note:  The product  integration  enabling product s include, as a function of the product -line life -cycle  phase , facilities , 
equipment, jigs, tooling, and assembly areas/lines . The integration environment  includes test  equipment, simulators 
(for products not available), storage  areas, and recording devices.  
e. Assemble and integrate  the received products  into the desired end product  in accordance with 
the specified requirements , conf iguration  documentation, interface requirements, applicable 
standards, and integration sequencing and procedures.  
Note:  This activity  includes managing , evaluating, and controlling physical, func tional, and data interfaces among 
the products  being integrated .  
f. Prepare appropriate product  support documentation , such as special procedures for 
performing product verification  and product validation . 
g. Capture work  products  and related information generated while performing the product 
integration process  activities .  
Note:  Work  products  include procedures used, rationale for decisions made, assumptions made in product 
integration , and decisions made, actions taken to correct identified anomalies , lessons learned in performing the 
product integration process  activities , and updated product configuration  and support documentation.  
C.2.2.5  Process Flow Diagram  
A typical process flow diagram  for product  integration  is provided in Figure  C-7 with inputs  and 
their sources and the outputs  and their destinations. The activities  of the product integration 
process  are truncated to indicate the action and object of the action.  
 
This Document Is Uncontrolled When Printed.  62  
Figure  C-7 – Product Integration  Process  
C.2.3 Product Verification Process  
C.2.3.1  Purpose   
The product  verification  process is used to demonstrate that an end product  generated from 
product implementation  or product integration  conforms to its design  solution  definition  
requirements  as a func tion of the product -line life-cycle  phase  and the location of the WBS  
model  end product in the system  structure . Special attention is given to demonstrating 
satisfaction  of the MOPs defined for each MOE  during conduct of the technical requirements 
definition process . 
Note:  Product verification  can be accomplished by inspections, analyses, demonstrations, or test  in accordance with 
the verification plan  and as a function of the product -line life-cycle  phase . 
C.2.3.2  Inputs  and Sources:  
a. End product  to be verified (from Product Implementation  Process or Product Integration  
Process).  
b. End product  specification  and configuration  baselines , including interface specifications, to 
which the product being verified was generate d (from Technical Data Management Process ). 
Note:  The baselines  would be updated design  solution  definition  specifications  and configuration  documents  based 
on corrections made during product  implementation  or product integration . 

This Document Is Uncontrolled When Printed.  63 c. Product verification  plan (from Design  Solution  Definition  Process and Technical Planning 
Process)  
d. Product verification  enabling product s (from existing resources or Product Transition  Process  
for enabling product  realization).  
C.2.3.3 Outputs  and Destinations:  
a. A verified end product  (to Product Validation  Process).  
b. Product verification  results  (to Technical Assessment Process ). 
c. Completed verification  report to include for each specified requirement : (1) the source 
paragraph references from the baseline  documents  for derived technical requirements, 
technical requirements , and s takeholder  expectations ; (2) bidirectional  traceability among 
these sources; (3) verification type(s) to be used in performing verification of the specified 
requirement; (4) reference  to any special equipment, conditions , or procedures for 
performing the verification; (5) results  of verification conducted; (6) variations, anomalies , or 
out-of-compliance  results; (7) corrective a ctions taken; and (8) results of corrective actions 
(to Technical Data Management Process ). 
Note:  The information in this report is captured in what is often referred to as a verification  matrix . This matrix is 
typically established and maintained once requirements  traceability is initiated after obtaining stakeholder  
commitment to the set of stakeholder expectations . 
d. Product ver ification  work  products  needed to provide reports , records,  and undeliverable  
outcomes of process activities  (to Technical Data Management Process ). 
C.2.3.4 Activities  
For the WBS  model  in the system  structure , the following activities  are typicall y performed : 
a. Prepare to conduct product  verification  to include as applicable to the product -line life-cycle  
phase  and WBS  model  location in the system  structure : (1) reviewing the product verification 
plan for specific procedures, constraints , conditions under which verification wi ll take place, 
pre- and post -verification actions, and criteria  for determining the success or failure of 
verification methods  and procedures; (2) arranging the needed product -verification enabling 
product s and support resources; (3) obtaining the end product  to be verified; (4) obtaining the 
specification  and configuration  baseline  against which the verification is to be made; and (5) 
establishing and checking the verification environment  to ensure readiness  for performing the 
verification.  
b. Perform the product  verifica tion in accordance with the product verification plan  and defined  
procedures to collect data on each specified requirement  with specific attention given to 
MOPs.  
Note:  Perform agai n any product  verification  steps that were not in compliance  with planned product verification 
procedures or the planned environment  including equipment, measurement , or data capture failures.  
c. Analyze the outcomes of the product  verification , includ ing identif ying verification 
anomalies , establishing recommended corrective actions, and establishing conform ance to 
each specified requirement  under controlled conditions.  
This Document Is Uncontrolled When Printed.  64 Note:  Corrective actions should be assessed using the technical assessment process  and decision analysis process  
with recommendations made and executed by planning the technical effort  again , repeating the system  design  
processes , and/or repeating the product  verifi cation . 
d. Prepare a product  verification  report providing the evidence of product conformance with the 
applicable design  solution  definition  specified requirements  baseline  to which the product 
was generated , including bidirectional  requirements traceability and actions taken to correct 
anomalies  of verification results . 
Note:  The recommended content of this report is provided in C.2.3.3.c.  
e. Capture the work  products  from the product verification .  
Note:  Work  products  include verification  outcomes; records of procedural steps taken against planned procedures; 
any failures or anomalies  in the planned verification procedures, equipment, or environment ; and records citing 
satisfaction  or nonsatisfaction of verification criteria . Also records should document : 
1) the v ersion of the set of specification  and configuration  documentation  used; 
2) the v ersion of the end product  verified;  
3) the v ersion or standard for tools  and equipment used, together with applicable calibration d ata; 
4) results  of each verific ation  including pass or fail declarations; and  
5) discrepanc ies between expected and actual results . 
C.2.3.5  Process Flow Diagram  
A typical process flow diagram  for product  verification  is provided in Figure  C-8 with inputs  and 
their sources and the outputs  and their destinations. The activities  of the product verification 
process are truncated to indicate the action and object of the action.   
 
Figure  C-8 – Product Verification Process  

This Document Is Uncontrolled When Printed.  65 C.2.4 Product Validation  Process  
C.2.4.1  Purpose   
The product  validation  process is used to confirm that a verified end product  generated by 
product implementation  or product integration  fulfills (satisfies) its in tended use when placed in 
its intended environment  and to assure that any anomalies discovered during validation are 
appropriately resolved prior to delivery of the product (if validation is done by the supplier of the 
product) or prior  to integration wi th other products into a higher level assembled product (if 
validation is done by the receiver of the product). The validation is done against the set of 
baselined  stakeholder  expecta tions . Special attention should be given to demonstrating 
satisfaction  of the MOEs identified during conduct of the stakeholder expectations definition  
process . The type of product validation is a function of the form of the product, product -line life-
cycle  phase , and applicable customer  agreement . 
Note 1:  A product should be validated aga inst its stakeholders’ expectations  before being integrated  into a higher 
level product . 
Note 2:  Early in the life cycle , product  validation  is conducted through simulation , inspection, analysis , or test , as 
appropriate.  
Note 3:  Later in the life cycle , product  validation  can be do ne through certification tests  against established 
requirements  or acceptance tests using operational processes  and personnel in an operational environment , where 
possible and as applica ble.  
C.2.4.2  Inputs  and Sources:  
a. End product  to be validated (from Product Verification Process).  
b. Baselined s takeholder  requirements  (from Configuration Management P rocess).  
Note:  The baselines  would be updated based on corrections made during product  implementation  or product 
integration  or as a result of correcting verification  anomalies . 
c. Product validation  plan (from Design  Solution  Definition  Process and Technical Planning 
Process)  
d. Product validation  enabling product s (from existing resources or Product Transition  Process  
for enabling product  realization).  
C.2.4.3  Outputs  and Destinations:  
a. A validated end product  (to Transition  Process ). 
b. Product validation  results  (to Technical Assessment Process ). 
c. Completed validation  report for each stakeholder  expectation  or subset of stakeholder 
expectations involved with the validation, for example: (1) the source requirement  paragraph 
reference  from the stakeholder expectations baseline ; (2) validation type(s) to be used in 
establishing compliance  with selected set of stakeholder expectations and match with each 
source expectation referenced; (3) identification of any special equipment, conditions , or 
procedures for performing the validation , which  includes referenced expectation; (4) results  
of validation conducted with respect to the referenced expectation; (5) deficiency findings 
(variations, anomalies , or out -of-compliance results); (6) corrective actions taken; and (7) 
results of corrective actions (to Technical  Data Management Process ). 
This Document Is Uncontrolled When Printed.  66 Note:  The information in this report is captured in what is often referred to as a validation  cross -reference  matri x. 
This matr ix is typically established and maintained once requirements  traceability is initiated after obtaining 
stakeholder  commitment to the set of stakeholder expectations  and establish ing the stakehol der expectations 
baseline . 
d. Product validation  work  products  needed to provide reports , records,  and undeliverable  
outcomes of process activities  (to Technical Data Managem ent Process ). 
C.2.4.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare to conduct product  validation  including,  as applicable to the product -line life-cycle  
phase  and product location i n the system  structure : (1) reviewing the product validation plan  
for specific procedures, constraints , conditions under which validatio n will take place, pre - 
and post -validation actions, and criteria  for determining the success or failure of validation 
methods  and procedures; (2) arranging the needed product -validation enabling product s and 
support resources; (3) obtaining the end product  to be validated; (4) obtaining the stakeholder  
expectations  baseline  against which the valid ation is to be made; and (5) establishing and 
evaluating  the validation environment  to ensure readiness  for performing the validation.  
Note:  Product validation  environmental considerations include: measurement  tools  (scopes, electronic devices, 
probes); temporary embedded test  software ; recording equipment (capture test results ); simulated subsystems in the 
loop (by softw are, electronics, or mechanics); simulated external interfacing products  of other systems /products 
(representations of external threats or constraints ); actual external interfacing products of other syste ms (aircraft, 
vehicles, boosters, humans); facilities ; and skilled operators.  
b. Perform the product  validation  in accordance with the product validation plan  and defined  
procedures to collect data on performance of the product against stakeholder  expectations  
with specific attention given to MOEs.  
Note 1:  Perform again any validation  steps that were not in compli ance with planned validation procedures or the 
planned environment  including equipment, measurement , or data capture failures.  
Note 2:  The validation  environment  may be a representative or simulated environment when it is not possible or 
cost prohibitive to use the operational environment . 
c. Analyze the outcomes of the product  validation  to include identif ying validation anomalies, 
establishing recommended corrective actions, and establishing conformance to stakeholder  
expectations  under operational conditions (actual, analyzed , or simulated).  
Note:  Corrective actions shoul d be assessed using the technical assessment process  and decision analysis process  
with recommendations made and executed by planning the technical effort  again, repeating the system  design  
processes , and/or repeating the product  validation . 
d. Prepare a  product  validation  report providing the evide nce of product conformance with the 
stakeholder  expectations  baseline , including corrective actions taken to correct anomalies of 
validation results . 
Note:  The recommended content of  this report is provided in C.2.4.3.c.  
e. Capture the work  products  from the product validation . 
Note:  Work  products  include validation  outcomes; records of proc edural steps taken against planned procedures; 
any failures or anomalies in the planned validation procedures, equipment, or environment ; and records citing 
satisfaction  or nonsatisfaction of validation  criteria . Also records should document : 
1) the v ersion of the stakeholder  expectations  baseline  used; 
This Document Is Uncontrolled When Printed.  67 2) the v ersion of the end product  validated ; 
3) the v ersion or standard for tools  and equipment used, together with applicable calibration data ;  
4) results  of the product  validation  including pass or fai l declarations ; and  
5) discrepanc ies between expected and actual results . 
C.2.4.5  Process Flow Diagram  
A typical process flow diagram  for product  valid ation  is provided in Figure  C-9 with inputs  and 
their sources and the outputs  and their destinations. The activities  of the product validation 
process are truncated to ind icate the action and object of the action.  
 
Figure  C-9 – Product Validation  Process  
C.2.5 Product Transition  Process  
C.2.5.1  Purpose  
The product  transition  process  is used to transition  to the customer  at the next level in the system  
structure  a verified and validated en d product  that has been generated by product implementation  
or product integration  for integration into an end product . For the top level end product, the 
transition is to the intended end user. The form of the product transitioned will be a function of 
the product -line life-cycle  phase  exit criteria  and the location wi thin the system structure of the 
WBS  model  in which the end product exits.  
Note 1:  Planning for transition  includes preparation  of packaging, handling, transporting, storing, training  or 
certification activities  and operations , users, or installation manuals  as appropriate for the product -line life-cycle  
phase  and the location of the end product  in the system  structure . 

This Document Is Uncontrolled When Printed.  68 Note 2:  Depending on the agreem ent and the product -line life-cycle  phase , the product transition  process  may 
include installation, training , and sustainment  tasks.  
Note 3:  For transitions during early life -cycle phases , products  may be in paper form, electronic form, physical 
models, or technology demonstration prototypes. During later life-cycle phases , products may be a one -of-a-kind 
operational/mission  product or one of many to be produced and delivered in a single package or container.  
C.2.5.2  Inputs  and Sources:  
a. End product  or products to be transitioned (from Product Validation  Process).  
b. Documentation including manuals , procedures , and processes  that are to accompany the end 
product  (from Technical Data Management Process ). 
Note:  In early product -line life-cycle phases , these manuals  and documents  would be in draft. In later phases , the 
manuals and documents should be in a form ready for use and should have been verified and/or validated that they 
meet end product  and user support needs.  
c. Product transition  enabling product s to include packaging materials, containers, handling 
equipment, and storage, receiving and shipping facilities  (from exis ting resources or Product 
Transition  Process  for enabling product  realization).  
C.2.5.3  Outputs  and Destinations:  
a. Delivered end product  with applicable documentation including manuals , procedures , and 
processes  in a form consistent with the product -line life-cycle  phase  and locati on of the 
product in the system  structure  (to end user or Product Integration  Process —recursive loop).  
Note 1:  If a physical form of the product  is delivered, the product should have been transitioned in protective 
packaging by appropriate handling and transporting mechanisms and/or stored in appropriate protective 
environments . 
Note 2:  If the end pr oduct  is an enabling product  providing life -cycle  support (e.g., for product implementation , 
product int egration , product verification , product validation , or product transition  for the end product), the 
development  or acquisition of the enabling produ ct is needed to be initiated early so that it will be available when 
needed.  
Note 3:  The manuals  and documents  to be considered for delivery with the end product  are the training  modules, 
installation manuals , and operations  and sustaining engineering  processes  to prepare  users, installers, or maintainers 
to do their  functions with respect to the transitioned product.  
b. Product transition  work  products  needed to provide reports , records,  and undeliverable  
outcomes of process activities  (to Tech nical Data Management Process ). 
c. Realized enabling product s from existing enabling products  and services or realized products 
from applying the common techn ical processes  (to Product Implementation , Integration, 
Verification, Validation  and Transition  Process es, as  appropriate)  
C.2.5.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare to conduct product  transition  to include : (1) preparing a product implementation  
strategy to establish  the type of produc t transition  to be made (to the next higher level 
customer  for product integration  or to an end user); and (2) reviewing related end product  
stakehold er expectations  and design  solution  definition  specified requirements  to identify 
special transition procedures and enabling product  needs for the type of product transition, if 
This Document Is Uncontrolled When Printed.  69 any, for packaging, storage, handling, shipping/transporting, site preparation , installation , or 
sustainment . 
Note 1:  The product -line life-cycle  phase  and the location of the end product  in the system  structure  will influence 
the form of the end product and the packaging, storage, handling, and shipping/transporting required.  
Note 2:  The requirements  for readying the product  for transition are typically addressed in  stakeholder  expectations  
and end product  design  solution  definition  specified requirements. Included are packaging  requirements for 
protection, security , and prevention of deterioration for products placed in storage or when it is necessary to 
transport or ship between and within organizational facilities  or between organizations by land, air , and/o r water 
vehicles. The end product  requirements  should state the spectrum of environmental and stress conditions specified 
for the package. Particular emphasis needs to be on protecting surfaces from physical damage  and preventing 
corrosion, rodent damage t o electronic wiring or cabling, shock or stress damage, heat warping or cold fractures, and 
moisture and other particulate intrusion that would damage moving parts. Other packaging considerations include: 
economy and ease of handling or transporting (e.g.,  containerization); accountability (e.g.,  tracking system in 
transit ); and ease and safety  of unpacking (e.g.,  shrink wrapping,  sharp edges, strength of binding materials, 
environmental hazards of packing materials, weight).  
Note 3:  The requ irements  for transporting the end product  are typically addressed in enabling product  requirements. 
Factors to consider inclu de: safety  to the product, property , and humans during moving; cost  of transport options in 
terms of acquisition, installation, and maintenance ; distances involved; environments  through w hich the product will 
move; volume, space and weight restrictions on transport options; and handling to/from locations/transporters.  
b. Evaluate  the end product , personnel, and enabl ing product  readiness  for product transition  
including: (1) availability and appropriateness of the documentation that will be packaged 
and shipped with the e nd product; (2) adequacy of procedures for conducting product 
transition ; (3) availability and skills  of personnel to conduct product transition; and (4) 
availability of packaging materials/cont ainers, handling equipment, storage facilities , and 
shipping/transporter services.  
Note:  Evaluations should include, as applicable: (1) packaging, handling, shipping, and storage procedures; (2) 
installation procedures; (3) use instructi ons; and (4) other relevant documentation such as manuals  and processes  for 
developers, users, operators, trainers, installers, and support personnel.  
c. Prepare the end product  for transition  to include the packaging and moving the product to the 
shipping/transporting location and any intermediate storage.  
d. Transition  the end product  with required documentation to the customer , based on the type of 
transition required, e.g., to the next higher level WBS  model  for product integration  or to the 
end user.  
e. Prepare sites, as required, where the end product  will be stored, assembled, integrated , 
installed, used, or m aintained, as appropriate for the life-cycle  phase , position of the end 
product in the system  structure , and customer  agreement .  
Note:  This may include making the end product  ready for assembly and integration  into an upper level product; 
bringing the product to operational/mission  readiness  (with appropriate acceptance and certification tests  having 
been completed); placing the product into operation/use; training  personnel such as users, operators, and 
maintainers; or providing in -service support (sustainment ) of the end product for operations /use, monitoring, and 
maintenance . 
f. Capture work  products  from product transition  process  activities . 
Note:  Work  products  include procedures used, rationale for decisions made, assumptions made in product transition , 
and dec isions made, actions taken to correct identified anomalies , lessons learned in performing the product 
transition process  activities , and updated support documentation.  
This Document Is Uncontrolled When Printed.  70 C.2.5.5  Process  Flow Diagram  
A typical process flow diagram  for product  transition  is provided in Figure  C-10 with inputs  and 
their sources and the outputs  and their destinations. The activities  of the product transition 
process  are truncated to indicate the action and object of the action.  
 
Figure  C-10 – Product Transition  Process  
C.3 Technical Management Processes  
There are eight technical management processes —Planning, Requirements  Management, 
Interface Management, Risk Management, Configuration Management, Technical Data 
Management, Assessment, and Decision Analysis . (See Figure  3-2.) These technical 
management processes are intended to su pplement the management requirements defined  in 
NPR  7120.5. NPR 7120.5 provide s program  and project  manager s with the technical activities  
that they are required to be cognizant of and are responsible for. On the other hand , the technical 
management process in this SE NPR : (1) provide s the technical team  its requirements for 
planning, monitoring , and controlling the technical effort as well as the technical decision 
analysis requirements for performing tradeoff and effectiveness analy ses to support decision  
making  throughout the technical effort;  (2) focus es on (a) completion of technical process 
planning (preparation  of the SEMP  and other technical plans), (b) technical progress assessment  
(using technical measures and conducting technical review s to assess progress against the S EMP 
and defined technical requirements), and (c) control  of product  requirements, product interfaces, 
technical risks , configurations, and technical data ; and (3) ensur es that common technical process 
impleme ntation s comply with NPR 7150.2 software  product realization requirements for 
software aspects of the system . Documentation produced through each technical management 
process should b e managed and disp osed as F ederal records . 

This Document Is Uncontrolled When Printed.  71 C.3.1 Technical Planning Process  
C.3.1.1  Purpose  
The technical planning process is used to plan  for the application  and management of each 
common techn ical process . It is also used  to identify, define , and plan the technical effort 
applicable to the product -line life-cycle  phase  for the WBS  model  location within the system  
structure  and to meet project  objectives and product -line life-cycle  phase exit criteria . A key 
documen t generated by this process is the SEMP . (See Chapter  6.) 
Note:  The results  of this technical planning effort should be summarized and provided to the project  manager  as 
input  to the technical summary section of the project plan required by NPR 7120.5 .  
C.3.1.2  Inputs  and Sources:  
a. Project  technical effort requirements  and project resource  constraints  (from the project).  
b. Agreements, capability  needs and applicable product -line life-cycle  phase (s) (from the 
project ). 
c. Applicable policies, procedures, standards, and organizational processes  (from the project ). 
d. Prior product -line life-cycle phase  or baseline  plans (from Technical Data Management 
Process ). 
e. Replanning needs (from Technical Assessment and Technical Risk Management Processes ). 
C.3.1.3  Outputs  and Destinations:  
a. Technical work  cost estimates, schedules , and resource  needs, e.g., funds, workforce , 
facilitie s, and equipment (to project ). 
b. Product and process measures needed to assess  progress of the technical effort and the 
effectiveness of processes  (to Technical Assessment Process ). 
c. The SEMP  and other technical plans that support implementation  of the technical effort (to 
all processes ; applicable plans to Technical Proce sses).  
d. Technical work  directives , e.g., work packages or task orders with work authorization (to 
applicable technical teams ). 
e. Technical planning work  products  needed to provid e reports, records, and undeliverable  
outcomes of process activities  (to Technical Data Management Process ). 
C.3.1.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare to conduct technical planning to include:  
This Document Is Uncontrolled When Printed.  72 1. Preparing or updating a pl anning strategy for each of the common technical processes  of 
this SE NPR . 
2. Determining:  
a) deliverable work  products  from technical efforts ; 
b) technical reporting requirements ; 
c) other technical information needs for reviews  or satisfying product -line life-cycle  
management phase  entry or exit criteria ; 
d) product  and process measures to be used in measuring technical performance, cost , and 
schedule  progress;  
e) key or critical technical events with entry and success  criteria ; 
f) data management approach  for data collection and storage and how measurement  data 
will be analyzed , reported, and dispos itioned as Federal records ; 
g) technical risks  that need to be ad dressed in the planning effort;  
h) tools  and engineering  methods  to be em ployed in the technical effort; and  
i) approach  to acq uiring and maintaining the technical expertise needed (training  and skills  
development  plan). 
b. Define the technical work  to be done , includ ing associated techni cal, support, and 
management tasks needed to generate the deliverable products  and satisfy entry and success 
criteria  of key technical events and the applicable product -line life-cycle  management phase .  
Note:  Accurate identification of tasks is needed to help : (1) create viable schedules , (2) identify staffing needs, (3) 
determine resource  loading , and (4) make acceptable cost estimations.  
c. Schedule , organize , and determine the cost of the technical effort.  
Note:  Based on the defined  technical work  and identified key events : (1) event -based and calendar -based schedules  
are prepared ; (2) resource  needs are established ; (3) costs  estimate are established ; and (4) workforce , staff, and 
skill/training needs are identified and requested.  
d. Prepare the SEMP  and other technical plans needed to support the technical effort and 
perform the technical processes .  
Note 1:  The SEMP  is described in Chapter  6 and an annotated outline is provided in Appendix D.  
Note 2:  Other technical plans include the product  verification  plan and product validation  plan developed to support 
the product verification process and product validation process, respectively, and based on the design  solution  
definition  specified requirements  to which the product to be evaluated will be generated.  
Note 3:  Larger projects  can find descriptions of other technical plans that may be applicable to the project in  
ANSI/EIA 632. Smaller projects may include the provisions of applicable plans in the project plan . The key is to 
ensure that necessary technical activities  and considerations are included in the technical effort.  
e. Obtain sta keholder  commitments to the technical plans.  
Note:  Review SEMP  and other technical plans and reconcile them to reflect work  and resource  levels.  
f. Issue authorized  technical work  directives  to implement  the technical work.  
Note:  Work  packages or task orders that implement  planned technical efforts are prepared and appropr iate work 
authorizations requested. Authorized work directives  are issued to technical teams  assigned to perform the technical, 
support , and management activities  of the planned technical effort.  
This Document Is Uncontrolled When Printed.  73 g. Capture work  products  from technical planning activities . 
Note:  Work  products  include the planning strategy for developing any needed technical plans, procedures used for 
technica l planning, rationale for decisions made, assumptions made during technical planning , and, with respect to 
decisions made, actions taken to correct identified anomalies , lessons learned in performing the technical planning 
activities , and updated support documentation.  
C.3.1.5  Process Flow Diagram  
A typical process flow diagram  for technical planning is provided in Figure  C-11 with inputs  and 
their sources and the outputs  and their destinations. The activities   of the technical planning 
process are truncated to indicate the action and object of the action.  
 
Figure  C-11 – Technical Planning Process  
C.3.2 Requirements  Management  Process  
C.3.2.1  Purpose  
The requirements  management  process is used to:  
a. manage the product  require ments  identified, baselined , and used in the definition  of the WBS  
model  products during system  design ;  
b. provide bidirectional traceability back to the top WBS  model  requirements ; and  
c. manage the changes to established requiremen t baselines  over the life cycle  of the system  
products . 

This Document Is Uncontrolled When Printed.  74 C.3.2.2  Inputs  and Sources:  
a. Expectations  and requirements  to be managed (from System  Design  Processes ). 
b. Requirement  change requests ( from the project  and Technical Assessment Process ). 
c. TPM  estimation/evaluation  results  (from Technical Assessment Process ) 
d. Product verification  and product  validation  results  (from Product Verification and Validation 
Processes ) 
C.3.2.3  Outputs  and Destinations:  
a. Requirement  documents  (to Configuration Management Process).  
b. Approved changes to requirement  baselines  (to Configuration Management Process).  
c. Requirements  management work  products  needed to provide reports, records , and 
undeliverable outcomes of process activities  (to Technical Data Management Process ). 
Note:  Bidirectional traceability status would be included as one of the work  products  and used in product 
verification  and product validation  reports.  
C.3.2.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare to conduct requirements  management , to include:  
1.  Preparing or  updating a strategy and procedures for:  
a) establishing that expectation  and requirement  statements , singularly and as a whole, 
are prepared in accordance with established formats and rules ;  
b) identifying  expectations  and requirements  to be managed, expectation and 
requirement sources, and allocation and traceability of requirements and linking 
product  expectations and  requirements with costs , weight, and power allocations , as 
applicable ; and  
c) formal initiation, assessment , review , approval , and disposition of engineering  change 
proposals and changes to expectation  and requirements  baseline .  
2. Selecting or updating an appropriate requirements  management  tool. 
3. Training technical team  members in the established requirements  management  
procedures and in the use of the selected/updated requirements management tool . 
b. Conduc t requirements  management , to include: (1) capturing, storing and documenting the 
expectations  and requirements; (2) establishing that expectation and requirement statements  
are compliant with format and other established rules; (3) confirming that each established 
requirements baseline  has been validated; and (4) identifying  and analyzing out -of-tolerance 
system -critical technical parameters  and unacceptable validation  and verification  results  and 
proposing requirement -appropriate changes to correct out -of-tolerance requirements.  
This Document Is Uncontrolled When Printed.  75 c. Conduc t expectation  and requirements  traceability to include: (1) tracking expectations and 
requirements between baselines , especially MOEs, MOPs , and TPMs  and (2) establishing 
and maintaining appropriate requirements compliance  matrixes that contain the requirements, 
bidirectional traceability, compliance status , and any actions to complete compliance.  
d. Manage expectation  and r equirement  changes to include: (1) reviewing engineering  change 
proposals (ECPs) to determine any changes to established requirement baselines , (2) 
implementing formal change procedures for proposed  and identified expectation or 
requirement changes , and (3) disseminating the approved  change information.  
e. Capture work  products  from requirements  management  process activities  to include 
maintaining and reporting information on the rationale for and disposition and 
implementation  of change actions, current requirement compliance  status, and expect ation  
and requirement baselines . 
C.3.2.5  Process Flow Diagram  
A typical process flow diagram  for requirements  management  is provided in Figure  C-12 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the requirements 
management process are tru ncated to indicate the action and object of the action.  
 
Figure  C-12 – Requirements  Management Process  

This Document Is Uncontrolled When Printed.  76 C.3.3 Interface Management Process  
C.3.3.1  Purpose  
The interface management process is used to :  
a. establish  and use formal interface management to assist in controlling system  product  
development  efforts when the efforts are divided between Government programs , 
contractors , and/or geographically diverse technical teams  within the same program or 
project  and  
b. maintain  interface definition  and com pliance  among the end product s and enabling product s 
that compose the system  as well as with other systems with which the end products and 
enabling products must interoperate . 
Note:  A less formal interface management approach  can be used in conjunction with requirements  management  
and/or configuration  management process activities  when the technical effort is co -located in the same project . 
C.3.3.2  Inputs  and Sources:  
a. Internal and external functional and physical interface requirements  for the products  of a 
WBS  model  (from user or program  and System  Design  Processes ).  
b. Interface change requests (from project , and Technical Assessment Process es). 
C.3.3.3  Outputs  and Destinations:  
a. Interface control  documents  (to Configuration Management Processes ). 
b. Approved interface requirement  changes (to Configuration Management Process)  
c. Interface management work  products  needed to provide reports, records , and undeliverable  
outcomes of process activities  (to Technical Data Management Process ). 
C.3.3.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare or update interface manag ement procedures for : (1) establishing interface 
management responsibilities  for those interfaces that are part of agreement  boundaries , (2) 
maintaining and controlling identified inte rnal and external physical and functional 
interfaces , (3) preparing and maintaining appropriate physical and functional interface 
specifications  or interface control  documents  and drawings to descri be and control interfaces 
external to the system  end product , (4) identifying  interfaces between system products 
(including humans) and among configuration  management items , (5) establishing and 
implementing formal change procedures for interface evolution , (6) disseminating the needed 
interface information for integration  into technical effort activities  and for external interface 
control , and (7) training  technical teams  and other applicable support and management 
personnel in the established interface management procedures.  
Note:  During application  of the system  design  processes  several kinds of interface requirements  are baselined  and 
thus need to be managed for each WBS  model : 
This Document Is Uncontrolled When Printed.  77 1) System  (External) . This external interface specifies the vertica l functional, physical, electro magnetic, and 
human and interoperability requirements  and characteristics in a system -to-system environment , e.g., end 
product s with parent platform and external end products.  
2) End Product  (Internal) . This interface specification  has horizontal internal interfaces with other end product s 
and with the enabling product s of the WBS  model .  
3) Enabling Product  (Internal and External) . This interface specification  encompasses the horizontal interfaces 
with other enabling product s and the end product s of the same WBS  model  and possibly vertical interfaces to 
other system  end products and enabling products.  
4) Subsystem (Internal) . This interface specification  detail s the horizontal internal interfaces with the subsystem 
end product s of the same parent within the WBS  model  to ensure effective product integration  with respect to 
form and fit, and, when the subsystem products are not physical ly mated together except by cabling or 
electronics, with respect to function.  
b. Conduct interface management during system  design  activities  for each WBS  model  in the 
system structure  to include: (1) integrating the interface management activities with 
requirements  management  activities; (2) analyzing  the concept of operations  to identify 
critical interfaces not included in the stakeholder  set of expectations ; (3) documenting 
interfaces both external and internal to each WBS model as the devel opment  of the system 
structure emerges and interfaces are added and existing interfaces are changed; (4) 
documenting origin, destination, stimulus, and special characteristics of interfaces; (5) 
maintaining the design solution  definition  for internal horizontal and vertical interfaces 
between WBS models in the system structure; (6) maintaining horizontal traceability of 
interface requirements across interfaces and capturing status in the establ ished requirements 
compliance  matri x; and (7) confirming that each interface control  document  or drawing that 
is established has been validated with parties on both sides of the interf ace. 
c. Conduct interface management during product  integration  activities  to include: (1) reviewing 
product integration procedures to ensure that interfaces are marked for easy and correct 
assembly/conn ection with other products , (2) identifying  product integration planning to 
identify interface discrepancies, if any, and report to the proper technical team  or technical 
manager , (3) confirming that a pre -check is comp leted on all physical interfaces bef ore 
connecting products , (4) evaluating assembled products for interface compatibility , (5) 
confirming that product verification  and product validation  plans/ procedures include 
confirming internal and external interfaces , and (6) preparing an interface evaluation  report 
upon completion of integration , product verification , and product validation.  
d. Conduct interface control  to include: (1) managing  interface changes within the system  
structure , (2) identifying  and tracking proposed and directed changes to interface 
specific ations  and interface control documents  and drawings , (3) confirming that the vertical 
and horizontal interface issues are analyzed and resolved when a change affects products  on 
both sides of the in terface , (4) controlling traceability of interface changes including source 
of the change, processing methods , and approvals , and (5) disseminating the approved  
interface change information for integration  into technical efforts at every level of the 
project . 
Note 1:  Typically , an interface control  working group  (ICWG) establishes communication links between those 
responsible for design  of inte rfacing systems , end product s, enabling product s, and subsystems. The ICWG has the 
responsibility to ensure accomplishment of the p lanning, scheduling , and execution of all interface activities . 
ICWGs are typically a technical team  with appropriate technical membership from the project , each contractor , 
significant ven dor, and program . 
Note 2:  An interface control  document  or drawing (ICD) is a document that establishes and defines t he detailed 
interface  between two or more systems , end product s, system elements, or configuration  items. It is used to control 
This Document Is Uncontrolled When Printed.  78 the defined interface early in the product -line life cycle  and thus to reduce des ign changes due to poorly identified, 
managed , or controlled interfaces.  
e. Capture work  products  from interface management activities . 
Note:  Work  products  include t he strategy and procedures for conducting interface management, rationale for 
interface decisions made, assumptions made in approving or denying an interface change, actions taken to correct 
identified interface anomalies , lessons learne d in performing the interface management activities , and updated 
support and interface agreement  documentation.  
C.3.3.5  Process Flow Diagram  
A typical process flow diagram  for interface management is provided in Figure  C-13 with inputs  
and their sources and the outputs  and their destinations. The activities  of the interface 
manageme nt process are truncated to indicate the action and object of the action.  
 
Figure  C-13 – Interface Management Process  
C.3.4 Technical Risk Management  Process  
C.3.4.1  Purpose  
The technical risk management process is used to examine  on a continuing basis the risks  of 
technical deviations from the project  plan and identify potential technical problems before they 
occur so that risk -handling activities  can be p lanned and invoked as needed across the life of the 
product  or project to mitigate impacts on achieving product -line life-cycle  phase  exit criteria  and 
meeting technical objectives.  
C.3.4.2  Inputs  and Sources:  
a. Project  Risk Management Plan  (from project)  
b. Technical risk issues (from project  and other common technical processes ). 
c. Technical risk status  measurements (from Technical Assessment and Decision Analysis 
Process es). 

This Document Is Uncontrolled When Printed.  79 d. Technical risk reporting requirements  (from project  and Technical Planning Process).  
C.3.4.3  Outputs  and Destinations:  
a. Technical risk mitigation and/or contingency actions (to Technical Planning Process for 
replanning and/or redirection).  
b. Technical risk  reports (to project  and Technical Data Management Process ). 
c. Work  products  from technical risk management activities  (to Technical Data Management 
Process ). 
C.3.4.4  Activities  
For the WBS  model  in the system  structure , the following activi ties are typically performed :  
(NPR  8000.4 , Agency Risk Management Procedural Requirements , is to be used as a source 
document  for defining this process and implementing procedures.)  
a. Prepare a strategy to conduct technical risk management  to include: (1) documenting how the 
project  risk management plan  will be implemented in the technical effort; (2) planning 
identification of technical risk sources and categories; (3) identif ying potential technical 
risks ; (4) characterizing and prioritizing technical risks; (5) planning info rmed technical 
management (mitigation) actions should the risk event occur; (6) tracking technical risk 
status  against established trigger s; (7) resolving  technical risk by taking planned act ion if 
established trigger s are tripped; and (8) communicating technical risk status and mitigation 
actions taken, when appropriate .  
b. Identify technical risks  to include: (1) identifying  sources of risk issues related t o the 
technical effort; (2) anticipate what could go wrong in each of the source areas to create 
technical risk issues; (3) analyzing identified technical risks for cause and importance; (4) 
preparing clear, understandable , and standard form risk statement s; and (5) coordinating with 
relevant stakeholders associated with each identified technical risk.  
Note 1:  Typical technical risk areas include: poorly defined  technical tasks, cost  estimations, calenda r-driven 
scheduling, poor definition of requirements  and interfaces, new technology, environmental conditions, planning 
assumptions, procedures used in performing technical processes , resource  availability , and the skills  of the 
workforce .  
Note 2: While there are many ways to identify risks , two potential approaches are by data mining and trending.  
Note 3:  Technical risks  are typically defined  by relative time frame of risk occurrence, concerns or doubts about risk 
circumstances, limits or boundary of risk applicability, and potential conse quences.  
c. Conduct technical risk assessment , to include: (1) categoriz e the severity of consequences for 
each identified technical risk in terms of performance, cost , and schedule  impacts to the 
techni cal effort and project ; (2) analyze the likelihood and uncertainties of events associated 
with each technical risk and quantify (for example by probabilities) or qualify ( e.g., high, 
moderate, or low) the probability of occurrence in accor dance with project risk management 
plan rules; and (3) prioritize risks  for mitigation.  
Note:  Typically the prioritization of the technical risk is based on whether the risk is a near- or far -term concern ; 
possible risk mitigation options and how long the options are viable ; the coupling between various sources and 
characteristics of risk (e.g., technologies, requirements , interfaces, test  approach es, manufacturing capacity, 
logistics , workforce  capability , schedules , and costs ); how the occurrence of risk can be detected ; and  influ ences of 
other factors (e.g., quality, safety , security, and interoperability).  
This Document Is Uncontrolled When Printed.  80 d. Prepare for technical risk mitigation to include: (1) selecting risks  for mitigation and 
monitoring , (2) selecting an appropriate risk -handling ap proach , (3) establishing the risk 
level or threshold when risk occurrence becomes unacceptable and triggers execution of a 
risk mitigation action plan , (4) selecting contingency actions and triggers should risk 
mitigat ion not work  to prevent a problem occurrence , (5) preparing risk mitigation and 
contingency action plans identif ying responsibilities  and authorities.  
e. Monitor  the status of each technical ri sk periodically to include: (1) tracking risk status  to 
determine whether conditions or situations have changed so that risk monitoring is no longer 
needed or new risks  have been discovered , (2) comparing risk status and risk thresholds , (3) 
reporting risk status to decision authorities when a threshold has been triggered and an action 
plan implemented , (4) preparing technical risk status report s as required by the project  risk 
management plan , (5) communicating risk status during technical review s in the form 
specified by the pr oject risk management plan . 
f. Implement technical risk mitigation and contingency action plans  when the applicable 
thresholds have been triggered to include: (1) monitoring the results  of the action plan  
implemented , (2) modifying the action plan as appropriate to the results of the actions , (3) 
continuing actions until the residual risk and/or consequences impacts are acceptable or 
become a problem to be solved , (4) communicate to the project  when risks  are beyond the 
scope  of the technical effort to control , will affect a product  higher in the system  structure , or 
represent a significant threat to the technical effort or project success , (5) preparing action 
plan effectiveness reports as required by the project risk management plan , (6) 
communi cating action plan effectiveness during technical review s in the form specified by 
the project risk management plan.  
g. Capture work  products  from technical risk management act ivities . 
Note:  Work  products  include the strategy and procedures for conducting technical risk management; rationale for 
technical risk management decisions made; assumptions made in prioritizing, handling , and reporting technical risks  
and action plan  effectiveness; actions taken to correct action plan  implementation  anomalies ; and lessons learned in 
performing the tech nical risk management activities . 
C.3.4.5  Process Flow Diagram  
A typical process flow diagram  for technical risk management is provided in Figure  C-14 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the technical risk 
management process are truncated to indicate the action and object of the action.  
 
This Document Is Uncontrolled When Printed.  81  
Figure  C-14 – Technical Risk Management Process  
C.3.5 Configuration Management  Process  
C.3.5.1  Purpose  
The configuration  management process for end product s, enabling product s, and other work  
products placed under configuration control  is used to :  
a. identify the configuration  of the product  or work  product at various points in time;  
b. systematically control  changes to the configuration  of the product  or work  product;  
c. maintain  the integrity and tr aceability of the configuration  of the product  or work  product 
throughout its life; and  
d. preserve the records of the product  or end product  config uration  throughout its life cycle , 
disposing them in accordance with NPR  1441.1 NASA Records Retention Schedul es. 
C.3.5.2  Inputs  and Sources:  
a. Project  configuration  management plan, if any (from project).  
b. ECPs (from contractors , if any, and technical teams ). 
c. Expectations  and requirement  outputs  to include stakeholder  expectations, technical 
requirements, derived technical requirements, system  and end product  specifications , 
requirement documents , and interface control  documents/drawings (from Requirements and 
Interface Management Processes ). 
d. Approved requirement  baseline  changes, including interface requirement changes (from 
Requirements Management and Interface  Management Processes ). 

This Document Is Uncontrolled When Printed.  82 e. Concepts of operations , enabling product  strategies, logical decomposition  models, SEMP , 
technical plans, and other configuration  items identified in the list of configuration item s to 
be controlled (from Stakeholder  Expectation Definition , Logical Decomposition, T echnical 
Planning , and other technical processes  as appropriate) . 
C.3.5.3  Outputs  and Destinations:  
a. List of configuration  items to be placed under control  (to applicable technical processes ). 
b. Current baselines  (to Technical Requirements  Definition , Logical Decomposition , Design  
Solution  Definition, and Product Implementation , Integration, Verification, and Validation  
Processes .) 
Note:  A configuration  management baseline  identifies an agreed  upon  description of the attributes of a work  product  
or set of work products at a point in time and provides a known configuration to which changes are addressed. Three 
example baselines for flight systems  and ground support  systems  that are often referenced are the ―functional, ‖ 
―allocated ,‖ and ―product ‖ baseline s. Functional baselines are established for each WBS  model  system element prior 
to the start of preliminary design . Allocated baselines are established for each WBS model end product  with the 
successful completion of a Preliminary Design  Review (PDR) at each level of the system structure . The product 
baseline represents the configuration o f each end product.  
c. Configuration management reports (to project  and Technical Data Management Process ). 
d. Work  products  from configuration  management activi ties (to Technical Data Management 
Process ). 
C.3.5.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare a strategy to conduct configuration  management for the system  products  and 
desig nated work  products to include: (1) documenting how the project  configuration 
management plan , if any, will be implemented; (2) identifying  items to be put under 
configuration control ; (3) identifying schema of identifiers to accurately describe a 
configuration item and its revisions or versions; (4) controlling changes to configuration 
items; (5) maintaining and reporting dis position and implementation  of change actions to 
appropriate stakeholders including technical teams  within the project; (6) ensuring that 
products are in compliance  with specifications  and configuration documentation during 
reviews  and audits ; (7) providing the appropriate reference  configuration at the start of each 
product -line life-cycle  phase; (8) obtaining appropriate tools  for configuration management; 
and (9) training  appropriate technical team members and other technical support and 
management personnel in the established configuration managem ent strategy and any 
configuration management procedures and tools.  
b. Identify baselines  to be under configuration  control  to include: (1) listing the configuration 
items to control; (2) providing each  configuration item with a unique identifier; (3) 
identifying  acceptance requirements  for each baseline identified for control; (4) identifying 
the owner of each configuration item; and (5) establishing a baselin e configuration for each 
configuration item.  
This Document Is Uncontrolled When Printed.  83 Note:  Typical acceptance requirements  for a baseline  include: product -line life-cycle  management phase  and entry 
or exit c riteria  to be satisfied; when the baseline will be approved ; when work  products will be ready for evaluation ; 
degree of control  desired; cost  and schedul e limitations; and customer  requirements.  
c. Manage configuration  change control  to include: (1) establishing change criteria , procedures, 
and responsibilities ; (2) receive, record , and evaluate  change requests; (3) tracking change 
requests to closure; (4) obtaining appropriate approvals before implementing a change; (5) 
incorporating approved  changes in appropr iate configuration items; (6) releasing changed 
configuration items for use; and (7) monitoring implementation  to determine whether 
changes resulted in uni ntended effects (e.g., have compromised safety  or security of b aseline  
product ).  
Note:  A configuration  management change board is typically established to receive, review , and approve change 
requests such as an engineering  change proposal submitted by a contractor . 
d. Maintain the status of configuration  documentation to include: (1) maintaining configuration 
item description records and records that verify readiness  of conf iguration items for testing , 
delivery , or other related technical efforts; (2) maintaining change requests, disposition 
action taken , and history of change status; (3) maintaining differences between successive 
baselines ; and (4) controlling access to and release of configuration baselines.  
e. Conduct configuration  audits  to include: (1) auditing baselines  under control  to confirm that 
the actual work  product  configuration matches the documented configuration, the 
configuration is in conformance with product requirements , and records of all change actions 
are complete and up  to date; (2) identifying  risks  to the technical effort based on incorrect 
documentation, implementation , or tracking of changes; (3) assessing the integrity of the 
baselines; (4) confirming the completeness and correctness of the co ntent of configuration 
items with applicable requirements; (5) confirming compliance  of configuration items with 
applicable configuration management standards and procedures; and (6) tracking action items 
to correct anomalies  from audit to closure.  
f. Capture work  products  from configuration  management activities  to include a list of 
identified configuration items; description of configuration items pla ced under control ; 
change requests , disposition of the request s, and rationale for the disposition s; documented 
changes with reason for change s and change action s; archive of old baselines ; and required 
reports o n configuration management outcomes.  
C.3.5.5  Process Flow Diagram  
A typical process flow diagram  for configuration  management is provided in Figure  C-15 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the configuration 
management process are truncated to indicate the action and object of the action.  
 
This Document Is Uncontrolled When Printed.  84  
Figure C-15 – Configuration Management Process  
C.3.6 Technical Data Management Process  
C.3.6.1  Purpose  
The technical data management process  is used to : 
a. provide the basis for identifying  and controlling data requirements ;  
b. responsively and economically acquire, access, and distribute data needed to develop, 
manage, operate , and support system  products  over their product -line life;  
c. manage and dispos e data as records;   
d. analyze data use;  
e. if any of the technical effort is performed by an external contractor , obtain technical data 
feedback for managing  the contracted technical effort; and  
f. assess  the collection of appropriate technical data and information.  
C.3.6.2  Inputs  and Sources:  
a. Technical data and work  products  to be managed  (from all technical processes  and 
contractors ). 
b. Requests for technical data (from all technical processes  and project ). 

This Document Is Uncontrolled When Printed.  85 C.3.6.3  Outputs  and Destinations:  
a. Form of technical data products  (to all technical processes  and contractors ). 
b. Technical data electronic exchange formats (to all technical processes  and contractors ). 
c. Delivered technical data (to proje ct and all technical processes ). 
C.3.6.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare a strategy for the conduct of technical data management to include: (1) determining 
required data content and form and electronic data exchange interfaces in accordance with 
international standards or agreements; (2) establishing a framework  for technical data flow 
within the project  technical processes  and to/from contractors ; (3) designating technical data 
management responsibilities  and authorities regarding origination, generation, capture, 
archiving, security, privacy , and dispos ition of technical data work  products ; (4) establishing 
the rights, obligations , and commitments regarding the retention of, transmission of , and 
access to technical data items; (5) establishing rel evant data storage, transformation, 
transmission , and presentation standards and conventions to be used ; (6) establishing project 
or program  policy and agreements or legislative constraints ; (7) describing the methods , 
tools , and metrics  used during the technical effort and for technical data management; and ( 8) 
training  appropriate technical team  members and support and management personnel in the 
established technical data management strategy and related procedures and tools.  
b. Collect and store required technical data to include: (1) identifying  existing sources of 
technical data that are designated as outputs  of the common technical processes ; (2) 
collecting and storing technical data in accordance with the technical data management 
strategy and procedures; (3) recording and distributing lessons learned; (4 ) performing 
technical data integrity checks on collected data to confirm compliance  with content and 
format requirements  and identifying errors in specifying or recording data; and (5) 
prioritizing, reviewing , and u pdating technical data collection and storage procedures.  
c. Maintain stored technical data to include: (1) managing  the databases to maintain  proper 
quality and integrity of the collected and stored technical da ta and to confirm that the 
technical data is secure and is available to those with authority  to have access; (2) performing 
technical data maintenance  as required; (3) preventing the stored data from being used or 
accessed inappropriately; (4) maintaining the stored technical data in a manner that protects it 
against foreseeable hazards , such as fire, flood, earthquake, and riots; and (5) maintaining 
periodic backups of each technical database.  
d. Provide technical data t o authorized parties to include: (1) maintaining an information library 
or reference  index to provide data available and access instructions; (2) receiving and 
evaluating requests for technical data and delivery instruct ions; (3) confirming that required 
and requested technical data is appropriately distributed to satisfy the needs of the requesting 
party and in accordance with established procedures, directives , and agreements; (4) 
confirming that  electronic access rules are followed before allowing access to the database 
and before any data is electronically released/transferred to the requester; and (5) provid ing 
This Document Is Uncontrolled When Printed.  86 proof of correctness, reliability , and security of technical data provided to intern al and 
external recipients.  
C.3.6.5  Process Flow Diagram  
A typical process flow diagram  for technical data management is provided in Figure  C-16 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the technical data 
management process  are truncated to indicate the actio n and object of the action.  
 
Figure  C-16 – Technical Data Management Process  
C.3.7 Technical Assessment  Process  
C.3.7.1  Purpose  
The technical assessment process  is used to help monitor  progress of the technical effort and 
provide status information for support of the system  design , product  realization, and techn ical 
management processes . 
C.3.7.2  Inputs  and Sources:  
a. Process and product  measures (from Technical Planning Process).  
b. Technical plans including the SEMP  (from Tec hnical Planning Process).  
c. Risk reporting requirements  during technical review s (from project ). 
d. Technical cost  and schedule  status repo rts (from project ). 
e. Product measurements (from Product Verification and Product Validation  Processes ). 
f. Decision support recommendations and impacts (from Decision Analysis Process ). 

This Document Is Uncontrolled When Printed.  87 C.3.7.3  Outputs  and Destinations:   
a. Assessment results  and findings including technical performance measure ment estimates of 
meas ures (to Technical Planning, Technical Risk Management , and Requirements  
Management Processes ). 
b. Analysis  support requests (to Decision Analysis Process ). 
c. Technical review  reports (to project  and Technical Data Management  Process ). 
d. Corrective action and requirement  change recommendations including actions to cor rect out -
of-tolerance TPMs  (to Technical Planning, Requirements Management, and Interface 
Management Processes ). 
e. Work  products  from technical assessment  activities  (to Technical Data Management 
Process ). 
C.3.7.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Prepare a strategy for conducting technical assessments to include: (1) identifying  the plans 
against which prog ress and achievement of the technical effort are to be assessed; (2) 
establishing procedures for obtaining cost  expenditures against work  planned and task 
completions against schedule ; (3) identifying and obtaini ng technical requirements  against 
which product  development  progress and achievement will be assessed and establishing the 
procedures for conducting the assessments; (4) establishing events when TPM s, estimation or 
measurement  techniques, and rules for taking action when out -of-tolerance conditions exist  
will be assessed ; (5) identifying and planning for phase -to-phase technica l review s and WBS  
model -to-model vertical progress review s, as well as establishing review  entry and success 
criteria , review board members , and close -out procedures; (6) establishing which technical 
effort work products will undergo peer review, the team  members who will perform the peer 
reviews , and reporting requirements; and (7) training  team members, support staff , and 
managers involved in conducting technical assessment  activities .  
b. Assess tec hnical work  productivity (progress and achievement against plans) to include: (1) 
identifying , collecting, and analyzing process measures (e.g., earned value measurements for 
measuring progress against planned cost , schedule , resource  use, and technical effort tasks) 
and identifying and reporting cost -effective changes to correct variances; (2) monitoring 
stakeholder  involvement according to the SEMP ; and (3) monitoring technical data 
management against plans.  
c. Assess product  quality  (progress and achievements against technical requirements ) to 
include : (1) identifying , collecting, and analyzing the degree of technical requirement and 
TPM  satisfaction ; (2) assessing the maturity of the WBS -model  products and services as 
applicable to the product -line life-cycle  phases ; (3) determining any variances from expected 
values of product performance and identif ying and defining cost -effective changes to correct 
variances.  
Note:  Product  measures  tell the degree of satisfaction  of stakeholder  expectations  and deliver an ever  improving 
value to the customers of system  products  and services. Product measures also indicate that the design  process is 
This Document Is Uncontrolled When Printed.  88 continuing in the direction of an acceptable solution. An example of an input  product measure is the quality of 
materials and skills  of assigned project  personnel. An example of an output  metric is a TPM . A T PM provides an 
early warning of the adequacy of a design in satisfying selected critical technical parameter requirements . A ― critical 
technical parameter‖  is one that characterizes a significant total system qualifier (e.g., one or mo re of the MOPs). 
TPM s also examine  the marginal cost  benefit of performance in excess of requirements. In addition, it should be 
possible to project the evolution of the parameter as a function of time toward the desired v alue at the completion of 
development . The projection can be based on test , planning, or historical data.  
d. Conduct technical review s to include: (1) identifying  the type of technical reviews  and each 
review ’s purpose  and objectives (see Chapter  5 for specific technical reviews that apply); (2) 
determining progress toward satisfyi ng entry criteria ; (3) establishing the makeup of the 
review team ; (4) preparing the review presentation materials; and (5) identifying and 
resolving  action items resulting from the review.  
Note 1:  Reviews  are typically closed out when the minutes have been prepared, approved , and distributed; action 
items have been resolved; and the review completion documented and signed off by the review chairperson.  
Note 2:  This activity  includes peer reviews , which are planned, focused review s by technical team  peers on a single 
work  product  with the intent of identifying  issues prior to that work product moving on to the next step. A peer 
review includes planning, preparing, conducting, analyzing outcomes, and identifying and implementing corrective 
actions.  
e. Capture work  products  from the conduct of technical assessment  activities  to include: (1) 
identifying  variances resulting from technical assessments; (2) identifying and reporting 
changes to correct variances; (3 ) recording methods  used in doing assessment activities; (4) 
documenting assumptions made in arriving at the process and product measure outcomes; 
and (5) reporting corrective action recommendations.  
C.3.7.5  Process Flow Diagram  
A typical process flow diagram  for technical assessment  is provided in Figure  C-17 with inputs  
and their sources and the outputs  and their destinations. The activities  of the technical assessment 
process  are truncated to indicate the action and object of the action.  
 
This Document Is Uncontrolled When Printed.  89  
Figure  C-17 – Technical Assessment Pro cess  
C.3.8 Decision Analysis  Process  
C.3.8.1  Purpose  
The decision analysis process  including data collection (e.g., engineering  performance, quality, 
and reliability data) is used to help evaluate  technical decision issues, technical alternatives, and 
their uncertainties to support decision making . This process is used throughout technical 
management, system  design , and product  realization processes  to evaluate the impact of 
decisions on performance , cost , schedule , and technical risk . 
C.3.8.2  Inputs  and Sources:  
a. Decision s need ed, alternatives, issues, or problems and supporting data (from all Technical 
Processes ). 
b. Analysis  support requests (from Technical Assessment Process ). 
C.3.8.3  Outputs  and Destinations:  
a. Alternative selection recommendations and impacts (to all Technical Processes ) 
b. Decision support r ecommendations and impacts ( to Technical Assessment Process ) 
c. Work  products  of decision analysis  activities  (to Technical Data Management Process ).  

This Document Is Uncontrolled When Printed.  90 C.3.8.4  Activities  
For the WBS  model  in the system  structure , the following activities  are typically performed : 
a. Establish guidelines  to determine which technical issues are subject to a formal 
analysis /evaluation  process to include: (1) when to use a formal decision m aking  procedure, 
for example, as a result of an effectiveness assessment , a technical trade off, a problem 
needing to be solved, action needed as a response to risk exceeding the acce ptable threshold, 
verification  or validation  failure, make/ buy choice, evaluating a solution alternative, or 
resolving  a requirements  conflict ; (2) what needs to be documented; (3) who will be the 
decision makers and th eir responsibilities  and decision authorities; and (4) how decisions will 
be handled that do not require a formal evaluation procedure.  
b. Define the criteria  for evaluating alternative solutions  to include: (1) the types of criteria to 
consider , includ ing technology limitations, environmental impact, safety , risks , total 
ownership and life -cycle  costs , and schedule  impact; (2) the acceptable range and scale of the 
criteria; and (3) the rank of each criterion by its importance.  
c. Identify alternative solutions  to address dec ision issues to include alternatives for 
consideration in addition to those that may be provided with the issue.  
d. Select evaluation  methods  and tools /techniques based on the purpose  for analyzing a decision 
and on the availability of the information used to support the method and/or tool.  
Note:  Typical evaluation  methods  include: simulations; weighted trade -
 , 
prototypes; user review  and comment; and testing . 
e. Evaluate  alternative solutions  with the established criteria  and selected methods  to include: 
(1) evaluation of assumptions related to evaluation criteria and of the evidence that supports 
the assumptio ns; and (2) evaluation of whether uncertainty in the values for alternative 
solutions affects the evaluation.  
f. Select recommended solutions from the alternatives based on the evaluation  criteria  to 
include documenting th e information that justifies the recommendations and gives the 
impacts of taking the recommended course of action.  
g. Report the analysis /evaluation  results /findings with recommendations, impacts , and 
corre ctive actions.  
h. Capture work  products  from decision analysis  activities  to include: (1) decision analysis 
guideline s generated and strategy and procedures used; (2) analysi s/evaluation  approach , 
criteria , and methods  and tools  used; (3) analysis/evaluation results , assumptions made in 
arriving at recommendations, uncertainties , and sensitivities of the recommended actions or 
corrective actions; and (4) lessons learned and recommendations for improving future 
decision analyses.  
C.3.8.5  Process Flow Diagram  
A typical process flow diagr am for technical decision analyses is provided in Figure  C-18 with 
inputs  and their sources and the outputs  and their destinations. The activities  of the decisio n 
analysis process  are truncated to indicate the action and object of the action.  
This Document Is Uncontrolled When Printed.  91  
 
Figure  C-18 – Decision Analysis Process  

This Document Is Uncontrolled When Printed.  92 Appendix D. Systems  Engineering  Management Plan  
D.1 Purpose and Use  
The purpose  of this appen dix is to provide an annotated outline for a SEMP  for use by NASA in 
planning the technical effort required for in -house and contracted  projects . The SEMP is the 
technical planni ng document  for systems  engineering . The SEMP is designed to be a single, 
integrated  technical planning document for the conduct and management of  the required 
technical effort that is the responsibility of an in -house NASA project. The resulting technical 
plan is to represent the agreed -to and approved  tailoring  of the requirements  of the SE NPR  to 
satisfy project technical requirements.  The plan is to be used by the technical team  responsible 
for generating technical work  products  to integrate and manage the full spectrum of technical 
activities  required to engineer the system covered by the SEMP. The SEMP should  be 
coordinated with the project plan for integration of the technica l planning and modifications 
related to the allocated resources, including cost , schedule , personnel, facilities , and deliverables 
required.  The plan will also be used to evaluate  the tea m’s technical approach , to make technical 
risk assessment s, and to measure progress.  
D.2 Terms Used  
Terminology is a key factor in ensuring a common understanding of the technical effort to be 
accomplished. Terms u sed in the SEMP  must  have the same meaning as the terms used in the SE 
NPR . 
D.3 SEMP  Prepara tion 
D.3.1 Outline Use  
The SEMP  outline in this appendix is to be used in preparing a project  SEMP. For a small 
project the material in the SEMP can be placed in the project plan ’s technical summary  and this 
annotated outline used as a topic guide.  
D.3.2 Tailoring  and Waivers  
D.3.2.1  SEMP  tailoring  is to be consistent with the SE NPR  tailoring requirements  and 
guidelines . (See Appendix F.) The SEMP is to include documentation of any tailoring to the SE 
NPR  requirements and SEMP sections  or subsections. Tailoring is an adaptation of a process or 
approach  to meet a requirement, whereas a waiver  is a documented agree ment  intentionally 
releasing a program  or project  from meeting a requirement. Tailored requirements will be 
documented directly following the heading of each affected SEMP section  or subsection.  
Tailored SE NPR requirements that are not directly related to a SEMP section or subsection will 
be documented in the waiver section . 
D.3.2.2  Approved waivers  will be documented and incorporated into the waiver section of the 
SEMP . 
This Document Is Uncontrolled When Printed.  93 D.3.3 Surveillance -Type  Projects  
For projects  with significant portions of the engineering  work  contracted  out, the SEMP  should 
scope  and plan  the NASA project’s  implementation  of the common technical processes  before, 
during, and at the completion of the contracted effort. This should include planning the technical 
team ’s involvement in RFP  preparation , in source selection activities , and in acceptance of 
deliverab les. The interface activities with the contractor, including NASA technical team 
involvement with and monitoring of contracted work, should be a focus of the SEMP.  
D.4 SEMP  Annotated Outline  
D.4.1 General Structure  
The SEMP  contains the following sections, unless they have been tailored  out. Cross references 
to detailed information in related technical plans are included in each pertine nt SEMP section.   
a. Purpose and Scope . 
b. Applicable Documents  and Designated Governing Authority . 
c. Technical Summary . 
d. Technical Effort Integration . 
e. Common Technical Pr ocesses  Implementation . 
f. Technology Insertion . 
g. Additional SE Functions and Activities . 
h. Integration with the Project  Plan Resource  Allocation . 
i. Waivers . 
j. Appendic es. 
D.4.2 Purpose and Scope  
This section provides a brief description of the purpose , scope , and content of the SEMP . The 
scope encompasses the SE  technical effort required to generate the work  products  necessary to 
meet the exit criter ia for the product -line life-cycle  phases .  
D.4.3 Applicable Documents  
This section lists the documents  applicable to SEMP implementation  and describes major 
standards and procedures that the technical effort needs to follow. Specific implementation of 
standardization tasking is incorporated into pertinent sections of the SEMP.  
D.4.4 Technical Summary  
This section contains  an executive summary describing the  problem to be solved by this 
technical effort.  
This Document Is Uncontrolled When Printed.  94 D.4.4.1 System  Description  
This subsection contains a definition  of the purpose  of the system  being developed and a brief 
description of the purpose of the products  of the WBS  model s of the  system structure  for which 
this SEMP  applies . Each WBS model  includes the system end product s and their subsystems and 
the supporting or enabling product s and any other work  products (plans, baselines ) required for 
the development  of the system. The description should include  any interfacing systems and 
system produc ts, including humans, with which the WBS model system products will interact 
physically, functionally , or electronically.  
D.4.4.2 System  Structure  
This subsection contains an explanation of how the WBS  models will be developed , how the 
resulting WBS  model  will be integrated  into the project  WBS , and how the overall system  
structure  will be developed. This subsection contains a description of the relationship of the 
specification  tree and the drawing tree with the products  of the system structure and how the 
relationship a nd interfaces of the system end product s and their life -cycle -enabling product s will 
be managed throughout the planned technical effort.  
D.4.4.3 Product Integration  
This subsection contains an explanation of how the product  will be integrated  and will describe 
clear organizational responsibilities  and interdependencies whether the  organizations  are 
geographically dispersed or managed across Centers.  
D.4.4.4 Planning Context  
This subsection contains the product -line life-cycle  model  constraints  (e.g., NPR  7120.5) that 
affect the planning and implementation  of the common technical processes  to be applied in 
performing the technical effort. The constraints provide a linkage of the technical effort with the 
applicable product -line life-cycle  phases  cover ed by the SEMP  including, as applicable, 
milestone  decision gates, major technical review s, key intermediate events leading to project  
completion, life-cycle  phase , event entry and exit criteria , and major baseline  and other work  
products to be delivered to the sponsor or customer  of the technical effort.  
D.4.4.5 Boundary of Technical Effort  
This subsection contains a description of the boundary of the general problem to be solved by the 
technical effort. Specifically , it identifies what can be controlled by the technical team  (inside the 
boundar y) and what influences the technical effort and is influenced by the technical effort but 
not controlled by the technical team (outside the boundary). Specific attention should be given to 
physical, functional , and electronic interfaces across the boundary . 
D.4.4.6 Cross -References  
This subsection contains cross -references to appropriate nontechnical plans that interface with 
the technical effort  and contains a summary description of how the technical activities  covered in 
other plans are accomplished as fully integrated  parts of the technical effort . 
This Document Is Uncontrolled When Printed.  95 D.4.5 Technical Effort Integration  
This section contains a description of how the various inputs  to the technical effort  will be 
integrated  into a coordinated effort that meets cost , schedule , and performance objectives.  
D.4.5.1 Responsibility and Authority  
This subsection contains a description of the org anizing  structure  for the technical teams  
assigned to this technical effort and includes how the teams will be staffed an d managed, 
including : (a) what organization/panel will serve as the  DGA  for this project  and, therefore , will 
have final signature authority for this SEMP ; (b) how multidisciplinary teamwork will be 
achieved ; (c) identification and definition  of roles , responsibilities , and authorities required to 
perform the activities  of each planned common technical process; ( d) planned technical  staffing 
by discipline and expertise level, with human resource  loading; ( e) required technical staff 
training ; and ( f) assignment of roles, responsibilities , and authorities to appropriate project 
stakeholders  or technic al teams to assure planned activities are accomplished.  
D.4.5.2 Contractor Integration  
This subsection contains a description of how the technical effort of in -house and external 
contractors  is to be integrated  with the NASA technical team  efforts. This includes establishing 
technical agreements, monitoring contractor  progress against the agr eement , handling technical 
work  or product  requirements  change requests, and acceptance of deliverables.  The section will 
specifically address how interfaces between the NASA technical te am and the contractor will be 
implemented for each of the 17 common technical processes . For example, it addresses how the 
NASA technical team will be involved with reviewing or controlling contractor -gener ated design  
solution  definition  documentation or how the technical team will be involved with product 
verification  and product validation  activities . 
D.4.5.3 Support Integration  
This subsection contains a description of the methods  (such as integrated  computer -aided tool  
sets, integrate d work  product  databases, and technical management information systems ) that 
will be used to support technical effort integration.  
D.4.6 Common Technical Processes  Implementation  
Each of the 17 common technical processes  will have a separate subsection that  contains the plan  
for performing the required process activities  as appropriately tailored . (See Chapter  3 for the 
process activities required and Appendix F for tailoring .) Implementation  of the 17 common 
technical processes inc ludes : (1) generating  outcomes needed to satisfy the entry and exit criteria  
of the applicable product -line life-cycle  phase  or phases identified in D.4.4.4 and (2) producing 
the nec essary inputs  for other technical processes . These sections contain a description of the 
approach , methods , and tools  for:  
a. Identifying and obtaining adequate human and nonhuman resources for pe rforming the 
planned process, developing the work  products , and providing the services of the process .  
This Document Is Uncontrolled When Printed.  96 b. Assigning responsibility and authority  for performing the planned process, developing the 
work  products , and providing the services of the process .  
c. Training the technical staff performing or supporting the process, where training  is identified 
as needed .  
d. Designating and placing designated work  products  of the process under appropriate levels of 
configuration  management . 
e. Identifying and involving stakeholders of the process .  
f. Monitoring and controlling the process .  
g. Objectively evaluating adherence of the proce ss and the work  products  and services of the 
process to the applicable requirements , objectives , and standards and address ing 
noncompliance . 
h. Reviewing activities , status, and results  of the process with appropriate levels of management 
and resolv ing issues.  
D.4.7 Technology Insertion  
This section contains a description of the approach  and methods  for identifying  key technologies 
and their associated risks  and criteria  for assessing and inserti ng technologies, including those for 
insert ing critical technologies from technology development  projects .  
D.4.8 Additional SE Functions and Activities  
This section contains a description of other areas not specifically included in previous se ctions 
but that are essential for proper planning and conduct of the overall technical effort . 
D.4.8.1 System  Safety  
This subsection contains a description of the approach  and methods  for conducting safety  
analysis  and assessing the risk to operators, the system , the environment , or the public.  
D.4.8.2 Engineering Methods  and Tools  
This subsection contains a descri ption of the methods  and tools  not included in D.4.7 that are 
needed to support the overall technical effort and identifies those tools to be acquired and tool 
training  requirements . 
D.4.8.3 Specialty Engineering  
This subsection contains a description of engineering  discipline and specialty requirements  that 
apply across projects  and the WBS  model s of the  system  structure . Examples of these 
requirement areas include planning for safety , reliability, human factors, logistics , 
maintainability, quality, operability, and supportability.   
 
D.4.8.4  Technical Performance Measures  
 
This Document Is Uncontrolled When Printed.  97 This subsection contains a description of the TPMs that have been derived from the Measures of 
Effectiveness (MOEs) and Measures of Performance  (MOPs) for the project.  The set should 
include the required TPMs as stated in section 6.2.7 of this NPR, the appropriate set of highly 
recommended Common Leading Indicators as described in NPR 7120.5 Formulation Agreement 
and Program/Project Management P lan templates, and any other project -unique TPM selected 
for this project.  The format and methodology of how the parameters will be reported (graph, 
table, plan versus actual, etc) should be described. The reporting period and reporting recipients 
should also be stated.  
 
D.4.9 Integration with the Project  Plan  and Technical Resource  Allocation  
This section contains how the technical effort will integrate  with project  management  and 
defines r oles and responsibilities . This section addresses how technical requirements  will be 
integrated with the pro ject plan  to determinate the allocation of resources , including cost , 
schedule , and personnel , and how changes to the allocations will be coordinated.   
D.4.10 Waivers  
This section contains all approved  waivers  to the Center  Director ’s SE NPR  Implementation  Plan 
requirement  for the SEMP . This section also contains a separate subsection that includes any 
tailored  SE NPR  requirements that are not related and able to be documented in a specific SEMP 
section or subsection.  
D.4.11 Appendices  
Appendices are included, as necessary, to provide a glossary, acronyms and abbre viations, and 
information published separately for convenience in document  maintenance . Included would be:  
(a) information that may be pertinent to multiple topic areas (e.g., description of methods  or 
procedures); (b) charts and proprietary data applicable to the technical efforts required in the 
SEMP ; and (c) a summary of technical plans associated with the project . Each appendix should 
be re ferenced in one of the sections of the engineering  plan where data would normally have 
been provided.  
 
This Document Is Uncontrolled When Printed.  98 Appendix E. Hierarchy of Related NASA Documents    
 
 
 

This Document Is Uncontrolled When Printed.  99 Appendix F . Tailoring  
F.1 Tailoring  is the documentation and approval  of the adaptation of the processes  and 
approach  to complying  with requirem ents according to the purpose , complexity , and scope  of a 
NASA program  or project . Tailoring, in cluding rationale for modifications, additions , or 
deletions should be approved  by the DGA . 
F.2 Each project  following this SE NPR  needs to tailor to the specific needs of a particular 
project, phase , or acquisition structure . Tasks that add unnecessary costs  or data and any factors 
that do not add value to the project should  be eliminated. Tailoring  takes the form of 
modification or addition.  
F.3 Tailoring  specific tasks requires definition  of the depth of detail, level of effor t, and the 
data expected. Tailoring is performed to both breadth and depth based on the project  and specific 
phase  of the life cycle . ―Tailoring in breadth‖ deals with factors that can include types and 
numbers of systems  impacted by the development  of a new subsystem, the numbers and types of 
assessments, and numbers and types of reviews . ―Tailoring in depth‖ involves decisions 
concerning the level of deta il needed to generate and substantiate the requirements . The depth of 
the SE effort varies from project to project in relation to complexity , uncert ainty, urgency, and 
the willingness to accept risk.  
F.4 The objectives of the effort , the scope  of the SE process , and the  breadth and depth of 
application  need to be considered. To assist in defining the depth of application and level of 
effort, the following should be evaluated as part of the tailoring  process of this SE NPR : 
a. The level of deta il in system  definition  required from the in -house Government or contracted  
effort . 
b. The directions and limitations of tasks including willingness to accept risk.  
c. The scenarios and missions  to be examined for each primary system  function.  
d. A set of measures of effectiveness .  
e. Known constraints  in areas where they exist but quantitative data is not available.  
f. The technology da tabase including identification of key technologies, performance, maturity, 
cost, risks , schedule , and any limiting criteria  on the use of technologies.  
g. The factors essential to system  success, including those factors related to major risk areas 
(e.g., budget, resources, and schedule ). 
h. Technical demonstration and confirmation events that need to be conducted (including 
technical review s).  
i. The goals  and constraints  of the project . 
j. The organizational and contractual requirements  for SE processes . 
k. The baseline  SE process for the organization  and tailoring  guidelines . 
l. Any cost  targets and the acceptable level  of risk.  
This Document Is Uncontrolled When Printed.  100 F.5 The basic SE tailoring  process can be applied to any development  effort (including new 
developments, modifications, and product  improve ments ) regardless of size or complexity . 
Attention to scope  of the effort and level of output  expected is essential. A revolutionary new 
system  development, for example, in Formulation  will not usually require formal configuration  
management audits  or formal change control  mechanisms. However, conceptual exploration 
investigation of modifications to an existing developed system may need this type of activity . 
F.6 The level of detail expected from the system  products  of the technical effort needs to be 
identified. This wi ll determine  the depth to which the SE process is executed. For example, 
functional analysis  and synthesis are conducted to a sufficiently detailed  depth to identify areas 
of technical risk based on the life-cycle  phase  or effort.  
F.7 The term ―sufficiently detailed ‖ is determined based on the objectives of the project  and 
can be characterized by the information content expected from the physical architecture . 
Throughout the life cycle , the level of detail may vary since the baseline  system  may be at one 
level of detail and product  improvements  or other modifications may be at a different level of 
detail. Note that level of detail needed from the technical effort to ensure adequacy of technical 
definition , design , and development  is not synonymous with the level of detail expected for 
management control  and reporting (e.g., cost  performance reports).  
F.8 The primary output  of the SE tailoring  process for a project  is documented in the 
SEMP . The form of the SEMP will vary depending on the s ize, complexity  and acceptable cost  
or risk level of the project.  
References  
The following documents  were used as reference  materials in the development  of this appendix:  
a. Defense Acquisition University Systems  Engineering  Fundamentals . Ft. Belvoir , Virginia: 
Defens e Acquisition University Press, December 2000 . 
b. International Council on Systems  Engineering  (INCOSE) Systems Engineering Guide . 
This Document Is Uncontrolled When Printed.  101 Appendix G . Technical Review Entrance and Success Crite ria 
This appendix describes the recommended best practices  for entrance and success criteria  for the 
technical review s required in Chapter  5. 
 
G.1 Program /System  Requirements  Review  
The P/SRR  is used to ensure that the program  requirements  are properly formulated and 
correlated with the Agency  and mission  directorate strategic objectives . 
Table G -1 – P/SRR  Entrance and Success  Criteria  
Program /System  Requirements Review   
Entr ance Criteria  Success Criteria  
1. A Formulation  Authorization Document  (FAD) has been 
approved .  
2. Program  requirements  have been defined  that support 
mission  directorate requirements on the program.  
3. Major program  risks  and corresponding mitigation 
strategies have been identified.  
4. The high -level progra m requirements  have been 
documented to include:  
a. performance,  
b. safety , and  
c. programmatic requirements . 
5. An approach  for verifying compliance  with prog ram 
requirements  has been defined . 
6. Procedures for controlling changes to program  requirements  
have been defined  and approved . 
7. Traceability of program  requirements  to individual projects  
is documented in accordance with Agency  needs, goals , and 
objectives, as described in the NASA Strategic Plan .  
8. Top program /project  risks  with significant technical, safety , 
cost, and schedule  impacts are identified.  
   1. With respect to mission  and science 
requirements , defined  high-level program  
requirements are determined to be 
complete and are approved . 
2. Defined interfaces with other programs  
are appro ved. 
3. The program  requirements  are 
determined to provide a cost -effective 
program.  
4. The program  requirements  are adequately 
levied on either the single -program 
project  or the multiple projects of the 
program.  
5. The plans for controlling program  
requirement  changes have been approved .   
6. The approach  for verifying compli ance 
with program  requirements  has been 
approved . 
7. The mitigation strategies for handling 
identified major risks  have been 
approved.  
 
G.2 Program /Syste m Definition  Review  
The P/SDR  applies to all NASA space flight programs to ensure the readiness  of the se program s 
to enter  an approved  Program  Commit ment Agreement  (PCA). The approved PCA permits 
programs to transition from the program formulation phase to the program implementation 
phase. A Program Approval Review (PAR) is conducted as part of the P/SDR to provide Agency 
management with an independent  assessment of the readiness of the program to proceed into 
implementation.   
 
The P/SDR examines the proposed program architecture and the flow down to the functional 
elements of the system. The proposed program’s objectives and the conce pt for meeting those 
This Document Is Uncontrolled When Printed.  102 objectives are evaluated. Key technologies and other risks are identified and assessed. The 
baseline Program Plan, budgets, and schedules are presented.  
 
The technical team provides the technical content to support the P/SDR.  
Table G -2 – P/SDR  Entrance and Success  Criteria  
Program /System Definition  Review  
Entrance Criteria  Success Criteria  
1. A Program /System  Requirements  
Review has been satisfactorily 
completed.  
2. A program  plan has been pr epared that 
includes the following:  
a. how the program will be managed;  
b. a list of specific projects;  
c. the high -level program requirements 
(including risk criteria);  
d. performance, safety, and 
programmatic requirements 
correlated to Agency and directorate 
strategic objectives ; 
e. description of the systems to be 
developed (hardware an d software), 
legacy systems, system interfaces, 
and facilities ; and   
f. identification of major constraints  
affecting system development (e.g., 
cost, launch window, required launch 
vehicle, mission planetary 
environment, engine design,  
international partners , and 
technology drivers) .   
3. Program level SEMP which includes 
project technical approaches and 
management plans to implement the 
allocated program requirements 
including constituent launch, flight, and 
ground systems, and operations and 
logistics concepts . 
4. Independent Cost Analyses (ICAs) and 
Independent Cost Estimates (ICEs)  
5. Management plan for resources other 
than budget.  
6. Documentation for obtaining the 
program commitment agreement that 
includes the following:  
a. the feasibility of the  
program mission solut ion with 
a cost estimate within 
acceptable cost range,  
b. project plans adequate for 
project formulation 1. An approved program plan and management 
approach.   
2. Approved SEMP and technical approach.  
3. Estimated costs are adequate.  
4. Documentation for obtaining the Program 
Commitment Agreement is approved.  
5. An approved draft program control pl an. 
6. Agreement that the program is aligned with the 
Agency needs, goals, and objectives.  
7. The technical approach is adequate.  
8. The schedule is adequate and consistent with cost, 
risk and mission goals.  
9. Resources other than budget are adequate and 
available.  
 
 
This Document Is Uncontrolled When Printed.  103 initiation,  
c. identified and prioritized 
program concept  
evaluation criteria to be 
used in project evaluations,  
d. estimates of required 
annual funding levels , 
e. credible program cost and 
schedule allocation 
estimates to projects,  
f. acceptable risk and 
mitigation strategies 
(supported  by a technical 
risk assessment ), 
g. organizational structures 
and defined work 
assignments,  
h. defined program 
acquisition strategies,  
i. interfaces to other 
programs and partners,  
j. a draft plan for program 
implementation, and  
k. a defined program 
management system.  
7. A draft program control plan that 
includes:  
a. how the program plans to 
control program 
requirements, technical 
design, schedule, and co st 
to achieve its high -level 
requirements;  
b. how the requirements, 
technical design, schedule, 
and cost of the program 
will be controlled ; 
c. how the program will 
utilize its technical, 
schedule, and cost reserves 
to control the baseline;  
d. How the program plans to 
report technical schedule, 
and cost status to the 
MDAA, including 
frequency and the level of 
detail; and  
e. how the program will 
address technical waivers 
and how dissenting 
opinions will be handled.  
8. For each project , a top -level description 
has been do cumented.  
 
 
 
This Document Is Uncontrolled When Printed.  104 G.3 Mission  Concept Review  
The MCR  affirm s the mission  need and examine s the proposed mission’ s objectives and the 
concept for mee ting those objectives.  
Table G -3 – MCR  Entrance and Success  Criteria  
Mission Concept Review  
Entrance Criteria  Success Criteria  
1. Mission goals  and objectives . 
2. Analysis  of alternative concepts to show 
at least one is feasible . 
3. Concept of operations . 
4. Preliminary mission  descope options . 
5. Prelim inary risk assessment , including 
technologies and associated risk 
management/mitigation strategies and 
options . 
6. Conceptual test  and evaluation  strategy . 
7. Preliminary technical plans to achieve 
next ph ase. 
8. Defined MOEs and MOPs . 
9. Conceptual life-cycle  support strategies 
(logistics,  manufacturing, and 
operation) . 1. Mission objectives are clearly defined  and stated and are 
unambiguous an d internally consistent . 
2. The preliminary set of requirements  satisfactorily provides a 
system  that will meet the mission  objectives . 
3. The mission  is feasible. A solution has been identified  that is 
technically feasible. A rough cost  estimate is within an 
acceptable cost range . 
4. The concept evaluation  criteria  to be used in candidate 
systems  evaluation have been identified and pr ioritized.  
5. The need for the mission  has been clearly identified . 
6. The cost  and schedule  estimates are credible . 
7. An updated  technical search was done to identify existing 
assets or products  that could satisfy the mission  or parts of 
the mission . 
8. Technical planning is sufficient to proceed to the next phase . 
9. Risk and mitigation strategies have been identified and are 
acceptable  based on technical risk assessments . 
 
G.4 System  Requirements  Review   
The SRR examine s the functional and performance requirement s defined  for the system  and the 
preliminary program  or project  plan and ensures that the requirements and the selected concept  
will satisfy the mission . 
Table G -4 – SRR Entrance and Success  Criteria  
System  Requirements Review   
Entrance Criteria  Success Criteria  
1. Successful completion of the MCR  and response s made to all MCR 
Requests for Actions (RFAs ) and Review Item Discrepancies  (RIDs) . 
2. A preliminary SRR agenda, success criteria , and charge to t he board 
have been agreed to by the technical team , project  manager , and 
review  chair prior to the SRR.  
3. The following technical products  for hardware and softwa re system  
elements are available to the cognizant participants prior to the 
review : 
a. system  requirements  document ; 
b. system  software  functionality description ; 
c. updated concept of operations ; 
d. updated mission  requirements , if applicable ; 
e. baselined  SEMP ; 
f. risk managem ent plan ; 
g. preliminary system  requirements  allocation to the next lower level 
system ; 1. The project  utilizes a sound 
process for the allocation and 
control  of requirements  
throughout all levels, and a 
plan has been defined  to 
complete the definition activity  
within schedule  constraints . 
2. Requirements  definition  is 
complete with respect to top-
level mission  and science  
requirements, and interfaces 
with external entities and 
between major internal 
elements have been defined.  
3. Requirements  allocation and 
flow down of key driving 
This Document Is Uncontrolled When Printed.  105 h. updated cost  estimate ; 
i. Technology Development Maturity Ass essment Plan ; 
j. updated risk assessment  and mitigations  (including PRA as 
applicable) . 
k. logistics  documentation (e.g., preliminary maintenance  plan); 
l. preliminary human ra ting plan , if applicable ; 
m. Software  Development Plan  (SDP) ; 
n. system  safety   and mission  assurance plan ; 
o. configuration management plan ; 
p. initial document  tree; 
q. verification and validation  approach ; 
r. preliminary system  safety  analysis ; and  
s. other specia lty disciplines , as required . requirements have been defined  
down to subsystems.  
4. Preliminary approaches have 
been determined for how 
requirements  will be verified 
and validated down to the 
subsystem level.  
5. Major risks  have been 
identified  and technically 
assessed , and viable mitigation 
strategies have be en defined.  
 
G.5 Mission Definition Review  
The MDR  examines  the proposed requirements , the mission  architecture , and the flow down  to 
all functional elements of the mission to ensure that the overall concept is complete, feasible , and 
consistent with available resources.  
 Table G -5 – MDR  Entrance and Success  Criteria  
Mission Definition Review  
Entrance Criteria  Success Criteria  
1. Successful completion of the SRR  and responses made to all SRR 
RFAs  and RIDs . 
2. A preliminary MDR  agenda, success criteria , and charg e to the board 
have been agreed to by the technical team , project  manager , and review  
chair prior to the MDR.  
3. The following technical products  for hardware and software  system  
elements are available to the cognizant participants prior to the review : 
a. system  architecture ; 
b. updated system  requirements  document , if applicable ; 
c. system  software  functionality description ; 
d. updated concept of operations , if applicable ; 
e. updated mission  requirements , if applicable ; 
f. updated SEMP , if applicable ; 
g. updated risk management plan , if applicable ; 
h. Technology Development Maturity Assessment Plan ; 
i. preferred system  solution definition , including major trades and 
options ; 
j. updated risk assessment  and mitigations  (including PRA, as 
applicable) ; 
k. updated cost  and schedule  data; 
l. logistics  documentation (e.g., preliminary maintenance  plan); 
m. Software  Development Plan  (SDP) ; 
n. system  safety  and mission  assurance plan ; 
o. configuration management plan ; 
p. updated initial document  tree, if applicable ; 
q. preliminary system  safety  analysis ; and  
r. other specialty disciplines as required . 1. The resulting overall concept 
is reasonable, feasible, 
complete, responsive to the 
mission  requirements , and is 
consistent with system  
requir ements and available 
resources (cost , schedule , 
mass , and power).  
2. System  and subsystem design  
approaches and operational 
concepts exist and are 
consistent with the 
requirements  set. 
3. The requirements , design  
approaches, and conceptual 
design will fulfill the mission  
needs within the estimated 
costs . 
4. Major risks  have been 
identified  and technically 
assessed , and viable 
mitigation strategies have 
been defined.  
 
 
This Document Is Uncontrolled When Printed.  106 G.6 System  Definition  Review  
The SDR examines  the proposed system  architecture  and design  and the flow  down to all 
functional elements of the system.  
Table G -6 – SDR Entrance and Success  Criteria  
System  Definition  Review  
Entrance Criteria  Success Criteria  
1. Successful completion of the SRR  and responses made to 
all SRR RFAs  and RIDs . 
2. A preliminary SDR agenda, success criteria , and charge to 
the board have been agreed to by the technical team , project  
manager , and review  chair prior to the SDR.  
3. SDR technical products  listed below for both hardware and 
software  system  elements have been made available to the 
cognizant participants prior to the review : 
a. system  architecture ; 
b. preferred system  solution definition  including major 
trade offs and options ; 
c. updated baselined  documentation, as required ; 
d. preliminary functional baseline  (with supporting trade -
off analyses and data) ; 
e. preliminary system  software  functional requirements ; 
f. SEMP  changes, if any ; 
g. updated risk management plan ; 
h. updated risk assessment  and mitigations  (including 
PRA, as applicable) ; 
i. updated technology development , maturity, and 
assessment  plan; 
j. updated cost  and schedule  data; 
k. updated logistics  documentation ; 
l. based on system  complexity , updated human rating  
plan; 
m. software  test plan; 
n. software  requirements  document (s); 
o. interface requirements  documents  (including  software ); 
p. technical resource  utilization estimates and margins ; 
q. updated safety  and mission  assurance (S&MA) plan; 
and 
r. updated preliminary safety  analysis . 1. Systems  requirements , including mission  
success criteria  and any sponsor -imposed 
constraints , are defined  and form the basis 
for the proposed conceptual design . 
2. All technical requirements  are allocated 
and the flow  down to subsystems is 
adequate.  The requirements, design  
approaches, and conceptual design will 
fulfill the mission  needs consistent with 
the available resources (cost , schedule , 
mass, and power).  
3. The requirements  process is sound and 
can reasonably be expected to continue to 
identify and flow detailed requirements in 
a manner timely for development . 
4. The technical approach  is credible and 
responsive to the identified requirements . 
5. Technical plans have been updated, as 
necessary . 
6. The trade offs are completed , and those 
planned for P hase B adequately address 
the option space . 
7. Significant development , mission , and 
safety  risks  are identified  and tec hnically 
assessed , and a process and resources 
exist to manage the risks.  
8. Adequate planning exists for the 
development  of any enabling new 
technology . 
9. The operations  concept is consistent with 
proposed design  concept(s) a nd is in 
alignment with the mission  requirements.  
 
G.7 Preliminary Design  Review  
The PDR demonstrates that the preliminary design  meets all system  requirements  with 
acceptable risk and within the cost  and schedule  constraints  and establishes the basis for 
proceeding with detailed design. It will s how that the correct design option s have been selected, 
interfaces have been identified, and verification  methods  have been described.  
This Document Is Uncontrolled When Printed.  107 Table G -7 – PDR Entrance and Success  Criteria  
Preliminary Design  Review  
Entrance Criteria  Success Criteria  
1. Successful completion of the SDR or MDR and responses 
made to all SDR  or MDR RFAs  and RIDs , or a timely 
closure plan  exists for those remaining open.  
2. A preliminary PDR agenda, success criteria , and charge 
to the board have been agreed to by the technical team , 
project  manager , and review  chair prior to the PDR.  
3. PDR technical products  listed below for both hardware 
and software  system  elements have been made available 
to the cognizant participants prior to the review : 
a. Updated baselined  documentation, as required . 
b. Preliminary subsystem design  specifications  for each 
configuration  item (hardware and software ), with 
supporting trade -off analyses and data, as required. 
The preliminary software design specification should  
include a completed definition  of the software 
architecture  and a preliminary database design 
description , as applicable . 
c. Updated technology development  maturity 
assessment  plan. 
d. Updated ris k assessment  and mitigation . 
e. Updated cost  and schedule  data. 
f. Updated logistics  documentation, as required . 
g. Applicable technical plans (e.g., technical 
performance measure ment plan, contamination 
control  plan, parts management plan, environments  
control plan, EMI/EMC control plan, payload-to-
carrier integration  plan, 
producibility/ manufacturability program  plan, 
reliability program plan, quality assurance plan). 
h. Applicable standards . 
i. Safety analyses and plans. 
j. Engineering drawing tree. 
k. Interface control documents . 
l. Verification/ validation  plan. 
m. Plans to respond to regulatory requirements  (e.g., 
Environmental Impact Statement), as required . 
n. Disposal  plan. 
o. Technical resource  utilization estimates and margins . 
p. System -level safety  analysis . 
q. Preliminary limited life items list (LLIL) . 1. The top -level requirements —including 
mission  success criteria , TPMs , and any 
sponsor -imposed constraints —are agreed 
upon,  finalized, stated clearly, and 
consistent with the preliminary design . 
2. The flow  down of verifiable requirements  is 
complete and proper or, if not, an adequate 
plan exists for timely resolution  of open 
items.  Requirements are traceable to 
mission  goals  and objectives . 
3. The preliminary design  is expected to meet 
the requirements  at an acceptable level of 
risk. 
4. Definition  of the technical interfaces is 
consistent with the overall t echnical 
maturity and prov ides an acceptable level of 
risk. 
5. Adequate technical interfaces are consistent 
with the overall technical maturity and 
provide an acceptable level of risk.  
6. Adequate technical margins exist with 
respect to TPMs . 
7. Any required new technology has been 
developed to an adequate state of readiness , 
or back -up option s exist and are supported 
to make them a viable alternative . 
8. The project  risks  are under stood  and have 
been credibly assessed , and plans , a 
process , and resources exist to effectively 
manage them.  
9. Safety and mission  assurance (e. g., safety , 
reliability, maintainability, quality, and 
EEE parts) have been adequate ly addressed 
in preliminary designs and any applicable 
S&MA products  (e.g., PRA, system  safety  
analysis , and failure modes and effects 
analysis) have been approved . 
10. The operational concept i s technically 
sound, includes (where appro priate) human 
factors , and includes the flow down of 
requirements  for its execution . 
 
This Document Is Uncontrolled When Printed.  108 G.8 Critical Design Review  
The CDR  demonstrate s that the maturity of the design  is appropriate to support proceeding with 
full-scale fabrication, assembly, integration , and test . CDR determines  that the technical effort is 
on track to compl ete the flight and ground system  development  and mission  operations , meet ing 
mission performance requirement s within the identified cost  and schedule  constraints . 
Table G -8 – CDR Entrance and Success  Criteria  
Critical Design Review  
Entrance Criteria  Success Criteria  
1. Successful completion of the PDR and responses made to all 
PDR RFAs  and RIDs , or a timely closure plan  exists for those 
remaining open.  
2. A preliminary CDR  agenda, success criteria , and charge to the 
board have been agreed to by the technical team , project  
manager , and review  chair prior to the CDR.  
3. CDR  technical work  products  listed below for both hardware 
and software  system  elements have been made available to the 
cognizant participants prior to the review : 
a. updated baselined  documents , as required ; 
b. product build -to specifications  for each hardware and 
software  configuration  item, along with supporting trade -off 
analyses and data ; 
c. fabrication, assembly, integration , and test  plans and 
procedures ; 
d. technical data package (e.g., integrate d schematics, spares 
provisioning list, interface control  documents , engineering  
analyses, and specifications ); 
e. operational limits and constra ints; 
f. technical resource  utilization estimates and margins ; 
g. acceptance c riteria ; 
h. command and telemetry l ist; 
i. verification p lan (including requirements  and specification ); 
j. validation  plan; 
k. launch s ite operations  plan; 
l. checkout and a ctivation p lan; 
m. disposal  plan (including decommissioning or ter mination) ; 
n. updated Technology Development Maturity Assessment 
Plan; 
o. updated risk assessment  and mitigation ; 
p. updated reliability analyses and assessments ; 
q. updated cost  and schedule  data; 
r. updated logistics  documentation ; 
s. software  design  document (s) (including interface d esign 
documents ); 
t. updated LLIL ; 
u. subsystem -level and preliminary operat ions safety  analyses ; 
v. systems  and subsystem cer tification plans and requirements  
(as needed) ; and  
w. system  safety  analysis  with associated ve rifications . 1. The detailed design  is expected to 
meet the requirements  with adequate 
margins at an acceptable level of 
risk. 
2. Interface control  documents  are 
sufficient ly matured to proc eed with 
fabrication, assembly,  integration , 
and test , and plans are in place to 
manage any open items . 
3. High confidence exists in the product  
baseline , and adequate 
documentation exists or w ill exist in 
a timely manner to allow proceeding 
with fabrication, assembly, 
integration , and test . 
4. The product  verification  and product 
validation  requirements  and plans are 
complete . 
5. The testing  approach  is 
comprehensive, and the planning for 
system  assembly, integration , test , 
and launch site and mission  
operations  is sufficient to progress 
into the next phase . 
6. Adequate technical and 
programmatic margins and resources 
exist to complete the development  
within budget, schedule , and risk 
constraints . 
7. Risks  to mission  success are 
understood  and credibly assessed , 
and plans and resources exist to 
effectively manage them.  
8. Safety and mission  assurance (e. g., 
safety , reliabili ty, maintainability, 
quality, and EEE parts) have been 
adequately addressed in system  and 
operational designs , and any 
applicable S&MA products  (e.g., 
PRA, system safety  analysis  and 
failure modes and effect s analysis) 
have been approved.  
This Document Is Uncontrolled When Printed.  109  
G.9 Production Readiness Review   
A PRR  is held for FS&GS  projects developing or acquiring multiple or similar systems  greater 
than three or as determined by the project . The PRR determines the readiness  of the system 
developers to efficiently produce the required num ber of systems. It ensures that the production 
plans; fabrication, assembly, and integration  enabling product s; and personnel are in place and 
ready to begin production.  
Table G -9 – PRR Entrance and Success  Criteria  
Production Readiness Review  
Entrance Criteria  Success Criteria  
1. The significant production 
engineering  problems 
encountered during 
development  are resolved.  
2. The design  documentation 
is adequate to support 
production . 
3. The production plans and 
preparation  are adequate to 
begin fabrication.  
4. The production -enabling 
products  and adequate 
resources are available, 
have been allocated, and 
are ready to support end 
product  production.  1. The design  is appropriately certified.  
2. The system  requirements  are fully met in the final production 
configuration . 
3. Adequa te measure s are in place  to support production . 
4. Design -for-manufacturing considerations ensure ease and efficiency of 
product ion and assembly.  
5. Risks  have been identified , credibly assessed,  and characterized , and 
mitigation eff orts have been defined . 
6. The bill of materials has been reviewed and critical parts identified.  
7. Delivery schedules  have been verified.  
8. Alternate sources for resources have been identified, as appropriate.  
9. Adequate spares  have been planned and budgeted.  
10. Required facilities  and tools  are sufficient for end product  production.  
11. Specified special tools  and test  equipment are available in proper 
quantities.  
12. Production and support staff are qualified.  
13. Drawings are certified.  
14. Production engineering  and planning are sufficiently mature for cost -
effective production.  
15. Production proce sses and methods  are consistent with quality 
requirements  and compliant with occupational safety , environmental, and 
energy conservation regulations . 
16. Qualified supplier s are available for materials that are to be procured.  
 
G.10 System  Integration Review  
An SIR  ensures that the system  is read y to be integrated. Segments, components, and subsystems 
are available and ready to be integrated into the system. Integration facilities , support personnel, 
and integration plans and procedures are ready for integration.  
Table G -10 – SIR Entrance and Success  Criteria  
System  Integration Review  
Entrance Criteria  Success Cri teria  
1. Integration plans and procedures have been completed and 
approved . 
2. Segments and/or components are available for integration . 
3. Mechanical and electrical interfaces have been verified 
again st the interface control  documentation.  1. Adeq uate integration  plans and procedures 
are completed and approved  for the system  
to be integrated.  
2. Previous component, subsystem, and 
system  test results  form a satisfactory basis 
This Document Is Uncontrolled When Printed.  110 4. All applicable functional, unit -level, subsystem, and 
qualification testing  has been conducted successfully.  
5. Integration facilities , including clean rooms, ground 
supp ort equipment, handling fixtures, overhead cranes , 
and electrical test  equipment , are ready and available.  
6. Support personnel have been adequately trained.  
7. Handling and safety  requirements  have been documented.  
8. All known system  discrepancies have been identified and 
disposed in accordance with an agreed -upon plan . 
9. All previous design  review  success criteria  and key issues 
have been satisfied in acco rdance with an agreed -upon 
plan. 
10. The quality control  organization  is ready to support the 
integration  effort.  for proceeding to integration . 
3. Risk level is identified and accepted by 
program /project  leadership , as required.  
4. The integration  procedures and work  flow 
have been clearly defined  and documented.  
5. The review  of the integration  plans, as well 
as the procedures, environment , and 
configuration  of the items to b e integrated, 
provide s a reasonable expectation  that the 
integration will pro ceed successfully.  
6. Integration personnel have received 
appropriate training  in the integration  and 
safety  procedures.  
 
G.11 Test Readiness Review  
A TRR  ensures that the test  article (hardware/software ), test facility, support pe rsonnel, and test 
procedures are ready for testing and data acquisition, reduction, and control . This is not a 
prerequisite for KDP  E. 
Table G -11 – TRR Entrance and Success  Criteria  
Test Readiness Review  
Entrance Criteria  Success Criteria  
1. The objectives of the testing  have been clearly defined  and 
documented , and all of the test plans, procedures, 
environment , and configuration  of the test item (s) support 
those objectives.  
2. Configuration of the syste m under test  has been defined  and 
agreed to. All interfaces have been placed under 
configuration  management or have been defined in 
accordance with an agreed to plan , and a version 
description document  has been made available to TRR  
participants prior to the review . 
3. All applicable functional, unit -level, subsystem, system , 
and qualification testing  has been conducted successfully.  
4. All TRR -specific materials , such as test  plans, test cases, 
and procedures , have been available to all par ticipants prior 
to conducting the review . 
5. All known system  discrepancies have been identified and 
disposed in a ccordance with an agreed -upon plan . 
6. All previous design  review  success  criteria  and key issues 
have been satisfi ed in accordance with an agreed -upon plan . 
7. All required test  resources —people (including a designated 
test director), facilities , test articles, test instrumentation, 
and other test enabling product s—have been identified and 
are available to support required tests.  
8. Roles  and responsibilities  of all test  participants are defined  
and agreed to.  
9. Test contingency planning has been accomplished, and all 
personnel have been trained.  1. Adequate test  plans are completed and 
approved  for the system  under test.  
2. Adequate identification and coordination 
of required test  resources are  completed . 
3. Previous component, subsystem, and 
system  test results  form  a satisfactory 
basis for proceeding into planned tests.  
4. Risk level is identified and accepted by 
program /competency leadership as 
required.  
5. Plans to capture any lessons learned from 
the test  program  are docum ented.  
6. The objectives of the testing  have been 
clearly defined  and documented, and the 
review  of all the test plans, as well as the 
procedures, environment , and 
configuration  of the test item, provide s a 
reasonable expectation  that the objectives 
will be met . 
7. The test  cases have been reviewed and 
analyzed for expected results , and the 
results are consistent with the te st plans 
and objectives . 
8. Test personnel have received appropriate 
training  in test operation and safety  
procedures.  
 
This Document Is Uncontrolled When Printed.  111 G.12 System  Acceptance Review  
The SAR  verif ies the compl eteness of the specific end  products  in relation  to the ir expected 
maturity level and assess es compliance  to stakeholder  expectations . The SAR examines  the 
system , its end products  and documentation, and test  data and analyses that support verification . 
It also ensures that the system has sufficient technical maturity to authorize its shipment to the 
designated operational facility or launch site.  
Table G -12 – SAR Entrance and Success  Criteria  
System  Acceptance Review  
Entrance Criteria  Success Criteria  
1. A preliminary agenda has been coordinated (nominally) 
prior to the SAR . 
2. The following SAR  technical products  have been made 
available to the cognizant participants p rior to the review : 
a. results  of the SARs conducted at the major suppliers ; 
b. transition  to production and/or manufacturing plan ; 
c. product verification  results ; 
d. product validation  results ; 
e. documentation that the delivered system  complies with 
the established acceptance criteria ; 
f. documentation that the system  will perform pr operly in 
the expected operational environment ; 
g. technical data p ackage updated to include all test  results ; 
h. certification package ; 
i. updated risk assessment  and mitigation ; 
j. successfull y completed p revious milestone  reviews ; and  
k. remaining liens  or unclosed actions and plans for 
closure.  1. Required tests  and analyses are complete 
and indicate that the system  will pe rform 
properly in the expected operational 
environment . 
2. Risks  are known and manageable.  
3. System  meets the established acceptance 
criteria . 
4. Required safe shipping, handling, 
checkout, and oper ational plans and 
procedures are complete and ready for 
use. 
5. Technical data package is complete and 
reflects the delivered system . 
6. All applicable lessons learned for 
organizational improvement and system  
operations  are captured.  
 
G.13 Operational Readiness Review  
The ORR  examines  the actual system  characteristics and the procedures used in the system or 
end product ’s operation and ensures that all system and support (flight and ground) hardware, 
software , personnel, procedures, and user documentatio n accurately reflect the deployed state of 
the system.  
Table G -13 – ORR Entrance and Success  Criteria  
Operational Readiness Review  
Entrance Criteria  Success Criteria  
1. All validation  testing  has been completed.  
2. Test failures and anomalies  from validation testing ha ve been resolved 
and the results  incorporated into all supporting and enabling 
operational products . 
3. All operational supporting and enabling product s (e.g., facilities , 
equipment, documents , updated databases) that are necessary for the 
nominal and contingency operations  have been tested and 
delivered/installed at the site(s) necessary to support operations.  
4. Operations  handbook  has been approved . 
5. Training has been provided to the users and operators on the correct 1. The system , including any 
enabling product s, is 
determined to be ready to be 
placed in an oper ational status.  
2. All applicable lessons learned 
for organizational 
improvement and systems  
operations  have been captured.  
3. All waivers  and anomalies  
have been closed.  
This Document Is Uncontrolled When Printed.  112 operational procedures for the system . 
6. Operational contingency planning has been accomplished, and all 
personnel have been trained.  4. Systems  hardware, software,  
personnel, and procedures are 
in place to support operations.  
 
G.14 Flight Readiness Review  
The FRR  exam ines tests, demonstrations, analyses, and audit s that determine the system ’s 
readiness for a safe and successful flight  or launch and for subsequent flight operations . It als o 
ensures that all flight and ground hardware, software , personnel, and procedures are 
operationally ready.  
Table G -14 – FRR Entrance and Success  Criteria  
Flight Readiness Review  
Entrance Criteria  Success Criteria  
1. Certification has been received that flight 
operations  can safely  proce ed with acceptable risk .  
2. The system  and support elements have been 
confirmed as  properly configured and ready for 
flight .  
3. Interfaces are compatible and function as expected.  
4. The system  state supports a launch ―go‖ decision 
based on go/no -go criteria . 
5. Flight failures and anomalies  from previously 
completed flights and reviews  have been resolved 
and the results  incorporated into all supporting and 
enabling oper ational products . 
6. The system  has been configured for flight.  1. The flight vehicle is ready for flight . 
2. The hardware is deemed acceptably safe for flight 
(i.e., meeting the established acceptable risk 
criteria  or documented as being accepted by the 
PM and DGA ). 
3. Flight and ground software  elements are ready to 
suppo rt flight and flight operations . 
4. Interfaces are checked and found to be functional . 
5. Open items and waivers  have been examined and 
found to be acceptable . 
6. The flight and recovery environmental factors are 
within constraint s. 
7. All open safety  and mission  risk items have been 
addressed.  
 
G.15 Post -Launch Assessment Review  
A PLAR  is a post -deployment evaluat ion of the readiness  of the spacecraft systems  to proceed 
with full , routine operations . The review  evaluates the status, performance, and capabilities  of 
the project  evident from the flight operations experience since launch. This can also mean 
assessing readiness to transfer responsibility from the development  organization  to the operations 
organization. The review also evaluates the status of the project plans and the capability to 
conduct th e mission  with emphasis on near -term operations and mission -critical events. This 
review is typically held after the early flight operation s and initial checkout.  
Table G -15 – PLAR  Entrance and Success  Criteria  
Post-Launch Assessment Review  
Entrance Criteria  Success Criteria  
1. The launch and early operations  performance, including (when 
appropriate) the early propulsive maneuver results , are available.  
2. The observed spacecraft  and science instrument performance , 
including instrument calibration plans and status , are available.   
3. The launch vehicle performance assessment  and mission  
implications , including launch sequence assessment , launch 1. The observed spacecraft and 
science payload perform ance 
agrees with prediction, or  if not, 
is adequately understood so  that 
future behavior can be predicted 
with confidence.  
This Document Is Uncontrolled When Printed.  113 operations  experience  with lessons learned , are completed.  
4. The mission  operations  and ground data system  experience , 
including tracking and data acquisition  support and spacecraft 
telemetry data analysis , is available.  
5. The mission  operations  organization , including status of 
staffing, facilities , tools , and mission software  (e.g., spacecraft 
analysis , and sequenci ng), is available.  
6. In-flight anomalies  and the respons ive actions  taken, including 
any autonomous fault protection actions taken by the spacecraft  
or any unexplained spacecraft telemetry , including alarms , are 
documented.  
7. The need for significant changes to procedures, interface 
agreements , software , and staffing has been documented.  
8. Documentation is updated, including any updates originating 
from the early opera tions  experience . 
9.  Future development/ test plans are developed.  2. All anomalies  have been 
adequately documented, and 
their impact on operations  
assessed.  Further, anomalies 
impacting spacecraft health and 
safety  or critical flight 
operations have been properly 
disposed.  
3. The mission  operations  
capabilities , including staffing 
and plans, are adequate to 
accommodate the actual flight 
performance.  
4. Liens , if any, on operati ons, 
identified as part of the ORR , 
have been satisfactorily 
disposed.  
 
G.16 Critical Event Readiness  Review  
A CERR  confirms  the project ’s readiness to execute the mission ’s critical activities  during flight 
operation .  
Table G -16 – CER R Entrance and Success  Criteria  
Critical Event Readiness Review  
Entrance Criteria  Success Criteria  
1. Mission overview and context for the critical event(s).  
2. Activity requirements  and constraints . 
3. Critical activity  sequence design  description including key  
trade offs and rat ionale for selected approach . 
4. Fault protection strategy.  
5. Critical activity  operations  plan including planned uplinks 
and criticality.  
6. Sequence verification  (testing , walk -throughs, peer 
review ) and critical activity  validation . 
7. Operations  team  training  plan and readiness  report. 
8. Risk areas and mitigations.  
9. Spacecraft readiness  report.  
10. Open items and plans.  1. The critical activity  design  compli es with 
requirements . 
2. The preparation  for the critical activity , 
including the verification  and validation , is 
thorough.  
3. The project  (including all the systems , 
supporting services, and docum entation) is 
ready to support the activity . 
4. The requirements  for the successful 
execution of the critical event(s) are 
complete and underst ood and have  flowed 
down to the appropriate levels for 
implementation . 
 
G.17 Post -Flight Assessment  Review  
The PFAR  evaluates the activities  from the flight after recovery. The review  identifies all 
anoma lies that occurred during the flight and mission  and determines the actions necessary to 
mitigate or resolve  the anomalies for future flights.  
This Document Is Uncontrolled When Printed.  114 Table G -17 – PFAR Entrance and Success  Criteria  
Post-Flight Assessment Review  
Entrance Criteria  Success Criteria  
1. All anomalies  that occurred duri ng the mission , as well as 
during preflight testing , countdown, and ascent , identified.  
2. Report on overall post -recovery condition.  
3. Report any evidence of ascent debris.  
4. All photo and video documentation available.  
5. Retention pla ns for scrapped hardware completed . 
6. Post-Flight Assessment Team  Operating Plan  completed.  
7. Disassembly activities  planned and scheduled.  
8. Processes  and controls  to coordinate in -flight anomaly trouble 
shooting and post -flight data preservation developed.  
9. Problem reports, corrective action requests, Post Flight 
Anomaly Records (PFARs), and final post -flight documentation 
completed.  
10. All post -flight hardware and flight data evaluation  reports 
completed.  1. Formal final report documenting 
flight performance and 
recommendations for future 
missions .  
2. All anomalies  have been 
adequately documented and 
dispositioned.  
3. The impact of anomalies  on 
future flight operations  has 
been assessed.     
4. Plans for retaining assessment  
documentation and imaging have 
been made.  
5. Reports and other documentation 
have been added to a database for 
performan ce comparison and 
trending.  
 
G.18 Decommissioning Review  
A DR confirm s the decision to terminate or decommission the system  and assess es the readiness  
of the system for the safe decommissioning and  disposal  of system assets.  
Table G -18 – DR Entrance and Success  Criteria  
Decommissioning Review  
Entrance Criteria  Success Criteria  
1. Requirements  associated 
with decommissioning and 
disposal  are defined . 
2. Plans are in place for 
decommis sioning, 
disposal , and any other 
removal from service 
activities .  
3. Resources are in place to 
support decommissioning 
and disposal  activities , 
plans for disposition of 
project  assets , and archival 
of essential mission  and 
project data.  
4. Safety, environmental , and 
any other const raints  are 
described . 
5. Current system  capabilities  
are described .  
6. For off -nominal 1. The reasons for decommissioning disposal  are documented.  
2. The decommissioning and dis posal  plan is complete, approved  by 
appropriate management, and compliant with applicable Agency  safety , 
environmental, and health regulations . Operations  plans for all potential 
scenarios, including contingencies, are complete and approved. All 
required support systems  are available.  
3. All personnel have been properly trained for the nominal and contingency 
procedures.  
4. Safety, h ealth , and environmental hazards have been identified. Controls  
have been verified.  
5. Risks  associated with the disposal  have been identified and adequately 
mitigated. Residual risks have been accepted by the required management.  
6. If hardware is to be recovered from orbit:  
a. Return site activity  plans have been defined  and approved . 
b. Required facilities  are available and meet requirements , including 
those for contamination control , if needed . 
c. Transportation plans are defined  and approved . Shipping containers 
and handling equipment , as well as contamination and environ mental 
control  and monitoring devices , are available.  
7. Plans for disposition of mission -owned assets ( i.e., hardware, software , 
and facilities ) have been defined  and ap proved . 
This Document Is Uncontrolled When Printed.  115 operations,  all contributing 
events, conditions, and 
changes to the originally 
expected baseline  are 
described . 8. Plans for archival and subsequent analysis  of mission  data have been 
defined  and approved . Arrangements have been finalized for the execution 
of such  plans . Plans for the capture and dissemination of appropriate 
lessons learned during the project  life cycle  have been defined and 
approved.  Adequate resources (schedule,  budget, and staffing) have been 
identified a nd are available to successfully complete all decommissioning, 
disposal,  and disposition activities . 
9. Plans for transition of personnel have been defined and approved.  
 
G.19 Periodic Technical Review  
a. Science and technol ogy development  conducted by NASA in BAR , ATD , and IP  programs  
and p rojects  may not be conducted along the same rigorous processes  and schedules  as 
FS&GS  programs. Depending on the scope  and technolog y readiness level  (TRL ) of these 
projects, a streamlined review  system  may be appropriate. Sound engineering  of processes 
defined  in this SE NPR  should be applied and reviewed , when appropriate. A PTR  review 
schedule with well -defined review entrance and success criteria  should be developed in 
project formulation . Success criteria  should ascertain whether sufficient technical maturity 
has been achieved to support a management decision to proceed to the next phase . In some 
cases, such as high TRL development  efforts, a subset of FS&GS reviews is appropriate 
(e.g., SRR, PDR, CDR , SAR ). PTRs should include both internal and independent external 
reviewers. Finding s and actions from each PT R should be disseminated and resolved after 
each review.  
 
b. NASA uses TRLs to measure the maturity of a technolog y. TRLs provide one metric for 
determining risk associated with the insertion of new technology. TRLs are shown in Table 
G-19. A TRL  of 6 (technology demonstrated in a relevant environment ) is desirable prior to 
integra ting a new technology . 
Table G -19 – Technology Readiness Level s 
 Techn ology Readiness  
Level  Description  
1 Basic principles observed and 
reported.  Lowest level of technology  readiness.   Scientific research begins to 
be translated into applied research  and development.   Examples 
might include pap er studies of a technology’s basic properties.   
2 Technology concept and/or 
application  formulated.  Invention begins.  Once basic principles are observed, practical 
applications can be invented.  The application  is speculative , and 
there is no proof or detailed analysis  to support the assumption.  
Examples are still limited to paper studies.   
3 Analytical and experimental 
critical function and/or 
characte ristic proof of concept.  At this step in the maturation process, active research and 
development  (R&D) is initiated. This must include both analytical 
studies to set the technology into an appropriate context and 
laboratory -based studie s to physically validate  that the analytical 
predictions are correct. These studies and  experiments should 
constitute ― proof -of-concept ‖ validation of the applications/concepts 
formulated at TRL  2. 
4 Component and/or breadboard 
validation  in laboratory 
environment.  Following successful ― proof -of-concept ‖ work , basic technological 
elements must be integrated  to establish  that the pieces will work 
together to achieve concept -enabling levels of performance for a 
This Document Is Uncontrolled When Printed.  116 component and/or breadboard. This validation  must be devised to 
support the concept that was formulated earlier and sho uld also be 
consistent with the requirements  of potential system  applications. 
The validation is re latively ― low-fidelity ‖ compared to the eventual 
system: it could be composed of ad hoc discrete components in a 
laborato ry. 
5 Component and/or breadboard 
validation  in relevant 
environment.  At this level, the fidelity of the component and/or breadboard being 
tested has to increase significantly. The basic technological elements 
must b e integrated  with reasonably realistic supporting elements so 
that the total applications (component -level, subsystem -level, or 
system -level) can be tested in a ―simulated ‖ or somewhat realistic 
environment.  
6 System/ subsystem model  or 
prototype demonstration in an 
operation environment.  A major step in the level of fidelity of the technology demonstration 
follows the completion of TRL  5. At TRL 6, a representative model  
or prototype system  or system , whic h would go well beyond ad hoc, 
―patch -cord,‖ or discrete component level breadboarding , would be 
tested in a relevant environme nt. At this level, if the only relevant 
environment is the environment of space, then the model  or 
prototype must be demonstrated in space.  
7 System  prototype demonstration 
in an operational environment.  Prototype near or at planned operational system .  TRL  7 is a 
significant step beyond TRL 6, requiring an actual system prototype 
demonstration in a space environment.  The prototype should be near 
or at the scale of the planned operational system , and the 
demonstration must take place in space.  Examples include testing  
the prototype in a test bed.   
8 Actual system  competed and 
―flight qualifie d‖ through test  and 
demonstration.  Technology has been proven to work  in its final form and under 
expected conditions.  In almost all cases, this level is the end of true 
system  development  for m ost technology elements. This might 
include integration  of new technology into an existing system.  
9 Actual system  flight proven 
through successful mission  
operations  Actual application  of the technology in its final form and under 
mission  conditions, such as those encountered in operational test  and 
evaluation.   In almost all cases, this is the end  of the last ―bug 
fixing‖ aspects of true system  development.   This TRL  does not 
include planned product  improvement of ongoing or reusable 
systems.  
Source:  Mankins (1995), ―Technology Readiness Level s: A White Paper .‖ 
 
 
G.20 Technical Peer Reviews  
a. Peer reviews  provide the technical insight essential to ensure product  and proc ess quality. 
Peer reviews are focused, in -depth technical review s that support the evolving design  and 
development  of a product , including critical documentation or dat a packages. They are often, 
but not always, held as supporting reviews for technical reviews such as PDR and CDR . A 
purpose  of the peer review is to add value and reduce ris k through expert knowledge, 
infusion, confirmation of approach , identification of defects, and specific suggestions for 
product improvements .  
b. The results  of the engineering  peer rev iews (EPRs) comprise a key element of the review  
process. The results and issues that surface during these reviews are documented and 
reported at the appropriate next higher element level . 
This Document Is Uncontrolled When Printed.  117 c. The peer reviewers  should be selected from outside the project , but they should have a 
similar technical background , and they should be selected for their skill and experience. Peer 
reviewers should be concern ed with only  the technical integrity and quality  of the product . 
Peer reviews  should be kept simple and informal. They should concentrate on a review of the  
documentation and minimize viewgraph presentations. A round -table  format rather than a 
stand -up presentation is pr eferred. The peer reviews  should give the full technical picture of 
items being reviewed.  
d. Technical depth should be established at  a level that allows the review  team  to gain insight 
into the t echnical risks . Rules should  be established to ensure consistency in the peer review 
process. At the conclusion of the review , a report on the findings and actions must be 
distributed.  
e. Peer reviews  must be part of the contract  for those projects  where systems  engineering  is 
done out -of-house.  
 
 
This Document Is Uncontrolled When Printed.  118 Appendix H. Templates  
H-1 Sample SE  NPR  Implementation  Plan  Template  
 
This Document Is Uncontrolled When Printed.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
SE NPR Implementation Plan  
 
<Center Name>  
 
 
 
 
 
 
 
 
 
 
 
 
 
Revision:   <enter r ev number>  
  <enter date>  
 
 
 
National Aeronautics and Space Administration  
 
SE NPR  IMPLEMENTATION  PLAN 
 
This Document Is Uncontrolled When Printed.    
SE NPR  Implementation  Plan 
<Center>  
<Date>  
 
 
 
 
 
 
Prepared by : 
 
 
 
 
 
  
Name  Date  
 
 
 
 
 
  
             Approved by:  
 
 
 
  
  
Name  
Center EMB Member  Date  
 
 
 
 
  
  
Name  
Office of  Chief Engineer  Date  
 
SE NPR  IMPLEMENTATION  PLAN 
 
This Docu ment Is Uncontrolled When Printed.  ii Change Log 
 
 
 
Rev.  Date  Originator  Approvals  Description  
     
     
     
     
     
     
     
 
SE NPR  IMPLEMENTATION  PLAN 
 
This Docu ment Is Uncontrolled When Printed.  iii Table of Contents  
 
 
1.0 INTRODUCTION  
1.1 PURPOSE  
1.2 SCOPE  
1.3 BACKGROUND  
1.4 DESIGNATED GOVERNING AUTHORITY  
2.0 REFERENCE DOCUMENTS  
3.0 COMPLIANCE WITH SE NPR 
3.1 DESCRIPTION OF CENTER COMPLIANCE METHODOLOGY  
3.2 COMPLIANCE MATRIX  
3.3 PLAN TO CLOSE GAPS  
4.0 OTHER  
 
APPENDIX A   ACRONYMS  
APPENDIX B   GLOSSARY  
SE NPR  IMPLEMENTATION  PLAN 
 
This Docu ment Is Uncontrolled When Printed.  iv Table of Figures  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table of Tables  
 
 
Table 3 -1     SE NPR Compliance Matrix  
 
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-1 1.0 INTRODUCT ION 
 
1.1 PURPOSE  
 
This document presents the organization’s plan to implement the requirements of the System 
Engineering (SE) NPR.  
 
1.2 SCOPE  
 
The scope of this document contains the plan for demonstrating compliance with the SE NPR 
requirements.   
 
1.3 BACKGROUND  
 
Describe basic product lines for the Center and the scope of application of NPR requirements.  
 
1.4 DESIGNATED GOVERNING AUTHORITY  
 
This section describes the criteria  or methodology that the Center will use to determine who the 
designated  governing a uthority (DGA) will be for various classes  or categorie s of projects 
performed at the C enter. One philosophy might be, f or example, for projects under $10 million , 
the DGA will be at the division level.  
 
2.0 REFERENCE  DOCUMENTS  
 
Enter s uch documents as existing  Center req uirement documents  and work instructions that 
reflect  implement ation of  the requirements of the NPR . 
 
3.0 COMPLIANCE WITH SE NPR  
 
3.1 DESCRIPTION OF CENTER COMPLIANCE METHODOLOGY  
 
This section would include general textual descriptions on how the organization will  approach 
compliance with the requirements in the SE NPR.  
 
Definition of the population that these requirements apply to and how they will be trained at the 
Center would also be included in this section.  
 
Estimates of the cost to implement these requiremen ts may also be included in this section.  
 
3.2 COMPLIANCE MATRIX  
 
Table 3 -1 provides the cross -reference of the SE NPR requirements with Center 
documentation.  
 
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-2  
 
Table 3 -1   SE NPR  Compliance  Matrix  
 
Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
1 2.1.1.2  The OCE , under the a uthority of this SE 
NPR , shall en sure compliance with this 
SE NPR.  NA NA NA NA NA 
2 2.1.1.3  For programs and projects  involving 
more than one Center, the lead 
organization shall develop 
documentation to describe the hierarchy 
and reconciliation of Center plans 
implementing this NPR.       
3 2.1.1.4  For systems that contain software, the 
technical team shall ensure that 
software developed within NASA or 
acquired complies with NPR 7150.2, 
NASA Software Engineering 
Requirements.  None    X Create a 
new 
work 
instruct -
tion 
4 2.1.1.5  The OCE shall be the clearinghouse for 
systems engineering policies to ensure 
compatibility a cross NASA .  NA NA NA NA NA 
5 2.1.2.2.
a Center Directors shall perform the 
following activit y or delegate it to the 
appropriate Center organization: 
develop the SE NPR Implementation 
Plan per the template in Appendix H -1 
describing how the requirements of  this 
SE NPR will be applied to the programs 
and projects under their cognizance or 
authority.   X   See this 
docu -
ment.  
6 2.1.2.2.
b Center Directors shall perform the 
following activities or delegate them to 
the appropriate Center organization: 
establish policies, procedures, and 
processes to execute the requirements 
of this SE NPR.  NPR 
7120.3   X  Update 
Center 
PR. 
7 2.1.2.2.c  Center Directors shall perform the 
following activities or delegate them to 
the appropriate Center organization: 
assess and take c orrective actions to 
improve the execution of the 
requirements of this SE NPR.  Center 
Survey   X  See 
Center 
Survey.  
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-3 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
8 2.1.2.2.
d Center Directors shall perform the 
following activities or delegate them to 
the appropriate Center organization: 
perform the SE  NPR Center Survey in 
accordance with Appendix H -2 for the 
purpose of providing feedback on the 
SE NPR. The initial Center Survey will 
be submitted five months from the 
effective date of this SE NPR. 
Subsequent updates will be upon the 
request of the OCE, no earlier than nine 
months after the initial submission. The 
Center Survey will use the common 
survey tool in Appendix H -2 and will be 
submitted through the Center System 
Engineering Working Group (SEWG) 
representative.  Center 
Survey  X   See 
Center 
Survey  
9 2.1.2.2.
e Center Directors shall perform the 
following activit y or delegate  it to the 
appropriate Center organization: select 
appropriate standards applicable to 
projects under their control.       
10 2.1.3  Each technical team shall execute the 
Center  processes intended to 
implement this SE NPR under the 
oversight of the Center Directors in 
accordance with the SEMP.       
11 2.2.1.2  The Center Directors shall submit their 
SE NPR Implementation Plan to the 
OCE within three months after the 
effective da te of this NPR.  Implemen -
tation Plan  X   See 
Imple -
menta -
tion 
Plan 
12 2.2.1.3  The Center Directors shall develop and 
document in the SE NPR 
Implementation Plan how the particular 
Center will assess compliance to the SE 
NPR and provide regular updates to the 
OCE.  Implemen -
tation Plan  X   See Im -
plement
ation 
Plan last 
sub-
mitted 
[date]  
13 2.3.1.1  The appropriate DGA shall have 
responsibility to approve or disapprove 
any SE NPR requirement that is either 
tailored or waived.       
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-4 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
14 3.1.3  The assigned tech nical teams shall 
define in the project SEMP how the 
required 17 common technical 
processes, as implemented by Center 
documentation, will be applied to the 
various levels of project WBS model 
system structure during each applicable 
life-cycle phase and hav e their 
approach approved by the DGA.       
15 3.2.1.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for the 
definition of stakeholder expectations 
for the appli cable WBS model.  Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
16 3.2.2.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for 
definition of the technical re quirements 
from the set of agreed upon stakeholder 
expectations for the applicable WBS 
model . Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
17 3.2.3.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, re quirements, 
guidelines, and documentation for 
logical decomposition of the validated 
technical requirements of the applicable 
WBS.  Example: 
JPR 
7120.3, 
Section xxx  X    
18 3.2.4.1  The Center Directors or designees shall 
establish and maintain a process to  
include activities, requirements, 
guidelines , and documentation for 
designing product solution definitions 
within the applicable WBS model that 
satisfy the derived technical 
requirements.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
19 3.2.5.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for 
implementation of a design solution 
definition by making, buying, or reusing 
an end product of the applicable WBS  
model.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-5 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
20 3.2.6.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for the 
integration of lower  level product s into 
an end product of the applicable WBS 
model in accordance with its design 
solution definition.     Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
21 3.2.7.1  The Center Directors or designees shall 
establish and maintain a process to 
include act ivities, requirements, 
guidelines, and documentation for 
verification of end products generated 
by the product implementation process 
or product integration process against 
their design solution definitions.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
22 3.2.8.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for 
validation of end products generated by 
the product implementation process or 
product integrat ion process against their 
stakeholder expectations.   None    X Add a 
new 
section 
to JPR 
7120.3  
23 3.2.9.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines , and documentation for 
trans itioning end products to the next 
higher level WBS -model customer or 
user.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
24 3.2.10.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and documentation for 
planning the technical effort.  Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
25 3.2.11.1  The Center Directors or designees shall 
establish and maintain a process to 
include activities, requirements, 
guidelines, and docu mentation for 
management of requirements defined 
and baselined during the application of 
the system design processes.  Example: 
JPR 
7120.3, 
Section xxx  X   No 
action 
needed  
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-6 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
26 3.2.12.1  The Center Directors or designees shall 
establish and maintain a proces s to 
include activities, requirements, 
guidelines, and documentation for 
management of the interfaces defined 
and generated during the application of 
the system design processes.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
27 3.2.13.1  The Center  Directors or designees shall 
establish and maintain a process  to 
include activities, requirements, 
guidelines, and documentation , for 
management of the technical risk 
identified during the technical effort.  
(NPR 8000.4, Agency Risk 
Management Procedural Requirements, 
is to be used as a source document for 
defining this process, and NPR 8705.5, 
Probabilistic Risk Assessment (PRA) 
Procedures for NASA Programs and 
Projects, provides one means of 
identifying and assessing technical 
risk.)  Example: 
NPR 
8000.4 
referenced 
in JPR 
7120.3.  X    
28 3.2.14.1  The Center Directors or designees shall 
establish and maintain a process  to 
include activities, requirements, 
guidelines, and documentation for 
configuration management.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
29 3.2.15.1  The Center Directors or designees shall 
establish and maintain a process  to 
include activities, requirements, 
guidelines, and documentation for 
management of the technical data 
generated and used in the technical 
effort.   Example:  
JPR 
7120.3, 
Section xxx   X  Update 
section  
30 3.2.16.1  The Center Directors or designees shall 
establish and maintain a process  to 
include activities, requirements, 
guidelines, and documentation for 
making assessments of the progress of 
planned technical  effort and progress 
toward requirements satisfaction.   Example: 
JPR 
7120.3, 
Section xxx   X  Update 
section  
31 3.2.17.1  The Center Directors or designees shall 
establish and maintain a process  to 
include activities, requirements, 
guidelines , and document ation for 
making technical decisions.   Example: 
JPR 
7120.3, 
Section xxx  X    
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-7 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
32 4.2.1  The assigned NASA technical team 
shall prepare a SEMP that covers the 
periods before contract award, during 
contract performance, and upon 
contract completion in accord ance with 
content contained in the annotated 
outline in Appendix D.        
33 4.2.2  The assigned technical team shall use 
common technical processes, as 
implemented by the Center's 
documentation, to establish the 
technical inputs  to the Request for 
Propos al (RFP) appropriate for the 
product to be developed , includ ing 
product requirements and Statement of 
Work tasks .        
34 4.2.3  The technical team shall determine the 
technical work products to be delivered 
by the offeror or contractor  to include a 
contractor SEMP that specifies the 
systems engineering approach for 
requirements development ; technical 
solution definition ; design realization ; 
product evaluation ; product transition ; 
and technical planning, control, 
assessment, and decision analysis.        
35 4.2.4  The technical team shall provide to the 
contracting officer, for inclusion in the 
RFP, the requirements for technical 
oversight activities planned in the NASA 
SEMP. (Care should be taken that no 
requirements or solicitation information 
is divulge d prior to the release of the 
solicitation by the cognizant contracting 
officer.)       
36 4.2.5  The technical team shall participate in 
the evaluation of offeror proposals 
following applicable NASA and Center 
source selection procedures.       
37 4.3.1  The assigned technical team, under the 
authority of the cognizant contracting 
officer, shall perform the technical 
oversight activities established in the 
NASA SEMP.        
38 4.4.1  The assigned technical team shall 
participate in scheduled milestone 
review s to finalize Government 
acceptance of the deliverables.        
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-8 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
39 4.4.2  The assigned technical team shall 
participate in product transition to the 
customer and/or disposal , as defined in 
the NASA SEMP.       
40 5.2.1.2  Technical teams shall monitor techn ical 
effort through periodic technical 
reviews.       
41 5.2.1.6  The technical team shall ensure that 
system aspects represented or 
implemented in software are included in 
all technical reviews to demonstrate that 
project technical goals and progress are 
being achieved and that all NPR 7150.2 
software review requirements are 
implemented.        
42 5.2.2  The technical team shall develop and 
document plans for technical reviews 
for use in the project planning process. 
The technical review schedule , as 
docume nted in the SEMP , will be 
reflected in the overall project plan 
described in NPR 7120.5. The results of 
each technical review will be used to 
update the technical review plan as part 
of the SEMP update process. The 
review plans, data, and results should 
be maintained and dispositioned as 
Federal records.       
43 5.3.1.2  The technical team shall address the 
entrance and success criteria listed in 
Appendix G for applicability to the 
respective reviews .      
44 5.3.1.3  The technical team shall execute the 
required Program/System 
Requirements Review (P/SRR) and 
Program Approval Review (PAR) in 
accordance with the review entry and 
success criteria defined in tables G -1 
and G -2 of Appendix G.        
45 5.3.1.4  The technical team shall execute the 
required progr am technical reviews in 
accordance with the following timeline: 
P/SRR before KDP 0 and PAR before 
KDP 1.       
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-9 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
46 5.3.1.5  For human FS&GS projects, the 
technical team shall execute the 
following required minimum set of 
technical reviews in accordance with 
the review entry and success criteria 
defined in tables G -3, G-4, G-6, G-7,  
G-8, and G -10 through G -18 of 
Appendix G: Mission Concept Review 
(MCR), System Requirements Review 
(SRR), System Definition Review 
(SDR), Preliminary Design Review 
(PDR), Critical  Design Review (CDR), 
System Integration Review (SIR), Test 
Readiness Review (TRR), System 
Acceptance Review (SAR), Operational 
Readiness Review (ORR), Flight 
Readiness Review (FRR), Post -Launch 
Assessment Review (PLAR), Critical 
Event Readiness Review (CE RR), Post -
Flight Assessment Review (PFAR), and 
Decommissioning Review (DR). (For 
more information on program and 
project life cycles and management 
reviews, see the appropriate NPR, e.g., 
NPR 7120.5.)       
47 5.3.1.6  For robotic FS&GS projects, the 
techni cal team shall execute and 
document the following minimum 
required technical reviews: the MCR, 
SRR, Mission Definition Review ( MDR ), 
PDR, CDR, SIR, TRR, ORR, FRR, 
PLAR, CERR, and DR in accordance 
with the review entry and success 
criteria given in tables G -3, G-4, G-5,  
G-7, G-8, G-10, G -11, G -13 through   
G-16, and G -18 of Appendix G. Robotic 
projects can combine the SRR and 
MDR based on size and level of risk. If 
the two reviews are conducted 
separately, Table G -4 will be used for 
the SRR and Table G -5 will be used for 
the MDR. If the two reviews are 
combined, the entrance and success 
criteria for both SRR and MDR will be 
combined for this single review.       
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-10 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
48 5.3.1.7  The technical team shall also execute a 
Production Readiness Review (PRR) as 
an additi onal technical review for both 
human and robotic FS&GS projects 
developing or acquiring multiple or 
similar systems greater than three (or 
as determined by the project) in 
accordance with the review entry and 
success criteria defined in Table G -9 of 
Append ix G. Any project producing end 
products with three or less units will still 
perform the required CDR. The CDR 
will include production considerations 
when a PRR is not performed.       
49 5.3.1.8  The technical team shall execute the 
required FS&GS project technical 
reviews in accordance with the following 
timelines:  
a. MCR prior to KDP A.  
b. Human FS&GS project SRR prior to 
SDR, and robotic missions SRR 
and MDR prior to KDP B.  
c. Human FS&GS project SDR prior to 
KDP B.  
d. PDR prior to KDP C.  
e. CDR prior to starting fabri cation of 
system end products and SIR.  
f. PRR prior to starting fabrication of 
system end products for projects 
requiring multiple units.  
g. SIR prior to KDP D.  
h. TRR prior to starting product 
verification and product validation 
testing.  
i. Human FS&GS project SAR af ter 
completion of KDP D.  
j. ORR after SAR or KDP D and 
before FRR.  
k. FRR prior to KDP E.  
l. PLAR after system end product 
launch.  
m. CERR after PLAR and before KDP 
F. 
n. Human FS&GS project PFAR at 
end of flight and before KDP F.  
o. DR after KDP F.       
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-11 Req 
ID SE NPR 
Section  Requirement Statement  Center Implementa tion Intent  
Existing 
Center 
Docu -
ment(s)/ 
Section  Compliance  
Plan to 
Close 
Gap Full Partial  None  
50 5.3.1.9  The ass igned technical team shall 
accomplish the monitoring function for 
flight -related ATD projects using 
appropriately defined and conducted 
periodic technical reviews (PTR) and 
continuation reviews  (CRs) . (See Figure 
5-3.)       
51 5.3.1.10  The assigned techn ical team shall 
accomplish the monitoring function for 
IPs using PTR and SAR. (See Figure 5 -
3.)      
52 6.2.1  Working with the program/project 
manager, the technical team shall 
determine the appropriate level within 
the system structure at which SEMPs 
are developed, taking into account 
factors such as number and complexity 
of interfaces, operating environments, 
and risk factors.        
53 6.2.2  The technical team shall baseline the 
SEMP per the Center's Implementation 
Plan, incorporating the content 
conta ined in Appendix D , Systems 
Engineering Management Plan, prior to 
completion of Phase A in the program 
life cycle or the equivalent milestone.        
54 6.2.3  The DGA shall review and approve or 
disapprove the SEMP at each major 
milestone review or its eq uivalent.        
55 6.2.4  The assigned technical team shall 
establish the initial SEMP early in the 
Formulation phase and update it as 
necessary to reflect changes in scope 
or improved technical development.        
56 6.2.5  The technical team shall ensur e that 
any technical and discipline plans 
describe how the technical activities 
covered in the plans are consistent with 
the SEMP and are accomplished as 
fully integrated parts of the technical 
effort.        
57 6.2.6  The technical team shall ensure that the 
project's software development/  
management plan describes how the 
software activities are consistent with 
the SEMP and are accomplished as 
fully integrated parts of the technical 
effort.        
 
SE NPR  IMPLEMENTATION PLAN 
 
This Document Is Uncontrolled When Printed.  H1-12  
 
 
3.3 PLAN TO CLOSE GAPS  
 
This section would include textua l descriptions about how the gaps noted in the matrix will be 
closed . 
 
 
 
 
 
 
 
4.0 OTHER  
 
 
 
 
 
 
 
This Document Is Uncontrolled When Printed.  132 H-2 SE NPR Center Survey  
 
This Document Is Uncontrolled When Printed.        
    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
SE NPR Center Survey  
 
<Center Name>  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Revision :  <enter rev number>  
<enter date>  
 
 
National Aeronautics and Sp ace Administration  
 
 
This Document Is Uncontrolled When Printed.  H2-i  
SE NPR Center Survey  
<Center>  
<Date>  
 
 
 
 
 
 
Prepared by : 
 
 
 
 
 
  
Name  Date  
 
 
 
 
 
  
Approved by:  
 
 
 
  
  
Name  
 Date  
 
 
 
 
  
  
Name  
 Date  
 
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-ii Change Log 
 
 
 
Rev.  Date  Originator  Approvals  Description  
     
     
     
     
     
     
     
 
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-iii Table of Contents  
 
1.0 INTRODUCTION  
1.1 PURPOSE  
1.2 SCOPE  
1.3 BACKGROUND  
2.0 APPLICABLE DOCUMENTS  
3.0 PLANNED ACTIVITIES  
3.1 DESCRIPTION OF CENTER -EQUIVALENT ACTIVITIES  
3.2 TRACEABILITY  MATRIX  
3.3 PLAN TO CLOSE GAPS 
4.0 LESSONS LEARNED  
5.0 CENTER BEST PRACTICES  
6.0 OTHER  
 
APPENDIX A   ACRONYMS  
APPENDIX B   GLOSSARY  
 
 
Table of Figures  
 
 
 
 
Table of Tables  
 
Table 3 -1     Traceability Matrix  
 
SE NPR Center Survey  
 
This Document Is Uncontrolled When Printed.  H2-1 1.0 INTRODUCTION  
 
1.1 PURPOSE  
 
This document presents the organization’s survey for implementing the best practice activities as 
described in A ppendix C of the System Engineering NPR.  
 
1.2 SCOPE  
 
The scope of this document contains the plan and traceability for implementing the best practice 
activities .   
 
1.3 BACKGROUND  
 
Describe basic product lines for the Center and the scope of application of NPR act ivities.  
 
2.0 REFERENCE  DOCUMENTS  
 
List documents s uch as  existing  Center requirement documents  or work instructions that reflect  
implement ation of  the NPR  activities.  
 
3.0 PLANNED ACTIVITIES  
 
3.1 DESCRIPTION OF CENTER -EQUIVALENT ACTIVITIES  
 
This section would include  general textual descriptions on the activities used to accomplish the 
processes at the Center.  
 
3.2 TRACEABILITY MATRIX  
 
Table 3 -1 provides the cross -reference of the expected process activities listed in Appendix C of 
the SE NPR with equivalen t activities in  or planned for C enter documentation . 
 
SE NPR Center Survey  
 
This Document Is Uncontrolled When Printed.  H2-2 TABLE 3-1   PROCESS ACTIVITY TRACEABILITY MATRIX  
 
 
No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
1 Stakeholder 
Expectations 
Definition 
Process  a). Establish a list that identifies 
customers and other stakeholders 
that have an interest in the system 
and its products.    Example:  
JPR 7120.3, 
Section xxx   x  Update 
section  
b). Elicit c ustomer and other 
stakeholder expectations (needs, 
wants, desires, capabilities, external 
interfaces, and constraints) from the 
identified stakeholders.   None    X Create a 
new work 
instruct -
ion 
c). Establish operational concepts 
and support strategies based on 
stakeholders’ expected use of the 
system products over the system’s 
life. JPR 7120.3, 
Section xxx  x    
d). Define stakeholder expectations 
in acceptable statements that are 
complete sentences and have the 
following characteristics: (1) 
individu ally clear, correct, and 
feasible to satisfy; not stated as to 
how it is to be satisfied; 
implementable; only one 
interpretation of meaning; one actor -
verb-object expectation; and can be 
validated at the level of the system 
structure at which it is stated;  and 
(2) in pairs or as a set there is an 
absence of redundancy, consistency 
with respect to terms used, are not 
in conflict with one another, and do 
not contain stakeholder expectations 
of questionable utility or which have 
an unacceptable risk of satisfa ction.    JPR 7120.3, 
Section xxx    X None  
e). Analyze stakeholder expectation 
statements to establish a set of 
measures (measures of 
effectiveness) by which overall 
system or product effectiveness will 
be judged, and customer satisfaction 
will be deter mined.        
f). Validate that the resulting set of 
stakeholder expectation statements 
are upward and downward traceable 
to reflect the elicited set of 
stakeholder expectations and that 
any anomalies identified are 
resolved.       
g). Obtain commitme nts from 
customer and other stakeholders 
that the resultant set of stakeholder 
expectation statements is 
acceptable.        
h). Baseline the agreed to set of 
stakeholder expectation statements.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-3 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
2 Technical 
Require -
ments 
Definition 
Process  a). Ana lyze the scope of the 
technical problem to be solved to 
identify and resolve the design 
boundary that identifies: (1) which 
system functions are under design 
control and which are not; (2) 
expected interaction among system 
functions (data flows, human 
responses, and behaviors); (3) 
external physical and functional 
interfaces (mechanical, electrical, 
thermal, data, procedural) with other 
systems; (4) required capacities of 
system products; (5) timing of 
events, states, modes, and functions 
related to operati onal scenarios; and 
(6) emerging or maturing 
technologies necessary to make 
requirements.        
b). Define constraints affecting the 
design of the system or products or 
how the system or products will be 
able to be used.         
c). Define functiona l and behavioral 
expectations for the system or 
product in acceptable technical 
terms for the range of anticipated 
uses of system products as 
identified in the concept of 
operations; this permits separating 
defined stakeholder expectation 
functions and beh aviors that belong 
to a lower level in the system 
structure and allocating them to the 
appropriate level.        
d). Define the performance 
requirements associated with each 
defined functional and behavioral 
expectation.         
e). Define technical requirements in 
acceptable “shall” statements that 
are complete sentences with a 
single “shall” per numbered 
statement and have the following 
characteristics: (1) individually clear, 
correct, and feasible; not stated as 
to how it is to be satisfied; 
implem entable; only one 
interpretation of meaning; one actor -
verb-object requirement; and can be 
validated at the level of the system 
structure at which it is stated; and 
(2) in pairs or as a set, there is an 
absence of redundancy, consistency 
with terms used, n o conflict with one 
another, and form a set of “design -
to” requirements.        
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-4 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
  f). Validate that the resulting 
technical requirement statements: 
(1) have bidirectional traceability to 
the baselined stakeholder 
expectations; (2) were formed using 
valid assumptions; and (3) are 
essential to and consistent with 
designing and realizing the 
appropriate product solution form 
that will satisfy the applicable 
product -line life -cycle phase exit 
criteria.        
g). Define MOPs for each identified 
measure of e ffectiveness (MOE) that 
cannot be directly used as a design -
to technical requirement.        
h). Define appropriate TPMs by 
which technical progress will be 
assessed.       
i). Establish the technical 
requirements baseline.       
3 Logical 
Decompos -
ition 
Process  a). Define one or more logical 
decomposition models based on the 
defined technical requirements to 
gain a more detailed understanding 
and definition of the design problem 
to be solved.        
b). Allocate the technical 
requirements to the l ogical 
decomposition models to form a set 
of derived technical requirement 
statements that have the following 
characteristics:  
(1) describe functional and 
performance, service and attribute, 
time, and data flow requirements, 
etc., as appropriate for the se lected 
set of logical decomposition models;    
(2) individually are complete 
sentences and are clear, correct, 
and feasible; not stated as to how to 
be satisfied; implementable; only 
have one interpretation of meaning, 
one actor -verb-object expectation; 
and can be validated at the level of 
the system structure at which it is 
stated;  
(3) in pairs or as a set, have an 
absence of redundancy, are 
adequately related with respect to 
terms used, and are not in conflict 
with one another; and  
(4) form a set of detai led “design -to” 
requirements.       
c). Resolve derived technical 
requirement conflicts.         
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-5 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
  d). Validate that the resulting set of 
derived technical requirements 
have: (1) bidirectional traceability 
with the set of validated technical 
requiremen ts and (2) assumptions 
and decision rationales consistent 
with the source set of technical 
requirements.        
e). Establish the derived technical 
requirements baseline.       
4 
 
 Design 
Solution 
Definition 
Process  a). Define alternative solutions for 
the system end product being 
developed or improved that are 
consistent with derived technical 
requirements and nonallocated 
technical requirements, if any.         
b). Analyze each alternative solution 
against defined criteria, such as 
satisfaction of e xternal interface 
requirements; technology 
requirements; off -the-shelf 
availability of products; physical 
failure modes, effects, and criticality; 
life-cycle cost and support 
considerations; capacity to evolve; 
make vs. buy; standardization of 
products; in tegration concerns; and 
context of use issues of operators 
considering tasks, location, 
workplace equipment, and ambient 
conditions.        
c). Select the best solution 
alternative based on the analysis 
results of each alternative solution 
and technical  decision analysis 
recommendations.       
d). Generate the full design 
description of the selected 
alternative solution in a form 
appropriate to the product -line life -
cycle phase, location of the WBS 
model in the system structure, and 
phase exit criteri a to include: (1) 
system specification and external 
interface specifications; (2) end 
product specifications, configuration 
description documents, and 
interface specifications; (3) end 
product subsystem initial 
specifications, if subsystems are 
required; ( 4) requirements for 
associated supporting enabling 
products; (5) end product verification 
plan; (6) end product validation plan; 
and (7) applicable logistics and 
operate -to procedures.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-6 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
  e). Verify that the design solution 
definition: (1) is realiza ble within 
constraints imposed on the technical 
effort; (2) has specified requirements 
that are stated in acceptable 
statements and have bidirectional 
traceability with the derived technical 
requirements, technical 
requirements, and stakeholder 
expectation s; and (3) has decisions 
and assumptions made in forming 
the solution consistent with its set of 
derived technical requirements, 
separately allocated technical 
requirements, and identified system 
product and service constraints.        
f). Baseline the design solution 
definition specified requirements 
including the specifications and 
configuration descriptions.        
g). Initiate development or 
acquisition of the life -cycle 
supporting enabling products 
needed, as applicable, for research, 
development , fabrication, 
integration, test, deployment, 
operations, sustainment, and 
disposal.        
h). Initiate development of the 
system products of the next lower 
level WBS model, if any.         
5 Product 
Implementa
-tion 
Process  a). Prepare to conduct prod uct 
implementation including: (1) 
prepare a product implementation 
strategy and detailed planning and 
procedures and (2) determine 
whether the product configuration 
documentation is adequately 
complete to conduct the type of 
product implementation as 
appli cable for the product -line life -
cycle phase, location of the product 
in the system structure, and phase 
exit criteria.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-7 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
  b). If the strategy is for buying an 
existing product, participate in the 
buy of the product including: (1) 
review the technical information 
made available by vendors; (2) 
assist the preparation of requests for 
acquiring the product from a vendor; 
(3) assist the inspection of the 
delivered product and the 
accompanying documentation; (4) 
determine whether the vendor 
conducted product  validation or if it 
will need to be done by a project 
technical team; and (5) determine 
the availability of enabling products 
to provide test, operations, and 
maintenance support and disposal 
services for the product.       
c). If the strategy is to re use a 
product that exists in the 
Government inventory, participate in 
acquiring the reused product 
including: (1) review the technical 
information made available for the 
specified product to be reused; (2) 
determine supporting documentation 
and user manual s availability; (3) 
determine the availability of enabling 
products to provide test, operations, 
and maintenance support and 
disposal services for the product; (4) 
assist the requests for acquiring the 
product from Government sources; 
and (5) assist the in spection of the 
delivered product and the 
accompanying documentation.        
d). If the strategy is to make the 
product, (1) evaluate the readiness 
of the product implementation 
enabling products to make the 
product, (2) make the specified 
product in ac cordance with the 
specified requirements, 
configuration documentation, and 
applicable standards, and (3) 
prepare appropriate product support 
documentation, such as integration 
constraints and/or special 
procedures for performing product 
verification and pr oduct validation.       
e). Capture work products and 
related information generated while 
performing the product 
implementation process activities.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-8 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
6 Product 
Integration 
Process  a). Prepare to conduct product 
integration to include: (1) preparing 
a product integration strategy, 
detailed planning for the integration, 
and integration sequences and 
procedures; and (2) determining 
whether the product configuration 
documentation is adequately 
complete to conduct the type of 
product integration applicable  for the 
product -line life -cycle phase, 
location of the product in the system 
structure, and management phase 
exit criteria.       
b). Obtain lower level products 
required to assemble and integrate 
into the desired product.       
c). Confirm that the r eceived 
products that are to be assembled 
and integrated have been validated 
to demonstrate that the individual 
products satisfy the agreed upon set 
of stakeholder expectations, 
including interface requirements.       
d). Prepare the integration 
environm ent in which assembly and 
integration will take place to include 
evaluating the readiness of the 
product -integration enabling 
products and the assigned 
workforce.       
e). Assemble and integrate the 
received products into the desired 
end product in acc ordance with the 
specified requirements, 
configuration documentation, 
interface requirements, applicable 
standards, and integration 
sequencing and procedures.       
 f). Prepare appropriate product 
support documentation, such as 
special procedures for p erforming 
product verification and product 
validation.       
g). Capture work products and 
related information generated while 
performing the product integration 
process activities.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-9 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
7 
 Product 
Verification 
Process  
?  a). Prepare to conduct product 
verification to include as applicable 
to the product -line life -cycle phase 
and WBS model location in the 
system structure: (1) reviewing the 
product verification plan for specific 
procedures, constraints, conditions 
under which verification will take 
place , pre- and post -verification 
actions, and criteria for determining 
the success or failure of verification 
methods and procedures; (2) 
arranging the needed product -
verification enabling products and 
support resources; (3) obtaining the 
end product to be ver ified; (4) 
obtaining the specification and 
configuration baseline against which 
the verification is to be made; and 
(5) establishing and checking the 
verification environment to ensure 
readiness for performing the 
verification.       
b). Perform the prod uct verification 
in accordance with the product 
verification plan and defined 
procedures to collect data on each 
specified requirement with specific 
attention given to MOPs.       
c). Analyze the outcomes of the 
product verification, including 
identifyi ng verification anomalies, 
establishing recommended 
corrective actions, and establishing 
conformance to each specified 
requirement under controlled 
conditions.       
d). Prepare a product verification 
report providing the evidence of 
product conformance  with the 
applicable design solution definition 
specified requirements baseline to 
which the product was generated, 
including bidirectional requirements 
traceability and actions taken to 
correct anomalies of verification 
results.       
e). Capture the wo rk products from 
the product verification.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-10 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
8 ? Product 
Validation 
Process  a). Prepare to conduct product 
validation to include as applicable to 
the product -line life -cycle phase and 
product location in the system 
structure: (1) reviewing the product 
validation plan for specific 
procedures, constraints, conditions 
under which validation will take 
place, pre - and post -validation 
actions, and criteria for determining 
the success or failure of validation 
methods and procedures; (2) 
arranging the needed pr oduct -
validation enabling products and 
support resources; (3) obtaining the 
end product to be validated; (4) 
obtaining the stakeholder 
expectations baseline against which 
the validation is to be made; and (5) 
establishing and evaluating the 
validation envi ronment to ensure 
readiness for performing the 
validation.       
b). Perform the product validation in 
accordance with the product 
validation plan and defined 
procedures to collect data on 
performance of the product against 
stakeholder expectations with  
specific attention given to MOEs.       
c). Analyze the outcomes of the 
product validation to include 
identification of validation anomalies, 
establishing recommended 
corrective actions, and establishing 
conformance to stakeholder 
expectations under op erational 
conditions (actual, analyzed, or 
simulated).       
d). Prepare a product validation 
report providing the evidence of 
product conformance with the 
stakeholder expectations baseline, 
including corrective actions taken to 
correct anomalies of val idation 
results.       
e). Capture the work products from 
the product validation.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-11 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
9 
 Product 
Transition 
Process  
?  
 a). Prepare to conduct product 
transition to include: (1) preparing a 
product implementation strategy to 
establish the type of produ ct 
transition to be made (to the next 
higher level customer for product 
integration or to an end user); and 
(2) reviewing related end product 
stakeholder expectations and design 
solution definition specified 
requirements to identify special 
transition proc edures and enabling 
product needs for the type of 
product transition, if any, for 
packaging, storage, handling, 
shipping/transporting, site 
preparation, installation, or 
sustainment.       
b). Evaluate the end product, 
personnel, and enabling product 
readiness for product transition 
including: (1) availability and 
appropriateness of the 
documentation that will be packaged 
and shipped with the end product; 
(2) adequacy of procedures for 
conducting product transition; (3) 
availability and skills of personne l to 
conduct product transition; and (4) 
availability of packaging 
materials/containers, handling 
equipment, storage facilities, and 
shipping/transporter services.       
c). Prepare the end product for 
transition to include the packaging 
and moving the p roduct to the 
shipping/transporting location and 
any intermediate storage.       
d). Transition the end product with 
required documentation to the 
customer, based on the type of 
transition required, e.g., to the next 
higher level WBS model for product 
integration or to the end user.       
e). Prepare sites, as required, where 
the end product will be stored, 
assembled, integrated, installed, 
used, or maintained, as appropriate 
for the life -cycle phase, position of 
the end product in the system 
structure,  and customer agreement.       
f). Capture work products from 
product transition process activities.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-12 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
10 Technical 
Planning 
Process  a). Prepare to conduct technical 
planning to include: (1) preparing or 
updating a planning strategy for 
each of the c ommon technical 
processes of this SE NPR and (2) 
determining: (a) deliverable work 
products from technical efforts, (b) 
technical reporting requirements, (c) 
other technical information needs for 
reviews or satisfying product -line 
life-cycle management pha se entry 
or exit criteria, (d) product and 
process measures to be used in 
measuring technical performance, 
cost, and schedule progress, (e) key 
or critical technical events with entry 
and success criteria, (f) data 
management approach for data 
collection a nd storage and how 
measurement data will be analyzed, 
reported, and dispositioned as 
Federal records, (g) technical risks 
that need to be addressed in the 
planning effort, (h) tools and 
engineering methods to be 
employed in the technical effort, and 
(i) ap proach to acquiring and 
maintaining the technical expertise 
needed (training and skills 
development plan).       
b). Define the technical work to be 
done to include associated 
technical, support, and management 
tasks needed to generate the 
deliverable pr oducts and satisfy 
entry and success criteria of key 
technical events and the applicable 
product -line life -cycle management 
phase.       
c). Schedule, organize, and 
determine the cost of the technical 
effort.       
d). Prepare the SEMP and other 
techni cal plans needed to support 
the technical effort and perform the 
technical processes.       
e). Obtain stakeholder commitments 
to the technical plans.       
f). Issue authorized technical work 
directives to implement the technical 
work.       
g). Cap ture work products from 
technical planning activities.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-13 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
11 Require -
ments 
Manage -
ment 
Process  a). Prepare to conduct requirements 
management to include: (1) 
preparing or updating a strategy and 
procedures for: (a) establishing that 
expectation and req uirement 
statements, singularly and as a 
whole, are prepared in accordance 
with established formats and rules; 
(b) identifying expectations and 
requirements to be managed, 
expectation and requirement 
sources, and allocation and 
traceability of requirements  and 
linking product expectations and 
requirements with costs, weight, and 
power allocations, as applicable; 
and (c) formal initiation, assessment, 
review, approval, and disposition of 
engineering change proposals and 
changes to expectation and 
requirement s baseline; (2) selecting 
or updating an appropriate 
requirements management tool; and 
(3) training technical team members 
in the established requirements 
management procedures and in the 
use of the selected/updated 
requirements management tool.       
b). Conduct requirements 
management to include: (1) 
capturing, storing, and documenting 
the expectations and requirements; 
(2) establishing that expectation and 
requirement statements are 
compliant with format and other 
established rules; (3) confirming 
each  established requirements 
baseline has been validated; and (4) 
identifying and analyzing out -of-
tolerance system -critical technical 
parameters and unacceptable 
validation and verification results 
and proposing requirement -
appropriate changes to correct out -
of-tolerance requirements.       
c). Conduct expectation and 
requirements traceability to include: 
(1) tracking expectations and 
requirements between baselines, 
especially MOEs, MOPs, and TPMs 
and (2) establishing and maintaining 
appropriate requirement s 
compliance matrixes that contain the 
requirements, bidirectional 
traceability, compliance status, and 
any actions to complete compliance.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-14 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
d). Manage expectation and 
requirement changes to include: (1) 
reviewing engineering change 
proposals (ECPs ) to determine any 
changes to established requirement 
baselines; (2) implementing formal 
change procedures for proposed 
and identified expectation or 
requirement changes; and (3) 
disseminating the approved change 
information.       
e). Capture work produ cts from 
requirements management process 
activities to include maintaining and 
reporting information on the 
rationale for and disposition and 
implementation of change actions, 
current requirement compliance 
status, and expectation and 
requirement baselines .      
 
12 Interface 
Manage -
ment 
Process  
 a). Prepare or update interface 
management procedures for: (1) 
establishing interface management 
responsibilities for those interfaces 
that are part of agreement 
boundaries; (2) maintaining and 
controlling identif ied internal and 
external physical and functional 
interfaces; (3) preparing and 
maintaining appropriate physical and 
functional interface specifications or 
interface control documents and 
drawings to describe and control 
interfaces external to the system 
end product; (4) identifying 
interfaces between system products 
(including humans) and among 
configuration management items; (5) 
establishing and implementing 
formal change procedures for 
interface evolution; (6) disseminating 
the needed interface informati on for 
integration into technical effort 
activities and for external interface 
control; and (7) training technical 
teams and other applicable support 
and management personnel in the 
established interface management 
procedures.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-15 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
b). Conduct interfa ce management 
during system design activities for 
each WBS model in the system 
structure to include: (1) integrating 
the interface management activities 
with requirements management 
activities; (2) analyzing the concept 
of operations to identify critical 
interfaces not included in the 
stakeholder set of expectations; (3) 
documenting interfaces both 
external and internal to each WBS 
model as the development of the 
system structure emerges and 
interfaces are added and existing 
interfaces are changed; (4) 
docu menting origin, destination, 
stimulus, and special characteristics 
of interfaces; (5) maintaining the 
design solution definition for internal 
horizontal and vertical interfaces 
between WBS models in the system 
structure; (6) maintaining horizontal 
traceabi lity of interface requirements 
across interfaces and capturing 
status in the established 
requirements compliance matrix; 
and (7) confirming that each 
interface control document or 
drawing that is established has been 
validated with parties on both sides 
of the interface.       
c). Conduct interface management 
during product integration activities 
to include: (1) reviewing product 
integration procedures to ensure 
that interfaces are marked to ensure 
easy and correct 
assembly/connection with other 
products;  (2) identifying product 
integration planning to identify 
interface discrepancies, if any, and 
report to the proper technical team 
or technical manager; (3) confirming 
that a precheck is completed on all 
physical interfaces before 
connecting products; (4) evaluating 
assembled products for interface 
compatibility; (5) confirming that 
product verification and product 
validation plans/procedures include 
confirming internal and external 
interfaces; and (6) preparing an 
interface evaluation report upon 
completio n of integration, product 
verification, and product validation.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-16 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
d). Conduct interface control to 
include: (1) managing interface 
changes within the system structure; 
(2) identifying and tracking proposed 
and directed changes to interface 
specifica tions and interface control 
documents and drawings; (3) 
confirming that the vertical and 
horizontal interface issues are 
analyzed and resolved when a 
change affects products on both 
sides of the interface; (4) controlling 
traceability of interface changes 
including source of the change, 
processing methods, and approvals; 
and (5) disseminating the approved 
interface change information for 
integration into technical efforts at 
every level of the project.       
e). Capture work products from 
interface manage ment activities.       
 
13 Technical 
Risk 
Manage -
ment 
Process  a). Prepare a strategy to conduct 
technical risk management to 
include: (1) documenting how the 
project risk management plan will be 
implemented in the technical effort; 
(2) planning identificat ion of 
technical risk sources and 
categories; (3) identification of 
potential technical risks; (4) 
characterizing and prioritizing 
technical risks; (5) planning informed 
technical management (mitigation) 
actions should the risk event occur; 
(6) tracking te chnical risk status 
against established triggers; (7) 
resolving technical risk by taking 
planned action if established triggers 
are tripped; and (8) communicating 
technical risk status and mitigation 
actions taken, when appropriate.       
b). Identify te chnical risks to include: 
(1) identifying sources of risk issues 
related to the technical effort; (2) 
anticipate what could go wrong in 
each of the source areas to create 
technical risk issues; (3) analyzing 
identified technical risks for cause 
and importa nce; (4) preparing clear, 
understandable, and standard form 
risk statements; and (5) coordinating 
with relevant stakeholders 
associated with each identified 
technical risk.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-17 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
c). Conduct technical risk 
assessment to include: (1) 
categorize the sever ity of 
consequences for each identified 
technical risk in terms of 
performance, cost, and schedule 
impacts to the technical effort and 
project; (2) analyze the likelihood 
and uncertainties of events 
associated with each technical risk 
and quantify (for exa mple, by 
probabilities) or qualify (for example, 
by high, moderate, or low) the 
probability of occurrence in 
accordance with project risk 
management plan rules; and (3) 
prioritize risks for mitigation.       
d). Prepare for technical risk 
mitigation to i nclude: (1) selecting 
risks for mitigation and monitoring; 
(2) selecting an appropriate risk -
handling approach; (3) establishing 
the risk level or threshold when risk 
occurrence becomes unacceptable 
and triggers execution of a risk 
mitigation action plan; (4) selecting 
contingency actions and triggers 
should risk mitigation not work to 
prevent a problem occurrence; (5) 
preparing risk mitigation and 
contingency action plans identifying 
responsibilities and authorities.       
e). Monitor the status of each 
technical risk periodically to include: 
(1) tracking risk status to determine 
whether conditions or situations 
have changed so that risk 
monitoring is no longer needed or 
new risks have been discovered; (2) 
comparing risk status and risk 
thresholds; (3) re porting risk status 
to decision authorities when a 
threshold has been triggered and an 
action plan implemented; (4) 
preparing technical risk status 
reports as required by the project 
risk management plan; (5) 
communicating risk status during 
technical revi ews in the form 
specified by the project risk 
management plan.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-18 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
f). Implement technical risk 
mitigation and contingency action 
plans when the applicable 
thresholds have been triggered to 
include: (1) monitoring the results of 
the action plan implem ented; (2) 
modifying the action plan as 
appropriate to the results of the 
actions; (3) continuing actions until 
the residual risk and/or 
consequences impacts are 
acceptable or become a problem to 
be solved; (4) communicate to the 
project when risks are bey ond the 
scope of the technical effort to 
control, will affect a product higher in 
the system structure, or represent a 
significant threat to the technical 
effort or project success; (5) 
preparing action plan effectiveness 
reports as required by the project  
risk management plan; (6) 
communicating action plan 
effectiveness during technical 
reviews in the form specified by the 
project risk management plan.       
g). Capture work products from 
technical risk management activities.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-19 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
14 Configura -
tion 
Mana ge-
ment 
Process  
 
 
?  a). Prepare a strategy to conduct 
configuration management for the 
system products and designated 
work products to include: (1) 
documenting how the project 
configuration management plan, if 
any, will be implemented; (2) 
identifying items  to be put under 
configuration control; (3) identifying 
schema of identifiers to accurately 
describe a configuration item and its 
revisions or versions; (4) controlling 
changes to configuration items; (5) 
maintaining and reporting disposition 
and implement ation of change 
actions to appropriate stakeholders 
including technical teams within the 
project; (6) ensuring  that products 
are in compliance with specifications 
and configuration documentation 
during reviews and audits; (7) 
providing the appropriate refe rence 
configuration at the start of each 
product -line life -cycle phase; (8) 
obtaining appropriate tools for 
configuration management; and (9) 
training appropriate technical team 
members and other technical 
support and management personnel 
in the establishe d configuration 
management strategy and any 
configuration management 
procedures and tools.       
b). Identify baselines to be under 
configuration control to include: (1) 
listing of the configuration items to 
control; (2) providing each 
configuration ite m with a unique 
identifier; (3) identifying acceptance 
requirements for each baseline 
identified for control; (4) identifying 
the owner of each configuration 
item; and (5) establishing a baseline 
configuration for each configuration 
item.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-20 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
c). Mana ge configuration change 
control to include: (1) establishing 
change criteria, procedures, and 
responsibilities; (2) receiving, 
recording, and evaluating change 
requests; (3) tracking change 
requests to closure; (4) obtaining 
appropriate approvals before 
implementing a change; (5) 
incorporating approved changes in 
appropriate configuration items; (6) 
releasing changed configuration 
items for use; and (7) monitoring 
implementation to determine 
whether changes resulted in 
unintended effects (e.g., have 
comprom ised safety or security of 
baseline product).       
d). Maintain the status of 
configuration documentation to 
include: (1) maintaining 
configuration item description 
records and records that verify 
readiness of configuration items for 
testing, delivery, or other related 
technical efforts; (2) maintaining 
change requests, disposition action 
taken, and history of change status; 
(3) maintaining differences between 
successive baselines; and (4) 
controlling access to and release of 
configuration baselines.       
e). Conduct configuration audits to 
include: (1) auditing baselines under 
control to confirm that the actual 
work product configuration matches 
the documented configuration, the 
configuration is in conformance with 
product requirements, and records 
of all change actions are complete 
and up to date; (2) identifying risks 
to the technical effort based on 
incorrect documentation, 
implementation, or tracking of 
changes; (3) assessing the integrity 
of the baselines; (4) confirming the 
completeness and corre ctness of 
the content of configuration items 
with applicable requirements; (5) 
confirming compliance of 
configuration items with applicable 
configuration management 
standards and procedures; and (6) 
tracking action items to correct 
anomalies from audit to closure.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-21 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
f). Capture work products from 
configuration management activities 
to include: (1) a list of identified 
configuration items; (2) description 
of configuration items placed under 
control; (3) change requests, 
disposition of the requests, an d 
rationale for the dispositions; (4) 
documented changes with reason 
for changes and change actions; (5) 
archive of old baselines; and (6) 
required reports on configuration 
management outcomes.       
15 Technical 
Data 
Manage -
ment 
Process  
 
 
 
 
?  a). Prepare a  strategy for the 
conduct of technical data 
management to include: (1) 
determining required data content 
and form and electronic data 
exchange interfaces in accordance 
with international standards or 
agreements; (2) establishing a 
framework for technical d ata flow 
within the project technical 
processes and to/from contractors; 
(3) designating technical data 
management responsibilities and 
authorities regarding origination, 
generation, capture, archiving, 
security, privacy, and disposal of 
technical data wor k products; (4) 
establishing the rights, obligations 
and commitments regarding the 
retention of, transmission of, and 
access to technical data items; (5) 
establishing relevant data storage, 
transformation, transmission and 
presentation standards and 
conven tions to be used; (6) 
establishing project or program 
policy and agreements or legislative 
constraints; (7) describing the 
methods, tools, and metrics used 
during the technical effort and for 
technical data management; and (8) 
training appropriate technica l team 
members and support and 
management personnel in the 
established technical data 
management strategy and related 
procedures and tools.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-22 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
b). Collect and store required 
technical data to include: (1) 
identifying existing sources of 
technical dat a that are designated 
as outputs of the common technical 
processes; (2) collecting and storing 
technical data in accordance with 
the technical data management 
strategy and procedures; (3) 
recording and distributing lessons 
learned; (4) performing technical  
data integrity checks on collected 
data to confirm compliance with 
content and format requirements 
and identifying errors in specifying or 
recording data; and (5) prioritizing, 
reviewing, and updating technical 
data collection and storage 
procedures.       
c). Maintain stored technical data to 
include: (1) managing the databases 
to maintain proper quality and 
integrity of the collected and stored 
technical data and to confirm that 
the technical data is secure and is 
available to those with authority to 
have access; (2) performing 
technical data maintenance as 
required; (3) preventing the stored 
data from being used or accessed 
inappropriately; (4) maintaining the 
stored technical data in a manner 
that protects it against foreseeable 
hazards, such as fire,  flood, 
earthquake, and riots; and (5) 
maintaining periodic backups of 
each technical database.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-23 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
d). Provide technical data to 
authorized parties to include: (1) 
maintaining an information library or 
reference index to provide data 
available and ac cess instructions; 
(2) receiving and evaluating 
requests for technical data and 
delivery instructions; (3) confirming 
that required and requested 
technical data is appropriately 
distributed to satisfy the needs of the 
requesting party and in accordance 
with established procedures, 
directives, and agreements; (4) 
confirming that electronic access 
rules are followed before allowing 
access to the database and before 
any data is electronically 
released/transferred to the 
requester; and (5) providing proof of 
correctness, reliability, and security 
of technical data provided to internal 
and external recipients.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-24 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
16 Technical 
Assessmen
t Process  a). Prepare a strategy for conducting 
technical assessments to include: 
(1) identifying the plans against 
which prog ress and achievement of 
the technical effort are to be 
assessed; (2) establishing 
procedures for obtaining cost 
expenditures against work planned 
and task completions against 
schedule; (3) identifying and 
obtaining technical requirements 
against which prod uct development 
progress and achievement will be 
assessed and establishing the 
procedures for conducting the 
assessments; (4) establishing 
events when TPMs, estimation or 
measurement techniques, and rules 
for taking action when out -of-
tolerance conditions exist will be 
assessed; (5) identifying and 
planning for phase -to-phase 
technical reviews and WBS model -
to-model vertical progress reviews, 
as well as establishing review entry 
and success criteria, review board 
members, and close out procedures; 
(6) estab lishing which technical 
effort work products will undergo 
peer review, the team members who 
will perform the peer reviews, and 
reporting requirements; and (7) 
training team members, support 
staff, and managers involved in 
conducting technical assessment 
activities.       
b). Assess technical work 
productivity (progress and 
achievement against plans) to 
include: (1) identifying, collecting, 
and analyzing process measures 
(e.g., earned value measurements 
for measuring progress against 
planned cost, schedule , resource 
use, and technical effort tasks) and 
identifying and reporting cost -
effective changes to correct 
variances; (2) monitoring 
stakeholder involvement according 
to the SEMP; and (3) monitoring 
technical data management against 
plans.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-25 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
c). As sess product quality (progress 
and achievements against technical 
requirements) to include: (1) 
identifying, collecting, and analyzing 
the degree of technical requirement 
and TPM satisfaction; (2) assessing 
the maturity of the WBS -model 
products and servic es as applicable 
to the product -line life -cycle phases; 
(3) determining any variances from 
expected values of product 
performance and identifying and 
defining cost -effective changes to 
correct variances.       
d). Conduct technical reviews to 
include: (1 ) identifying the type of 
technical reviews and each review’s 
purpose and objectives (see 
Chapter 5 for specific technical 
reviews that apply); (2) determining 
progress toward satisfying entry 
criteria; (3) establishing the makeup 
of the review team; (4) p reparing the 
review presentation materials; and 
(5) identifying and resolving action 
items resulting from the review.       
e). Capture work products from the 
conduct of technical assessment 
activities to include: (1) identifying 
variances resulting from  technical 
assessments; (2) identifying and 
reporting changes to correct 
variances; (3) recording methods 
used in doing assessment activities; 
(4) documenting assumptions made 
in arriving at the process and 
product measure outcomes; and (5) 
reporting corre ctive action 
recommendations.       
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-26 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
 
17 
 
 
 
 Decision 
Analysis 
Process  a). Establish guidelines to determine 
which technical issues are subject to 
a formal analysis/evaluation process 
to include: (1) when to use a formal 
decision making  procedure, for 
examp le, as a result of an 
effectiveness assessment, a 
technical tradeoff, a problem 
needing to be solved, action needed 
as a response to risk exceeding the 
acceptable threshold, verification or 
validation failure, make -buy choice, 
evaluating a solution alterna tive, or 
resolving a requirements conflict; (2) 
what needs to be documented; (3) 
who will be the decision makers and 
their responsibilities and decision 
authorities; and (4) how decisions 
will be handled that do not require a 
formal evaluation procedure.       
b). Define the criteria for evaluating 
alternative solutions to include: (1) 
the types of criteria to consider 
include the following: technology 
limitations, environmental impact, 
safety, risks, total ownership and 
life-cycle costs, and schedule 
impact; (2) the acceptable range and 
scale of the criteria; and (3) the rank 
of each criterion by its importance.       
c). Identify alternative solutions to 
address decision issues to include 
alternatives for consideration in 
addition to those that may be 
provided with the issue.       
d). Select evaluation methods and 
tools/techniques based on the 
purpose for analyzing a decision and 
on the availability of the information 
used to support the method and/or 
tool.      
e). Evaluate alternative solutions 
with the established criteria and 
selected methods to include: (1) 
evaluation of assumptions related to 
evaluation criteria and of the 
evidence that supports the 
assumptions; and (2) evaluation of 
whether uncertainty in the values for 
alternative solutions  affects the 
evaluation.       
f). Select recommended solutions 
from the alternatives based on the 
evaluation criteria to include 
documenting the information that 
justifies the recommendations and 
gives the impacts of taking the 
recommended course of act ion.      
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-27 No. NPR 
Process  Expected Process Activities  Center Implementation  
Center 
Document(s)/ 
Section/Task  Fully  
Included  Partially 
Included  Gap Plan  to 
Close 
Gap 
g). Report the analysis/evaluation 
results/findings with 
recommendations, impacts, and 
corrective actions.       
h). Capture work products from 
decision analysis activities to 
include: (1) decision analysis 
guidelines generated and strategy  
and procedures used; (2) 
analysis/evaluation approach, 
criteria, and methods and tools 
used; (3) analysis/evaluation results, 
assumptions made in arriving at 
recommendations, uncertainties and 
sensitivities of the recommended 
actions or corrective actions ; and (4) 
lessons learned and 
recommendations for improving 
future decision analyses.       
 
SE NPR Center Survey  
 
This Document Is Unc ontrolled When Printed.  H2-28  
 
 
3.3 PLAN TO CLOSE GAPS  
 
This section would include textual descriptions about how the gaps noted in the matrix will be 
closed . 
 
 
4.0 LESSONS LEARNED  
 
This section woul d include any lessons learned during the Center survey that was valuable to the 
Center and which might also be useful information for other Centers.  
 
 
5.0 CENTER BEST PRACTICES  
 
This section would include descriptions of what the Center considers its best prac tices and which 
practices might be used to update  or improve the processes in the SE NPR.  
 
6.0 OTHER  
 
Any other information that the Center would like to document or pass on.  
 
 
This Document Is Uncontrolled When  Printed.  159 Appendix I. References  
The following documents were used as reference materials in the development of this SE NPR . 
The documents are offered as informational sources and are not evoked in this SE NPR , though 
they may be referenced . 
1. MIL-STD -499B (draft) , Systems  Engineering .  
2. ISO/IEC 15288 , System  Life Cycle  Processes . 
ISO/IEC 15288 defines international system life processes  plus for any domain (e.g., 
transportation, medical, commercial).  
3. ANSI/EIA 632 , Processes  for Engineering a System . 
EIA 632 is a commercial document that evolved from the never released, but fully developed , 
1994 Mil -Std 499B Systems  Engineering . It was intended to provide a framework  for developing 
and supporting universal SE  discipline for both defense and commercial environments . EIA 632 
was intended to be a top-tier standard further defined  to lower level standards that define specific 
practices .  
IEEE 1220  is a second -tier standard that implements EIA 632 by defining one way to practic e 
systems engineering .  
4. CMMI model . 
The Capability  Maturity Model® (CMM) IntegrationSM (CMMI) in its present form is a 
collection of best practices  for the ―development  and maintenance ‖ of both ―products  and 
services.‖ The model  was developed by integrating practices from four different CMMs , the 
―source models‖ –the CMM for software , for systems  engineering , for integrated  product 
development (IPD), and for acquisition. Organizations can use the model to improve  their ability 
to develop (or maintain ) products (and services) on time, within budget, and with desired quality. 
CMMI  also provides these organizations the framework  for enlarging the focus of process 
improvement to other areas that also affect product developm ent, i.e., the discipline of systems 
engineering . During the past decade, new and effective concepts for organizing  developmental 
work  have surfaced and been adopted , such as concurrent engineering or t he use of integrated 
teams . Organizations using (or wishing to adopt these ideas) can also find support in the CMMI 
by using the model with integrated product and process development (IPPD) additions.  
5. Defense Acquisition University Systems  Engineering  Fundamentals. Ft. Belvoir, Virginia: 
Defense Acquisition University Press, December 2000 . 
6. International Council on Systems  Engineering  Systems Engineering Guide . 
7. ISO/IEC TR 19760 , Systems Engineering —A Guide for the Application of ISO/IEC 15288 
(System  Life Cycle  Processes ). 
8. AS9100 : Quality Management Syste ms—Aerospace —Requirements . G-14 Americas 
Aerospace Quality Group.  
 
 
This Document Is Uncontrolled When  Printed.  160 Appendix  J. Index  
Action Plans, 79  
Activities, 1, 4, 5, 7, 8, 10, 12, 14, 15, 16, 
17, 18, 19, 20, 22, 28, 32, 33, 34, 35, 37 , 
38, 39, 40, 43, 44, 45, 47, 48, 50, 51, 52, 
53, 54, 57, 58, 59, 60, 62, 63, 65, 66, 67, 
68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 
79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 
93, 94, 95, 99, 102, 111, 112  
Advanced Technology Development, 1, 24, 
28, 29, 30, 34, 36, 41, 95, 104, 105, 113  
Agency, 4, 5, 7, 8, 9, 10, 28, 34, 43, 100, 
112 
Agreement, 9, 12, 18, 31, 37, 40, 45, 64, 67, 
68, 75, 77, 91, 94, 100  
Agreement Boundaries, 75  
Allocation, 92, 96  
Alternative Solutions, 16, 51, 53, 89  
Analysis, 13, 22, 40, 47, 53, 64, 69, 86, 88, 
89, 95, 102, 103, 104, 105, 106, 110, 112, 
113 
Analysis Process, 20, 21, 53, 63, 65, 77, 85, 
86, 88, 89, 90  
Analysis, Functional, 99  
Announcement of Opportunity, 24, 41  
AO, 24, 41  
Applicability, 1, 4, 5, 7, 18, 19, 24, 32, 34, 
37, 3 8, 39, 43, 53, 54, 70, 75, 98, 113, 114  
Applicability of NPR, 1, 2, 29, 37, 39, 93  
Application, 1, 4, 5, 7, 18, 19, 24, 32, 34, 37, 
38, 39, 43, 53, 54, 70, 75, 98, 113, 114  
Applied Research. See BAR, 34, 45, 113  
Approach, 1, 4, 5, 15, 22, 29, 32, 38, 39, 7 1, 
75, 79, 89, 91, 94, 95, 98, 100, 102, 104, 
106, 111, 114  
Approval, 10, 15, 24, 74, 76, 82, 87, 91, 96, 
98, 100, 105, 106, 107, 108, 112  
Architecture, 10, 11, 37, 99, 103, 104, 105  
Assessment, 3, 6, 7, 11, 20, 22, 28, 29, 30, 
42, 69, 70, 73, 83, 86, 87, 89, 104, 105, 
109, 110, 111, 112  
Assessment, Risk, 28, 77, 78, 79, 91, 100, 
102, 103, 104, 105, 106, 109  ATD, 1, 24, 28, 30, 34, 41, 113  
Audits, 81, 82, 99, 110  
Authority, 2, 5, 8, 9, 10, 11, 12, 15, 22, 32, 
34, 36, 41, 44, 84, 92, 94, 95, 98, 110  
Autonomy , 4 
BAR, 1, 24, 28, 34, 41, 113  
Baseline, 15, 16, 18, 19, 28, 32, 34, 35, 36, 
37, 40, 44, 45, 46, 47, 48, 49, 51, 52, 53, 
54, 61, 62, 63, 64, 65, 70, 72, 73, 74, 75, 
80, 81, 82, 93, 98, 99, 100, 102, 104, 105, 
106, 112  
Baselines, 15, 16, 18, 19, 35, 44, 45 , 46, 48, 
52, 64, 72, 75, 104, 105, 106  
Baselines, Archive, 82  
Basic and Applied Research, 1, 24, 28, 34, 
41, 45, 113  
Cancellation, 3  
Capability, 1, 4, 6, 7, 15, 34, 35, 36, 38, 39, 
41, 43, 44, 47, 68, 70, 71, 78, 87, 110, 
112, 159  
Capability, Decision -Making, 4, 8, 43  
CDR, 29, 30, 41, 100, 106, 113, 114  
Center Directors, 3, 9, 10, 11, 15, 16, 17, 18, 
19, 20, 96  
Center Survey, 10, i  
Center System Engineering Working Group, 
10, 42  
Center. See NASA Centers, 3, 7, 9, 10, 11, 
15, 16, 17, 18, 19, 20, 22, 28, 32,  34, 43, 
96 
CERR , 29, 30, 41, 111  
Chapters, 1, 7, 8, 13, 18, 22, 24, 35, 36, 70, 
71, 87, 94, 100  
CoF, 1, 41  
Common Technical Processes, 43  
Compatibility, 9, 15, 41, 44, 76  
Complexity, 4, 12, 32, 39, 98, 99, 104  
Compliance, 2, 3, 9, 11, 19, 39, 40, 41, 62, 
64, 65, 74, 75, 76, 81, 82, 84, 98, 100, 109  
Configuration, 20, 45, 48, 51, 52, 53, 54, 56, 
57, 58, 59, 60, 61, 62, 63, 75, 76, 80, 81, 
82, 95, 99, 105, 106, 107, 108  
 
This Document Is Uncontrolled When  Printed.  161 Conflict, 5, 9, 38, 40, 45, 48, 50, 89  
Constraints, 4, 5, 13, 15, 35, 39, 44, 45, 47, 
54, 57, 62, 65, 70, 84, 93, 98, 100, 102, 
104, 106, 110, 111, 112  
Construction of Facilities, 1, 41  
Contract, 8, 20, 22, 32, 34, 37, 76, 82, 83, 
91, 92, 94, 98, 115  
Contract Award, 22  
Contract Performance, 22  
Contract, and Contractors, 1, 8, 19, 22, 34, 
38, 7 5, 80, 83, 84, 94  
Contractor Integration, 94  
Contractors, 1, 8, 19, 22, 34, 38, 75, 80, 83, 
84, 94  
Controls, 10, 20, 22, 31, 36, 41, 45, 47, 48, 
50, 51, 54, 69, 75, 76, 79, 80, 81, 82, 99, 
100, 102, 105, 106, 107, 108, 112  
Costs, 1, 4, 5, 7, 12, 13, 21, 32 , 37, 38, 39, 
47, 48, 50, 53, 65, 68, 70, 71, 73, 78, 82, 
85, 86, 87, 88, 89, 91, 94, 96, 98, 99, 100, 
102, 103, 104, 105, 106, 107  
Costs, Reduction of, 1, 4  
Criteria, 13, 15, 30, 35, 38, 39, 44, 48, 50, 
53, 54, 62, 63, 65, 82, 87, 89, 95, 98, 100, 
102, 10 6, 109, 110, 113  
Criteria, Entrance, 28, 100, 102, 103, 104, 
105, 106, 107, 108, 109, 110, 111, 112  
Criteria, Exit, 8, 13, 15, 16, 17, 18, 19, 35, 
37, 48, 51, 53, 54, 55, 56, 57, 58, 59, 66, 
70, 71, 77, 82, 92, 93, 94  
Criteria, SE Engine, 13, 38  
Criteria, Success, 29, 30, 32, 38, 39, 71, 86, 
100, 102, 103, 104, 105, 106, 107, 108, 
109, 110, 111, 112, 113  
Critical Design Review, 29, 30, 41, 100, 
106, 113, 114  
Critical Event Readiness Review , 29, 30, 41, 
111 
Customer, 18, 23, 34, 37, 39, 40, 44, 45, 46, 
58, 6 4, 66, 67, 68, 82, 93  
Data Management Process, 20, 44, 47, 49, 
53, 57, 59, 61, 62, 64, 65, 67, 70, 73, 75, 
78, 81, 83, 85, 86, 88  
Decisionmaking, 13, 21, 69, 88, 89  
Decommissioning Review, 29, 30, 41, 112  Definition Process, 15, 16, 17, 18, 43, 45, 
46, 48,  49, 50, 51, 52, 53, 54, 61, 64  
Definitions, 1, 2, 5, 6, 9, 10, 11, 12, 14, 15, 
16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 
30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 
43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 
54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 67, 
68, 69, 70, 71, 72, 73, 75, 76, 78, 81, 93, 
94, 98, 99, 100, 102, 103, 104, 105, 107, 
108, 112, 113, 159  
Design, 1, 13, 14, 16, 17, 19, 20, 21, 22, 28, 
34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 
48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 
61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 75, 
76, 77, 81, 85, 86, 88, 94, 99, 100, 103, 
104, 105, 106, 107, 108, 111, 114  
Design of Facilities, 1  
Design Solution, 16, 17, 28, 36, 43, 44, 45, 
46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 
61, 62, 63, 64, 67, 68, 71, 76, 81, 94  
Design, Preliminary, 24, 29, 42, 81, 104, 
105 
Designated Governing Authority, 2, 5, 11, 
12, 15, 32, 41, 94, 98, 110  
Development, 4, 5, 6, 9, 13, 19, 22, 33, 34, 
35, 38, 40, 44, 45, 50, 52, 54, 67, 71, 75, 
76, 86, 87, 93, 98, 99, 100, 104, 106, 107, 
110, 11 3, 114, 159  
Development, Advanced Technology, 1, 34, 
36 
Development, Modeling, 15  
Development, Simulation, 15, 53, 64  
DGA, 5, 11, 12, 15, 32, 41, 94, 98, 110  
Diagrams, 48, 51, 54, 58, 60, 63, 66, 69, 72, 
74, 77, 79, 82, 85, 87, 89  
Disposal, 4, 5, 14, 23, 2 4, 35, 40, 45, 54, 57, 
84, 105, 106, 112  
Document, NASA Procedural, 2, 4, 5, 9, 10, 
38, 41  
Documents, i, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 
18, 19, 29, 30, 32, 34, 38, 39, 41, 43, 52, 
53, 57, 59, 61, 62, 63, 65, 67, 70, 73, 75, 
76, 78, 80, 91, 92, 96, 97, 99,  100, 102, 
103, 104, 105, 106, 108, 109, 116  
Documents, Manuals, 2, 5, 6, 7, 9, 10, 29, 
57, 59, 66, 67, 68, 109  
 
This Document Is Uncontrolled When  Printed.  162 Documents, Other Referenced, i, 1, 2, 3, 4, 
5, 6, 7, 9, 10, 11, 19, 20, 24, 28, 29, 32, 
33, 34, 35, 38, 41, 43, 55, 62, 64, 65, 69, 
70, 75, 78, 80, 81, 84, 91, 92, 93, 96, 97, 
99, 106, 109, 159  
DR, 29, 30, 41, 112  
ECP, 41  
ECR, 1, 41  
Enabling Product, 14, 15, 16, 19, 20, 35, 37, 
38, 40, 43, 44, 46, 47, 52, 53, 54, 56, 57, 
59, 60, 62, 64, 65, 67, 68, 75, 76, 80, 81, 
93, 107, 108, 109  
End Product, 14 , 15, 16, 17, 18, 19, 20, 30, 
35, 37, 38, 40, 43, 44, 46, 52, 53, 54, 55, 
56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 
75, 76, 80, 81, 93, 107, 109  
Engineering, 1, 2, 4, 5, 6, 7, 8, 10, 13, 15, 
21, 32, 36, 38, 39, 67, 71, 73, 74, 82, 88, 
89, 92, 95, 96, 106 , 107, 113, 114, 159  
Engineering Peer Reviews, 41, 54, 86, 87, 
114, 115  
Engineering, Systems, i, 1, 2, 3, 4, 5, 6, 7, 9, 
10, 11, 22, 24, 29, 32, 38, 39, 41, 42, 91, 
99, 115, 159  
Environment, 4, 5, 18, 32, 39, 45, 47, 59, 60, 
62, 63, 64, 65, 67, 68, 76, 95,  100, 105, 
107, 108, 109, 113, 114, 159  
Environmental Compliance and Restoration, 
1, 41  
EPR, 41  
Evaluation, 21, 22, 28, 37, 39, 54, 57, 68, 
73, 76, 82, 88, 89, 91, 100, 102, 110, 112, 
114 
Examination, 19, 24, 77, 87, 102, 103, 104, 
109, 110  
Expectations, 1 3, 15, 16, 18, 24, 35, 36, 40, 
43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 
59, 62, 64, 65, 67, 68, 73, 74, 76, 80, 86, 
107, 108, 109  
Facilities, 1, 29, 38, 60, 65, 67, 68, 70, 91, 
100, 107, 108, 109, 110, 112  
Facilities Design, 1  
Facilities, Component, 1  
Facilities, Construction of, 1, 41  
Federal Records, 29, 69, 71  Figures, iii, 6, 7, 10, 11, 13, 14, 15, 24, 27, 
30, 31, 38, 40, 43, 45, 46, 48, 49, 51, 54, 
55, 56, 58, 60, 61, 63, 66, 69, 72, 74, 77, 
79, 80, 82, 83, 85, 87, 88, 89, 90  
Flight Readiness Review , 29, 30, 41, 110  
Flight Systems, 1, 24, 28, 29, 30, 34, 35, 41, 
45, 81, 107, 113  
Formulation, 2, 7, 24, 33, 35, 41, 99, 100, 
113 
Framework, 4, 6, 8, 84, 159  
FRR , 29, 30, 41, 110  
FS&GS, 1, 24, 28, 29, 30, 34, 35, 41, 45, 
107, 113  
Goals, 1, 4, 5, 28, 37, 39 , 40, 98, 100, 102, 
105 
Ground Support, 1, 24, 28, 29, 30, 34, 35, 
41, 45, 81, 107, 113  
Guidelines, 4, 15, 16, 17, 18, 19, 20, 89, 91, 
98 
Historical Record, 28  
Identification, 15, 19, 20, 36, 43, 73, 75, 76, 
78, 81, 82, 83, 84, 86, 87, 95  
Implementation, 1 , 2, 3, 4, 6, 7, 8, 9, 10, 11, 
12, 13, 15, 16, 17, 18, 24, 31, 32, 35, 37, 
40, 43, 45, 48, 50, 52, 53, 54, 55, 56, 57, 
58, 61, 64, 66, 67, 69, 70, 71, 74, 79, 81, 
82, 92, 93, 94, 96, 100, 111, 116  
Improvements, 7, 28, 99, 114  
Information Systems, 1, 29, 35 , 94 
Inputs, 16, 22, 24, 37, 43, 44, 45, 46, 48, 49, 
51, 52, 54, 56, 58, 59, 60, 61, 63, 64, 66, 
67, 69, 70, 72, 73, 74, 75, 77, 79, 80, 82, 
83, 85, 87, 88, 89, 94  
Institutional Project, 1, 24, 28, 29, 35, 41, 
113 
Integration, 1, 2, 4, 5, 6, 7, 16, 17, 18,  29, 
30, 33, 35, 37, 38, 39, 40, 42, 45, 48, 50, 
52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 66, 
67, 68, 75, 76, 91, 93, 94, 96, 105, 106, 
107, 113, 114, 159  
Integration, Contractor, 94  
Integration, Planning, 17, 58, 61, 67, 93  
Integration, Support, 94  
Interop erate, 19, 75  
IP, 1, 24, 28, 29, 41, 113  
KDP, 24, 28, 29, 30, 34, 36, 41, 108  
 
This Document Is Uncontrolled When  Printed.  163 Key Decision Point, 24, 28, 29, 30, 34, 36, 
41, 108  
Key Performance Parameters, 34, 36, 39, 41  
KPP, 34, 36, 41  
Liens, 31, 109, 110  
Life Cycle, 1, 2, 4, 5, 7, 8, 13, 14, 15, 16, 1 7, 
18, 19, 20, 24, 26, 28, 29, 32, 34, 35, 36, 
37, 38, 39, 43, 44, 47, 48, 51, 52, 53, 54, 
55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 
67, 68, 70, 71, 72, 77, 80, 81, 82, 86, 89, 
92, 93, 94, 98, 99, 100, 102, 112, 159  
Logical Decomposition, 16, 36, 43, 47,  49, 
50, 51, 52, 53, 81  
Logistics, 2, 53, 78, 95, 100, 102, 103, 104, 
105, 106  
Maintenance, 4, 5, 9, 15, 24, 34, 35, 38, 57, 
59, 68, 84, 96, 102, 103, 159  
Management, 1, 2, 4, 5, 8, 9, 10, 15, 20, 32, 
33, 36, 42, 60, 76, 78, 79, 80, 81, 83, 84, 
96, 100, 10 2, 103, 104, 105  
Project, 2  
Management, Requirements, 19, 48, 51, 54, 
72, 73, 74, 75, 76  
Matrix, 62, 65, 76, iv, 2 
MCR, 29, 30, 41, 102  
MDR, 30, 41, 103  
Measure of Effectiveness, 17, 34, 36, 41, 44, 
45, 47, 48, 61, 98  
Measurement, 3, 48, 62, 65, 71, 86  
Methods, 6, 7, 15, 48, 62, 65, 71, 76, 84, 87, 
89, 94, 95, 96, 104, 107  
Metrics, 4, 32, 39, 84  
Milestone, 23, 28, 32, 37, 93, 100, 109  
Mission, 1, 4, 5, 6, 9, 10, 14, 22, 30, 35, 36, 
37, 38, 39, 44, 48, 55, 56, 57, 59, 67, 68, 
98, 100, 102, 103, 104, 105, 106 , 110, 
111, 112, 114  
Mission Concept Review, 29, 30, 41, 102  
Mission Definition Review, 30, 41, 103  
Model, 4, 5, 6, 7, 13, 14, 15, 16, 17, 18, 19, 
35, 37, 38, 43, 44, 45, 46, 47, 50, 51, 52, 
53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 
67, 68, 70, 72, 73, 7 5, 76, 78, 81, 84, 86, 
89, 93, 114, 159  
MOE, 17, 34, 36, 41, 45, 47, 48, 61  NASA Centers, 1, 3, 7, 9, 10, 11, 15, 16, 17, 
18, 19, 20, 22, 28, 32, 34, 43, 96  
NASA Directives, 2, 4, 5, 6, 7, 9, 10, 29, 38, 
41, 43, 70, 71, 84, 109  
NASA Headquarters, 1  
NASA In vestment Areas, 24  
NASA Policy Directive, 2  
NASA Procedural Document, 2, 4, 5, 9, 10, 
38, 41  
NASA Procedural Requirement, i, 1, 2, 3, 4, 
5, 6, 7, 9, 10, 11, 19, 20, 24, 28, 29, 32, 
33, 34, 35, 38, 41, 43, 55, 69, 78, 80, 91, 
93, 96  
NASA Procedural Requirem ent. See NPR, 
1, 41, 42  
NODIS, i, 3, 41  
NPD, 2, 4, 5, 9, 10, 38, 41  
NPR, i, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 19, 20, 
24, 28, 29, 32, 33, 34, 35, 38, 41, 43, 55, 
69, 78, 80, 91, 93, 96, 116  
NPR, Purpose of, 1, 8, 10, 32, 37, 38, 40, 
43, 87, 89, 91, 92, 93, 9 8, 114  
Office of the Chief Engineer, i, 3, 6, 7, 9, 10, 
11, 41, 43  
Operational Readiness Review, 29, 30, 41, 
109, 110  
Operations, 4, 7, 14, 15, 24, 29, 34, 35, 39, 
40, 45, 47, 53, 54, 57, 66, 67, 68, 76, 81, 
100, 102, 103, 104, 106, 109, 110, 111, 
112, 114  
Organization, 1, 2, 5, 6, 8, 9, 10, 11, 34, 58, 
59, 71, 94, 98, 107, 110, 159  
ORR , 29, 30, 41, 109, 110  
Outputs, 7, 16, 37, 43, 44, 45, 47, 48, 49, 51, 
52, 53, 54, 56, 58, 59, 60, 62, 63, 64, 66, 
67, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 
81, 82, 84, 85,  86, 87, 88, 89, 99  
Oversight, 8, 10, 11, 22, 31, 34, 38  
P/SDR , 100  
P/SRR, 29, 42, 100  
PAR , 29, 42  
Parameters, 39, 45, 73  
Parameters, Key Performance, 36, 39  
Partnership, 1, 37  
PFAR , 29, 30, 42, 111, 112  
 
This Document Is Uncontrolled When  Printed.  164 Phases, 2, 7, 13, 15, 16, 17, 18, 19, 24, 29, 
32, 33 , 34, 35, 36, 37, 39, 48, 51, 53, 54, 
55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 
67, 68, 70, 71, 77, 81, 82, 86, 93, 94, 98, 
99, 100, 102, 104, 106, 113  
Plan, 3, 7, 10, 11, 18, 19, 24, 29, 31, 32, 33, 
37, 38, 42, 52, 53, 61, 62, 64, 65, 70, 71, 
77, 79, 91 , 92, 94, 96, 100, 102, 103, 104, 
105, 106, 107, 108, 109, 111, 112, 116  
Planning Context, 93  
PLAR , 29, 30, 42, 110  
Portfolio, 42  
Post-Flight Assessment Review , 29, 30, 42, 
111, 112  
Post-Launch Assessment Review , 29, 30, 
42, 110  
Practices, 4, 5, 10, 15, 16 , 17, 18, 19, 20, 21, 
28, 39, 43, 100, 159  
Precedence, 5  
Preface, 1, 8  
Preliminary Design, 24, 29, 42, 81, 104, 105  
Preparation, 35, 57, 66, 68, 69, 92, 107, 111  
Process, i, 1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 
15, 19, 20, 21, 22, 24, 32, 36, 37, 38, 39, 
43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 
55, 56, 63, 64, 65, 67, 68, 69, 70, 71, 73, 
75, 77, 78, 80, 81, 83, 84, 85, 86, 88, 92, 
93, 94, 98, 107, 112, 113, 159  
Process Flow Diagram, 45, 48, 51, 54, 58, 
60, 63, 66, 69, 72, 74, 77, 79, 82, 85, 87, 
89 
Proce ss(es)  
Common Technical, 43  
Process, Common Technical, 1, 4, 5, 7, 8, 
13, 14, 15, 22, 24, 32, 38, 39, 43, 67, 71, 
77, 78, 81, 83, 84, 92, 93, 94  
Process, Data Management, 20, 83, 85  
Process, Decision Analysis, 20, 21, 53, 63, 
65, 77, 85, 86, 88, 89, 90  
Process, Decisionmaking, 13, 21, 69, 88, 89  
Process, Establish, 1, 4, 7, 15, 16, 17, 18, 19, 
20, 22, 33, 35, 45, 67, 75, 80, 84, 113, 159  
Process, Integration, 16, 17, 18, 45, 48, 50, 
52, 54, 58, 59, 60  
Process, Transition, 18, 34, 37, 39, 40, 64, 
66, 67, 68,  109 Product Integration, 17, 58, 61, 67, 93  
Product Quality, 86  
Product Transition Process, 18, 56, 59, 62, 
64, 66, 67, 68, 69  
Product, End, 14, 15, 16, 17, 18, 19, 20, 30, 
35, 37, 38, 40, 43, 44, 46, 52, 53, 54, 55, 
56, 58, 60, 61, 62, 63, 64, 65, 66, 67 , 68, 
75, 76, 80, 81, 93, 107, 109  
Product, Transition, 18, 22, 23, 55, 56, 58, 
59, 62, 64, 66, 67, 68, 69  
Production Readiness Review, 30, 42, 107  
Products, 1, 4, 5, 6, 7, 8, 11, 13, 14, 15, 16, 
17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 32, 
34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 
47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 
58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 
69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 
80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 
92, 93, 94, 95, 99, 100, 102, 103, 104, 
105, 106, 10 7, 109, 110, 114, 159  
Products, Enabling, 14, 15, 16, 19, 20, 35, 
37, 38, 40, 43, 44, 46, 52, 53, 54, 56, 57, 
59, 60, 62, 64, 65, 67, 68, 75, 76, 80, 81, 
93, 107, 108, 109  
Program Approval Review , 29, 42  
Program Management Plan, 5, 42  
Program/System Defini tion Review , 100  
Program/System Requirements Review, 29, 
42, 100  
Programs, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 19, 
22, 24, 28, 29, 31, 32, 34, 36, 37, 38, 39, 
40, 42, 44, 69, 75, 76, 84, 91, 98, 100, 
102, 105, 107, 108, 113  
Project Manager. See also Projects.  See also 
Management, 5, 32, 42, 110  
Project, Institutional, 1, 24, 28, 29, 35, 41, 
113 
Projects, 1, 2, 4, 5, 7, 9, 10, 11, 12, 13, 15, 
18, 19, 22, 24, 28, 29, 30, 31, 32, 33, 34, 
35, 36, 37, 38, 39, 40, 42, 44, 47, 48, 57, 
59, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 
81, 83, 84, 85, 86, 87, 91, 92, 93, 94, 95, 
96, 98, 99, 100, 102, 103, 104, 105, 106, 
107, 110, 111, 112, 113, 114, 115  
Projects, Complexity of, 4, 12, 32, 39, 98, 
99, 104  
 
This Document Is Uncontrolled When  Printed.  165 Projects, Development of, 4  
Projects, Management of, 1, 2, 4, 5, 8, 9, 1 0, 
11, 12, 32, 69, 70, 96, 102, 103, 104, 105, 
106 
PRR, 30, 42, 107  
PTR. See Reviews, Technical, 30, 31, 42, 
113 
Purpose, 1, 8, 10, 32, 37, 38, 40, 43, 87, 89, 
91, 92, 93, 98, 114  
Readiness, 22, 28, 29, 30, 35, 36, 41, 42, 57, 
59, 62, 65, 66, 67, 68, 69, 8 2, 92, 100, 
105, 107, 108, 109, 110, 111, 112, 113  
Regulations, 15, 44, 46, 107, 112  
Repeatable , 4, 5, 36, 37, 38, 54  
Request for Actions, 31, 42, 102, 103, 104, 
105, 106  
Request for Proposal, 22, 42, 92  
Requirements, i, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 24, 
28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 
41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 
52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 
63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 
75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 
89, 91, 93, 94, 95, 96, 98, 100, 102, 103, 
104, 105, 106, 107, 111, 112, 113, 159  
Research, Applied, 24, 34, 41, 45, 113  
Resolution, 5, 9, 31, 43, 47, 50, 78, 87, 89, 
95, 105, 111  
Resource, 70, 71, 78, 86, 92, 94, 96, 104, 
105, 106  
Responsibilities, 1,  8, 9, 15, 32, 36, 75, 79, 
82, 84, 89, 93, 94, 96, 108  
Results, 24, 29, 31, 34, 53, 62, 63, 64, 65, 
66, 70, 73, 79, 86, 89, 95, 107, 108, 109, 
110, 114  
Review, 28, 86  
Review Item Discrepancies, 31, 42, 102  
Review, and Monitor, 20, 28, 79, 85  
Review, Techni cal, 8, 11, 24, 28, 29, 30, 38, 
69, 79, 85, 86, 87, 93, 98, 100, 114  
Reviews, 1, 4, 5, 6, 10, 11, 23, 24, 28, 29, 
30, 31, 32, 37, 38, 41, 45, 57, 71, 73, 81, 
82, 86, 87, 89, 98, 100, 102, 103, 104, 
105, 106, 107, 108, 109, 110, 111, 113, 
114, 115  Reviews, Formal, 28  
Reviews, Independent, 28  
Reviews, Management, 29  
Reviews, Safety, 28  
Reviews, System Acceptance, 29, 30, 31, 
42, 109, 113  
Reviews, Systems, 29, 42, 100, 102  
Reviews, Technical, 11, 24, 28, 29, 30, 42, 
69, 79, 85, 86, 87, 93, 98, 100, 114  
RFA, 31 , 42 
RFP, 22, 42, 92  
RID, 31, 42  
Risks, 19, 24, 28, 50, 69, 71, 77, 78, 79, 82, 
89, 95, 98, 100, 102, 103, 104, 105, 106, 
107, 109, 112, 115  
Roles, 8, 9, 32, 38, 39, 94, 96, 108  
Safety, 1, 2, 4, 5, 12, 15, 28, 35, 36, 38, 39, 
44, 48, 50, 68, 78, 82, 89, 95 , 100, 102, 
103, 104, 105, 106, 107, 108, 110, 112  
SAR. See Reviews, System Acceptance, 29, 
30, 31, 42, 109, 113  
Satisfaction and Approval, 5, 11, 12, 17, 18, 
20, 34, 36, 37, 39, 41, 42, 45, 50, 53, 61, 
63, 64, 65, 73, 86, 98  
Schedule, 2, 4, 5, 7, 13, 20, 21, 24, 27, 29, 
38, 47, 48, 50, 54, 70, 71, 78, 80, 82, 85, 
86, 88, 89, 91, 94, 96, 98, 100, 102, 103, 
104, 105, 106, 107, 112, 113  
Scope, 1, 8, 9, 33, 34, 47, 79, 92, 98, 99, 113  
Scope of NPR, 1, 92  
SE Engine, 13, 14  
SE NPR. See Systems Engineering, 1, 3,  4, 
7, 8, 9, 10, 11, 12, 13, 15, 40, 42, 43, 69, 
71, 91, 96, 98, 113, 116  
SE. See Systems Engineering, 1, 3, 4, 6, 7, 
8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 42, 
43, 69, 71, 91, 92, 95, 96, 98, 99, 113, 
116, 159  
SEMP, 43  
SEWG, 10, 28, 38, 39, 41, 42, 76  
SIR, 29, 30, 42, 107  
Skills, 15, 39, 43, 68, 71, 78, 87  
Software, 2, 4, 7, 9, 28, 33, 36, 38, 42, 43, 
53, 55, 65, 69, 100, 102, 103, 104, 105, 
106, 108, 109, 110, 112, 159  
Specialty Engineering, 95  
 
This Document Is Uncontrolled When  Printed.  166 Specifications, 16, 17, 38, 40, 52, 53, 54, 56, 
58, 59, 61 , 62, 63, 75, 76, 80, 81, 93, 105, 
106 
SRR, 103, 104  
Stakeholder, 4, 5, 13, 15, 16, 18, 24, 36, 37, 
38, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 
54, 59, 62, 64, 65, 67, 68, 71, 76, 80, 81, 
86, 109  
Statement of Work, 22  
Status, Risk, 28, 77, 78, 79  
Structure s, 1, 7, 13, 14, 15, 16, 17, 18, 19, 
32, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 
48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 
61, 62, 65, 66, 67, 68, 70, 72, 73, 75, 76, 
78, 79, 81, 84, 86, 89, 93, 94, 95, 98  
Success Criteria, 29, 30, 32, 38, 39, 71, 86, 
100, 102, 103, 104, 105, 106, 107, 108, 
113 
Sufficiently Detailed, 99  
Support Integration, 94  
Sustainment, 14, 40, 45, 54, 67, 68  
System, i, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 
14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 28, 
29, 30, 32, 34, 35, 36, 37, 38, 39 , 40, 41, 
42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 
54, 55, 57, 59, 61, 62, 63, 65, 66, 67, 68, 
69, 70, 72, 73, 75, 76, 78, 79, 80, 81, 83, 
84, 85, 86, 88, 89, 91, 93, 95, 98, 99, 100, 
102, 103, 104, 105, 106, 107, 108, 109, 
110, 111, 112, 113, 114, 115,  159 
System  Integration Review , 29, 30, 42, 107  
System Requirements Review, 103, 104  
System Safety, 39  
System Structure, 14, 39, 93  
Systems Approach, 38  
Systems Engineering, i, 1, 2, 3, 4, 5, 6, 7, 9, 
10, 11, 22, 24, 29, 32, 38, 39, 41, 42, 91, 
99, 115, 15 9 
Systems Engineering Management Plan, 1, 
5, 7, 8, 10, 11, 12, 15, 18, 22, 23, 29, 32, 
33, 39, 42, 43, 69, 70, 71, 78, 79, 80, 81, 
85, 86, 91, 92, 93, 94, 96, 99, 100, 102, 
103, 104, 105  
Systems Engineering, Related Disciplines, 2  
Systems, and Structure, 1 3, 14, 15, 16, 17, 
18, 32, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 57, 59, 61, 62, 65, 
66, 67, 68, 70, 73, 75, 76, 78, 79, 81, 84, 
86, 89, 93, 95  
Systems, Information, 1, 29, 35, 94  
Tailor, 4, 5, 12, 39, 91, 94, 98, 99  
Tailoring, 4, 5, 12, 39, 91, 92, 94, 96, 98, 99  
Teams, 1, 4, 5, 7, 8, 9, 10, 15, 19, 22, 23, 28, 
29, 30, 31, 32, 33, 38, 39, 43, 55, 57, 59, 
69, 70, 71, 73, 75, 76, 80, 81, 84, 86, 87, 
91, 92, 93, 94, 102, 103, 104, 105, 106, 
111, 112, 115, 159  
Technical Assessment Process , 20, 47, 62, 
63, 64, 65, 70, 73, 75, 85, 87, 88  
Technical Performance Measures, 34, 39, 
42, 47, 48, 73, 74, 86, 87, 105  
Technology Insertion, 92, 95  
Technology Readiness Level, 34, 39, 42, 
113, 114  
Template, 10, 116  
Templates , 116  
Test, 29, 30, 34, 35, 37 , 39, 40, 42, 45, 48, 
52, 54, 57, 60, 61, 64, 65, 68, 78, 82, 87, 
89, 102, 104, 106, 107, 108, 109, 110, 
111, 112, 114  
Test Readiness Review, 29, 30, 42, 108  
Tools, 6, 7, 10, 15, 63, 65, 66, 71, 73, 81, 
84, 89, 94, 95, 107, 110  
TPM, 34, 42, 48, 73, 86, 87  
Training, 6, 7, 15, 35, 36, 59, 66, 67, 68, 70, 
71, 75, 78, 81, 84, 86, 94, 95, 107, 108, 
111 
Transition Process, 40, 64, 67  
TRL, 34, 39, 42, 113, 114  
TRR , 29, 30, 42, 108  
Validation, 15, 17, 18, 30, 37, 40, 42, 44, 45, 
53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 
66, 67, 68, 71, 72, 73, 76, 77, 79, 81, 82, 
85, 89, 94, 102, 105, 106, 109, 110, 111, 
112, 113, 114  
Verification, 3, 16, 17, 30, 37, 50, 52, 53, 
54, 55, 57, 58, 60, 61, 62, 63, 64, 67, 71, 
73, 76, 89, 94, 104, 106, 109, 111  
Waivers, 4, 5, 11, 12, 4 0, 91, 96, 100, 109, 
110 
WBS, 14, 15, 16, 17, 18, 19, 37, 38, 39, 40, 
42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 
 
This Document Is Uncontrolled When  Printed.  167 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 
70, 72, 73, 75, 76, 78, 81, 84, 86, 89, 93, 
95 
Work, 1, 5, 7, 10, 12, 13, 14, 15, 20, 22, 34, 
35, 37, 39, 40, 42, 43, 44, 47, 48, 49, 51, 
57, 58, 59, 60, 62, 63, 65, 67, 68, 70, 71, 
72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 
84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 100, 
106, 107, 113, 114, 159  Work Breakdown Structure, 14, 15, 16, 17, 
18, 19, 37, 38, 3 9, 40, 42, 43, 44, 45, 46, 
47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 
61, 62, 65, 66, 67, 68, 70, 72, 73, 75, 76, 
78, 81, 84, 86, 89, 93, 95  
Workforce. See also Teams, 6, 7, 15, 59, 70, 
71, 78  
 
 
 